{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AvsvWxEK6AX"
   },
   "source": [
    "# Prediciendo una cancion de Rock en español,  usando la herramienta de Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAueq2Stwhf7"
   },
   "source": [
    "## Instalar matplotlib en Anaconda3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Pmi9Lwowhf-"
   },
   "source": [
    "Se debe tener encuenta en que perfil se va a instalar esta libreria de anaconda 3. Se recomienda para este caso de Uso de Tensor Flow, primero instalar y activar el mismo para instalar el resto de librerias con las que se va a trabajar:\n",
    "\n",
    "1. conda install -c conda-forge matplotlib\n",
    "2. conda install matplotlib\n",
    "3. conda install matplotlib.pyplot\n",
    "4. pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osx3NkOHK_fa"
   },
   "source": [
    "## Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1637587990163,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "yvLhn22DKuJc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# manipulacion de archivos y carpetas\n",
    "import io\n",
    "import os\n",
    "import requests # libreria que nos permite conectarnos a una direccion online o una URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1637587991192,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "eUXlUGp5whgI"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # Para trabajar los asuntos de generacion de graficos (una de varias librerias que hay)\n",
    "plt.rcParams['figure.figsize'] = (16,9) #tamaño de la figura (ancho,alto)\n",
    "plt.style.use('ggplot') # estilo grafico de las imagenes generadas\n",
    "# guardar las imagenes y tablas en el notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1637587995499,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "7RXRU378LIYx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time #Para uso del tiempo\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0jDKCkSwhgK"
   },
   "source": [
    "### Instalacion de Tensor en Anaconda3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNBLxsJhw_Pj"
   },
   "source": [
    "https://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQzRt4_iwhgL"
   },
   "source": [
    "1. Download and install Anaconda or the smaller Miniconda.\n",
    "\n",
    "2. On Windows open the Start menu and open an Anaconda Command Prompt. On macOS or Linux open a terminal window. Use the default bash shell on macOS or Linux.\n",
    "\n",
    "3. Choose a name for your TensorFlow environment, such as “tf”.\n",
    "\n",
    "4. To install the current release of CPU-only TensorFlow, recommended for beginners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tUvZfT5HwhgN"
   },
   "outputs": [],
   "source": [
    "# conda create -n tf tensorflow\n",
    "# conda activate tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSZNUZuPwhgP"
   },
   "source": [
    "Or, to install the current release of GPU TensorFlow on Linux or Windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Sn5u4nHWwhgQ"
   },
   "outputs": [],
   "source": [
    "#conda create -n tf-gpu tensorflow-gpu\n",
    "#conda activate tf-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZh7zonzvW0A"
   },
   "source": [
    "### Libreria Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1614,
     "status": "ok",
     "timestamp": 1637588002319,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "IDEG4ytxpGhG",
    "outputId": "3ef0ea94-0053-4076-ca7d-003241977809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ---------\n",
      "absl-py                      0.13.0\n",
      "aiohttp                      3.8.1\n",
      "aiosignal                    1.2.0\n",
      "anyio                        2.2.0\n",
      "argon2-cffi                  20.1.0\n",
      "astor                        0.8.1\n",
      "astunparse                   1.6.3\n",
      "async-generator              1.10\n",
      "async-timeout                4.0.1\n",
      "attrs                        21.2.0\n",
      "Babel                        2.9.1\n",
      "backcall                     0.2.0\n",
      "bleach                       4.0.0\n",
      "blinker                      1.4\n",
      "brotlipy                     0.7.0\n",
      "cachetools                   4.2.2\n",
      "certifi                      2021.10.8\n",
      "cffi                         1.15.0\n",
      "charset-normalizer           2.0.4\n",
      "click                        8.0.3\n",
      "colorama                     0.4.4\n",
      "cryptography                 3.4.8\n",
      "cycler                       0.11.0\n",
      "debugpy                      1.5.1\n",
      "decorator                    5.1.0\n",
      "defusedxml                   0.7.1\n",
      "entrypoints                  0.3\n",
      "flatbuffers                  2.0\n",
      "fonttools                    4.28.2\n",
      "frozenlist                   1.2.0\n",
      "gast                         0.4.0\n",
      "google-auth                  1.33.0\n",
      "google-auth-oauthlib         0.4.1\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.42.0\n",
      "h5py                         3.6.0\n",
      "idna                         3.2\n",
      "importlib-metadata           4.8.1\n",
      "ipykernel                    6.4.1\n",
      "ipython                      7.29.0\n",
      "ipython-genutils             0.2.0\n",
      "jedi                         0.18.0\n",
      "Jinja2                       3.0.2\n",
      "json5                        0.9.6\n",
      "jsonschema                   3.2.0\n",
      "jupyter-client               7.0.6\n",
      "jupyter-core                 4.9.1\n",
      "jupyter-server               1.4.1\n",
      "jupyterlab                   3.2.1\n",
      "jupyterlab-pygments          0.1.2\n",
      "jupyterlab-server            2.8.2\n",
      "keras                        2.7.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "kiwisolver                   1.3.2\n",
      "libclang                     12.0.0\n",
      "Markdown                     3.3.4\n",
      "MarkupSafe                   2.0.1\n",
      "matplotlib                   3.5.0\n",
      "matplotlib-inline            0.1.2\n",
      "mistune                      0.8.4\n",
      "mkl-fft                      1.3.1\n",
      "mkl-random                   1.2.2\n",
      "mkl-service                  2.4.0\n",
      "multidict                    5.1.0\n",
      "nbclassic                    0.2.6\n",
      "nbclient                     0.5.3\n",
      "nbconvert                    6.1.0\n",
      "nbformat                     5.1.3\n",
      "nest-asyncio                 1.5.1\n",
      "notebook                     6.4.6\n",
      "numpy                        1.21.2\n",
      "oauthlib                     3.1.1\n",
      "opt-einsum                   3.3.0\n",
      "packaging                    21.3\n",
      "pandocfilters                1.4.3\n",
      "parso                        0.8.2\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       8.4.0\n",
      "pip                          21.2.4\n",
      "prometheus-client            0.12.0\n",
      "prompt-toolkit               3.0.20\n",
      "protobuf                     3.14.0\n",
      "pyasn1                       0.4.8\n",
      "pyasn1-modules               0.2.8\n",
      "pycparser                    2.21\n",
      "Pygments                     2.10.0\n",
      "PyJWT                        2.1.0\n",
      "pyOpenSSL                    21.0.0\n",
      "pyparsing                    3.0.4\n",
      "PyPrind                      2.11.3\n",
      "pyreadline                   2.1\n",
      "pyrsistent                   0.18.0\n",
      "PySocks                      1.7.1\n",
      "python-dateutil              2.8.2\n",
      "pytz                         2021.3\n",
      "pywin32                      228\n",
      "pywinpty                     0.5.7\n",
      "pyzmq                        22.2.1\n",
      "requests                     2.26.0\n",
      "requests-oauthlib            1.3.0\n",
      "rsa                          4.7.2\n",
      "scipy                        1.7.1\n",
      "Send2Trash                   1.8.0\n",
      "setuptools                   58.0.4\n",
      "setuptools-scm               6.3.2\n",
      "six                          1.16.0\n",
      "sniffio                      1.2.0\n",
      "tensorboard                  2.7.0\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.6.0\n",
      "tensorflow                   2.5.0\n",
      "tensorflow-estimator         2.7.0\n",
      "tensorflow-gpu               2.7.0\n",
      "tensorflow-io-gcs-filesystem 0.22.0\n",
      "termcolor                    1.1.0\n",
      "terminado                    0.9.4\n",
      "testpath                     0.5.0\n",
      "tomli                        1.2.2\n",
      "tornado                      6.1\n",
      "traitlets                    5.1.1\n",
      "typing-extensions            3.10.0.2\n",
      "urllib3                      1.26.7\n",
      "wcwidth                      0.2.5\n",
      "webencodings                 0.5.1\n",
      "Werkzeug                     2.0.2\n",
      "wheel                        0.35.1\n",
      "win-inet-pton                1.1.0\n",
      "wincertstore                 0.2\n",
      "wrapt                        1.12.1\n",
      "yarl                         1.6.3\n",
      "zipp                         3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59248,
     "status": "ok",
     "timestamp": 1637588065611,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "zsI6flBBulya",
    "outputId": "468ae34d-e332-46fa-e936-559b1eb14467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (0.22.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (3.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (1.21.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (12.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (1.42.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (0.35.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (3.10.0.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorflow-gpu) (0.13.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (58.0.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.6.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in f:\\anaconda\\envs\\tf-gpu\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2940,
     "status": "ok",
     "timestamp": 1637588072030,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "vZLGt8ZjLDz5"
   },
   "outputs": [],
   "source": [
    "#Librerias enfocadas al Deep Learning\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1637588076006,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "5xRHx1YULGaz",
    "outputId": "079983d7-4f99-498a-a67a-0424b77d9910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.7.0\n",
      "GPU esta disponible\n",
      "Dispositivos disponibles:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "print(\"GPU esta\", \"disponible\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "print(\"Dispositivos disponibles: \", tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\derma\\AppData\\Local\\Temp/ipykernel_20116/337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-moL5b2kLs6l"
   },
   "source": [
    "### Activacion de la GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jQVrYa9u5HC"
   },
   "source": [
    "Uso de GPU para entrenar en tensorflow\n",
    "\n",
    "https://medium.com/analytics-vidhya/solution-to-tensorflow-2-not-using-gpu-119fb3e04daa\n",
    "\n",
    "Elejir una de las siguientes dos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 168,
     "status": "ok",
     "timestamp": 1637588104918,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "8oq-MMh3Lweq",
    "outputId": "0b5b5be4-e610-4a5e-ae1b-280ebdc88435"
   },
   "outputs": [],
   "source": [
    "#tf.device('/CPU:0') #activando la CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4eG9CYPEzkT1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x1cd13bf7c00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.device('/GPU:0') #activando la GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directorio en PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directorio donde guardar los checkpoints en pc\n",
    "root = 'C:/Users/derma/Documents/Checkpoints Deep/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DimSM2kUxIHb"
   },
   "source": [
    "### Descargar y preprocesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1637588152736,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "V43MysRtMOAh",
    "outputId": "56de1dd2-76a2-4a4d-b5b5-73b1b5514406"
   },
   "outputs": [],
   "source": [
    "fileDL= tf.keras.utils.get_file('100CancionesParaEntrenar100-100.txt','https://raw.githubusercontent.com/DerUwU/Deep-Learning/main/Proyecto%20Final/Dataset/100CancionesParaEntrenar100-100.txt')\n",
    "texto = open(fileDL, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "omOiynNhMlWx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flaca\n",
      "No me claves tus puñales por la espalda\n",
      "Tan profundo\n",
      "No me duelen, no me hacen mal\n",
      "\n",
      "Lejos\n",
      "En el centro de la tierra\n",
      "Las raíces del amor\n",
      "Donde estaban, quedarán\n",
      "\n",
      "Entre el no me olvides\n",
      "Me dejé nuestros abriles olvidados\n",
      "En el fondo del placard\n",
      "Del cuarto de invitados\n",
      "Eran tiempos dorados\n",
      "Un pasado mejor\n",
      "\n",
      "Aunque casi me equivoco y te digo poco a poco:\n",
      "No me mientas, no me digas la verdad,\n",
      "No te quedes callada, no levantes la voz,\n",
      "Ni me pidas perdón\n",
      "\n",
      "Aunque casi te confieso\n",
      "Que también he sido un perro compañero\n",
      "Un perro ideal que aprendió a ladrar\n",
      "Y a volver al hogar, para poder comer\n",
      "\n",
      "Flaca\n",
      "No me claves, tus puñales, por la espalda\n",
      "Tan profundo\n",
      "No me duelen, no me hacen mal\n",
      "\n",
      "Lejos\n",
      "En el centro de la tierra\n",
      "Las raíces del amor\n",
      "Donde estaban, quedaran\n",
      "Ay\n",
      "Ven y dime todas esas cosas\n",
      "Invítame a sentarme junto a ti\n",
      "Escucharé todos tus sueños\n",
      "En mi oído\n",
      "\n",
      "Y déjame estrechar tus manos\n",
      "Y regalarte unas pocas de ilusiones\n",
      "Ay, ven y cuéntame una historia\n",
      "Que me haga sentir bien\n",
      "\n",
      "Yo te escucharé\n",
      "Con todo el silencio del planeta\n",
      "Y miraré tus ojos\n",
      "Como si fueran los últimos de este país\n",
      "\n",
      "Ay\n",
      "Déjame ver cómo es que floreces\n",
      "Con cinco pétalos te absorberé\n",
      "Cinco sentidos que te roban\n",
      "Solo un poco de tu ser\n",
      "\n",
      "Y seis veces para vivirte\n",
      "Debajo de una misma Luna\n",
      "Y otras nueve pasarán para\n",
      "Sentir que nuevas flores nacerán\n",
      "\n",
      "Y que cada estrella\n",
      "Fuese una flor\n",
      "Y así regalarte\n",
      "Todo un racimo de estrellas\n",
      "\n",
      "No dejes que amanezca\n",
      "No dejes que la noche caiga\n",
      "No dejes que el Sol salga\n",
      "Solo déjame estar junto a ti\n",
      "\n",
      "Ay larara larara\n",
      "Ay lara ay larara\n",
      "Cuando estoy en mis excesos\n",
      "Contigo en grande emoción\n",
      "Quisiera con embelesos arrancarte el corazón\n",
      "Arrancarte el corazón y comérmelo a besos\n",
      "\n",
      "Ay larara larara\n",
      "Ay lara ay larara\n",
      "Yo te juro y te prometo\n",
      "Como siempre te he querido\n",
      "Que si tu amor es completo\n",
      "Cúmpleme lo prometido\n",
      "Yo no quiero que otro prieto\n",
      "Quiera lo que yo he querido\n",
      "\n",
      "Ay larara larara\n",
      "Ay lara ay larara\n",
      "Ay larara larara\n",
      "Ay lara ay larara\n",
      "\n",
      "Mariquita quita, quita\n",
      "Quítame dolor y pena\n",
      "Debajo de tu rebozo\n",
      "Se pasa una noche buena\n",
      "Buena es la buena memoria\n",
      "Memoria del que se acuerda\n",
      "\n",
      "Se acuerda de San Francisco\n",
      "San Francisco no es Esteban\n",
      "Esteban no es ningún santo\n",
      "Santo es aquel que le reza\n",
      "Rezan los Padres Maitines\n",
      "\n",
      "Los Maitines no son completos\n",
      "Completas serán las mañas\n",
      "Las mañas de un hechicero\n",
      "Hechicero es el que urde\n",
      "Urde la mujer su tela\n",
      "\n",
      "Tela la del buen cedazo\n",
      "Cedazo de harina y cuerda\n",
      "Cuerda la de los cochinos\n",
      "Los cochinos tragan hierba\n",
      "De la hierba nace el trigo\n",
      "El trigo es el que se siembra\n",
      "\n",
      "Se siembra porque es costumbre\n",
      "Dijo un viejito al pasar\n",
      "Y lo echaron al alumbre\n",
      "Porque no supo Trovar\n",
      "Y lo echaron al alumbre\n",
      "Porque no supo Trovar\n",
      "Me quieren agitar, me incitan a gritar\n",
      "Soy como una roca, palabras no me tocan\n",
      "Adentro hay un volcán, que pronto va estallar\n",
      "Yo quiero estar tranquilo\n",
      "\n",
      "Es mi situación, una desolación\n",
      "Soy como un lamento, lamento boliviano\n",
      "Que un día empezó y no va a terminar\n",
      "Ya nadie hace daño\n",
      "\n",
      "Uoh\n",
      "Yo', yo', yo'\n",
      "Eh, eh, eh\n",
      "Yo'\n",
      "\n",
      "Y yo estoy aquí\n",
      "Borracho y loco\n",
      "Y mi corazón idiota\n",
      "Siempre brillará (siempre brillará)\n",
      "\n",
      "Y yo te amaré\n",
      "Te amaré por siempre\n",
      "Nena, no te peines en la cama\n",
      "Que los viajantes se van a atrasar\n",
      "\n",
      "Uoh\n",
      "Yo', yo', yo'\n",
      "Eh, eh, eh\n",
      "Yo'\n",
      "\n",
      "Y hoy estoy aquí\n",
      "Borracho y loco\n",
      "Y mi corazón idiota\n",
      "Siempre brillará (siempre brillará)\n",
      "\n",
      "Y yo te amaré\n",
      "Te amaré por siempre\n",
      "Nena, no te peines en la cama\n",
      "Que los viajantes se van a atrasar\n",
      "\n",
      "Y yo estoy aquí\n",
      "Borracho y loco\n",
      "Y mi corazón idiota\n",
      "Siempre brillará (siempre brillará)\n",
      "\n",
      "Y yo te amaré\n",
      "Te amaré por siempre\n",
      "Nena, no te peines en la cama\n",
      "Que los viajantes se van a atrasar\n",
      "Te puedes vender\n",
      "Cualquier oferta es buena, si quieres poder\n",
      "Uy, qué fácil es\n",
      "Abrir tanto la boca para opinar\n",
      "Y si te piensas echar atrás\n",
      "Ya tienes muchas huellas que borrar\n",
      "\n",
      "Uh, déjame\n",
      "Que yo no tengo la culpa de verte caer\n",
      "Si yo no tengo la culpa de verte caer\n",
      "\n",
      "Pierdes la fe\n",
      "Cualquier esperanza es vana\n",
      "Y no sé qué creer\n",
      "Pe-Pe-Pe-Pero olvídame\n",
      "Que nadie te ha llamado\n",
      "Y ya estás otra vez\n",
      "\n",
      "Uh, déjame\n",
      "Que yo no tengo la culpa de verte caer\n",
      "Si yo no tengo la culpa\n",
      "\n",
      "Entre dos tierras estás\n",
      "Y no dejas aire que respirar\n",
      "Entre dos tierras estás\n",
      "Y no dejas aire que respirar\n",
      "\n",
      "Déjalo ya\n",
      "No seas membrillo y permite pasar\n",
      "Y si no piensas echar atrás\n",
      "Ya tienes mucho barro que tragar\n",
      "\n",
      "Uh, déjame\n",
      "Que yo no tengo la culpa de verte caer\n",
      "Si yo no tengo la culpa de verte\n",
      "\n",
      "Entre dos tierras estás\n",
      "Y no dejas aire que respirar\n",
      "Entre dos tierras estás\n",
      "Y no dejas aire que respirar\n",
      "\n",
      "Déjame\n",
      "Que yo no tengo la culpa de verte caer\n",
      "Si yo no tengo la culpa de verte\n",
      "\n",
      "Entre dos tierras estás\n",
      "Y no dejas aire que respirar\n",
      "Entre dos tierras estás\n",
      "Y no dejas aire que respirar\n",
      "Soy un chico de la calle\n",
      "Camino la ciudad con mi guitarra\n",
      "Sin molestar a nadie\n",
      "Voy cortando cadenas\n",
      "Estoy creciendo contra la miseria\n",
      "Y alguna que otra pena\n",
      "Pero pierdo el control\n",
      "Llego a casa y escucho su voz\n",
      "Siempre la misma canción\n",
      "\n",
      "Nene, nene-ne que vas a ser\n",
      "Cuando seas grande\n",
      "Nene, nene-ne que vas a ser\n",
      "Cuando seas grande\n",
      "Estrella de rock and roll\n",
      "Presidente de la nación\n",
      "Nene, nene-ne que vas a ser\n",
      "Cuando alguien aprete el botón\n",
      "\n",
      "Estoy casi condenado\n",
      "A tener éxito para no ser\n",
      "Un perro fracasado\n",
      "Así, así, así, así yo fui enseñado\n",
      "Generaciones tras generaciones\n",
      "Marchan a mi lado\n",
      "Solo quiero jugar\n",
      "Soy el sueño de mamá y papá\n",
      "Yo, no les puedo fallar\n",
      "\n",
      "Nene, nene-ne que vas a ser\n",
      "Cuando seas grande\n",
      "Nene, nene-ne que vas a ser\n",
      "Cuando seas grande\n",
      "Estrella de rock and roll\n",
      "Presidente de la nación\n",
      "Nene, nene-ne que vas a ser\n",
      "Cuando alguien aprete el botón\n",
      "Nene, nene-ne que vas a ser\n",
      "Cuando seas grande\n",
      "\n",
      "(Cuando seas grande)\n",
      "Nene, nene-ne que vas a ser\n",
      "Cuando seas grande\n",
      "(Cuando seas grande)\n",
      "Nene, nene-ne que vas a ser\n",
      "Cuando seas grande\n",
      "(Cuando seas grande)\n",
      "Nene, nene-ne que vas a ser\n",
      "Cuando seas grande\n",
      "Cae la noche y amanece en París\n",
      "En el día en que todo ocurrió\n",
      "Como un sueño de loco sin fín\n",
      "La fortuna se ha reído de ti, ja ja\n",
      "\n",
      "Sorprendido espiando\n",
      "El lobo escapó aullando\n",
      "Es mordido por el mago del Siam\n",
      "\n",
      "La Luna llena sobre París\n",
      "Ha transformado en hombre a Denisse\n",
      "\n",
      "Rueda por los bares del boulevard\n",
      "Se ha alojado en un sucio hostal\n",
      "\n",
      "Mientras está cenando\n",
      "Junto a el se ha sentado\n",
      "Una joven con la que irá a contemplar\n",
      "La Luna llena sobre París\n",
      "\n",
      "Algunos francos cobra Denisse\n",
      "Auuu!! Lobo hombre en París\n",
      "Auuu!! Su nombre es Denisse\n",
      "\n",
      "El hombre lobo está en París\n",
      "Su nombre Denisse\n",
      "La Luna llena sobre París\n",
      "Ha transformado en hombre a Denisse\n",
      "\n",
      "Mientras está cenando\n",
      "Junto a él se ha sentado\n",
      "Una joven con la que irá a contemplar\n",
      "La Luna llena sobre París\n",
      "\n",
      "Ha transformado en hombre a Denisse\n",
      "Lobo hombre en París\n",
      "No sabes como te deseo\n",
      "No sabes como te he soñado\n",
      "Si tu supieras que me muero\n",
      "Por tu amor, y por tus labios\n",
      "\n",
      "Si tu supieras que soy sincero\n",
      "Yo soy derecho y no te fallo\n",
      "Si tu supieras lo que te quiero\n",
      "Podría darte todo hasta mis ojos\n",
      "\n",
      "Pero tu ya tienes otro\n",
      "Un tipo frió y aburrido\n",
      "Un tonto que es un reprimido\n",
      "Eso no te queda a ti\n",
      "No te va\n",
      "\n",
      "Oye mi amor\n",
      "No me digas que no\n",
      "Y vamos juntando las almas\n",
      "Oye mi amor\n",
      "No me digas que no\n",
      "Y vamos juntando los cuerpos\n",
      "\n",
      "Conmigo tu alucinarías, como no!\n",
      "Conmigo tu hasta el fin del mundo\n",
      "Contigo yo me perdería\n",
      "Contigo yo quiero todo\n",
      "Y nada a medias\n",
      "\n",
      "Pero tu ya tienes otro\n",
      "Tipo frió y aburrido\n",
      "Un tonto que es un reprimido\n",
      "Eso no te queda a ti\n",
      "No te va\n",
      "\n",
      "Oye mi amor\n",
      "No me digas que no\n",
      "Y vamos juntando las almas\n",
      "Oye mi amor\n",
      "No me digas que no\n",
      "Y vamos juntando los cuerpos\n",
      "En la vida, conocí mujer igual a la flaca\n",
      "Coral negro de la Habana, tremendísima mulata\n",
      "Cien libras de piel y hueso, cuarenta kilos de salsa\n",
      "Y, en la cara, dos soles, que, sin palabras, hablan\n",
      "Que, sin palabras, hablan\n",
      "\n",
      "La flaca duerme de día, dice que así el hambre engaña\n",
      "Y cuando cae la noche, baja a bailar a la tasca\n",
      "Y bailar y bailar, y tomar y tomar\n",
      "Una cerveza tras otra, pero ella nunca engorda\n",
      "Pero ella nunca engorda\n",
      "\n",
      "Por un beso de la flaca, daría lo que fuera\n",
      "Por un beso de ella, aunque solo uno fuera\n",
      "Por un beso de la flaca, daría lo que fuera\n",
      "Por un beso de ella, aunque solo uno fuera\n",
      "Aunque solo uno fuera\n",
      "\n",
      "Mojé mis sábanas blancas, como dice la canción\n",
      "Recordando las caricias que me brindó el primer día\n",
      "Y enloquezco de ganas de dormir a su ladito\n",
      "Porque, Dios, que esta flaca a mí me tiene loquito\n",
      "Ooh, a mí me tiene loquito\n",
      "\n",
      "Por un beso de la flaca, yo daría lo que fuera\n",
      "Por un beso de ella, aunque solo uno fuera\n",
      "Por un beso de la flaca, yo daría lo que fuera\n",
      "Por un beso de ella, aunque solo uno fuera\n",
      "\n",
      "Aunque solo uno fuera\n",
      "Aunque solo uno fuera\n",
      "Aunque solo uno fuera\n",
      "Aunque solo uno fuera\n",
      "\n",
      "Aunque solo uno fuera\n",
      "\n",
      "Aunque solo uno fuera\n",
      "\n",
      "Aunque solo uno fuera\n",
      "Aunque solo uno fuera\n",
      "Aunque solo uno fuera\n",
      "Aunque solo uno fuera\n",
      "\n",
      "Aunque solo uno fuera\n",
      "\n",
      "Aunque solo uno fuera\n",
      "\n",
      "Aunque solo uno fuera\n",
      "\n",
      "Aunque solo uno fuera\n",
      "Aunque solo uno fuera\n",
      "Aunque solo uno fuera\n",
      "Se llama Lola y tiene historia\n",
      "Aunque mas que historia sea un poema\n",
      "Su vida entera pasó buscando\n",
      "Noches de gloria como alma en pena\n",
      "Detras de su manto de fría dama\n",
      "Tenía escondidas tremendas armas\n",
      "Para las batallas del cara a cara\n",
      "Que con ventaja muy bien libraba\n",
      "Le fue muy mal de mano en mano\n",
      "De boca en boca, de cama en cama\n",
      "Como una muñeca que se desgasta\n",
      "Se queda vieja y la pena arrastra\n",
      "\n",
      "Oyeme mi Lola, mi tierna Lola\n",
      "Tu triste vida es tu triste historia\n",
      "Pero que manera de caminar\n",
      "Mira que soberbia en su mirar\n",
      "Oyeme mi Lola, mi tierna Lola\n",
      "Tu triste vida es tu triste historia\n",
      "Pero que manera de caminar\n",
      "Mira que soberbia en su mirar\n",
      "Oyeme mi Lola, mi tierna Lola\n",
      "Tu triste vida es tu triste historia\n",
      "\n",
      "Fue mujer serena hasta el instante\n",
      "De entregarse presta a sus amantes\n",
      "Es tiempo de llanto, es tiempo de duda\n",
      "De nostalgia y de su locura\n",
      "Tienes el consuelo de saberte llena\n",
      "De cariño limpio y amor sincero\n",
      "Por que nadie supo robar de tus besos\n",
      "Eso que hoy te sobra y que nadie añora\n",
      "\n",
      "Es el tiempo de la arruga que no perdona\n",
      "Es el tiempo de la fruta y la pintura\n",
      "Acompaño a mi sombra por la avenida\n",
      "Mis pasos se pierden entre tanta gente\n",
      "Busco una puerta, una salida donde convivan pasado y presente\n",
      "De pronto me paro, alguien me observa\n",
      "Levanto la vista, me encuentro con ella\n",
      "Y ahí está, ahí está, ahí está, ahí está\n",
      "Viendo pasar el tiempo la Puerta de Alcalá\n",
      "\n",
      "Una mañana fría llegó Carlos III\n",
      "Con aire insigne se quitó el sombrero\n",
      "Muy lentamente bajó de su caballo\n",
      "Con voz profunda le dijo a su lacayo\n",
      "Ahí está la Puerta de Alcalá\n",
      "Ahí está, ahí está\n",
      "Viendo pasar el tiempo la Puerta de Alcalá\n",
      "Lanceros con casaca\n",
      "Monarcas de otras tierras fanfarrones\n",
      "Que llegan inventando la guerra\n",
      "Milicias que resisten bajo el no pasarán\n",
      "Y el sueño eterno como viene se va\n",
      "Y ahí está, ahí está, la Puerta de Alcalá\n",
      "Ahí está, ahí está, viendo pasar el tiempo la Puerta de Alcalá\n",
      "\n",
      "Todos los tiranos se abrazan como hermanos\n",
      "Exhibiendo a las gentes sus calvas indecente\n",
      "Mandadas de mangante\n",
      "Doscientos estudiantes inician la revuelta\n",
      "Son los años sesenta\n",
      "Y ahí está, ahí está, la Puerta de Alcalá\n",
      "Ahí está, ahí está, viendo pasar el tiempo la Puerta de Alcalá\n",
      "\n",
      "Un travestí perdido\n",
      "Un guardia pendenciero\n",
      "Pelos colorados, chinchetas en los cueros\n",
      "Rockeros insurgentes, modernos complacientes\n",
      "Poetas y colgados, aires de libertad\n",
      "Y ahí está la Puerta de Alcalá\n",
      "Ahí está, ahí está, viendo pasar el tiempo la Puerta de Alcalá\n",
      "\n",
      "Miro de frente, me pierdo en sus ojos\n",
      "Sus arcos me vigilan, su sombra me acompaña\n",
      "No intento esconderme, nadie la engaña\n",
      "Toda la vida pasa por su mirada\n",
      "Mírala, mírala, mírala, mírala, mírala\n",
      "La Puerta de Alcalá, mírala, mírala, mírala, mírala\n",
      "Ella existió solo en un sueño\n",
      "Él es un poema que el poeta nunca escribió\n",
      "En la eternidad los dos unieron sus almas\n",
      "Para darle vida a esta triste canción de amor\n",
      "A esta triste canción de amor\n",
      "A esta triste canción de amor\n",
      "\n",
      "Él es como el mar\n",
      "Ella es como la Luna\n",
      "Y en las noches de Luna llena hacen el amor\n",
      "Y en la inmensidad los dos unieron sus almas\n",
      "Para darle vida a esta triste canción de amor\n",
      "A esta triste canción de amor\n",
      "A esta triste canción de amor\n",
      "\n",
      "Él es como un Dios, ella es como una virgen\n",
      "Y los dioses les enseñaron a pecar\n",
      "Y en la eternidad los dos unieron sus almas\n",
      "Para darle vida a esta triste canción de amor\n",
      "A esta triste canción de amor\n",
      "A esta triste canción de amor\n",
      "Siento el calor de toda tu piel\n",
      "En mi cuerpo otra vez\n",
      "Estrella fugaz, enciende mi sed\n",
      "Misteriosa mujer\n",
      "\n",
      "Con tu amor sensual, cuánto me das\n",
      "Haz que mi sueño sea una verdad\n",
      "Dame tu alma hoy, haz el ritual\n",
      "Llévame al mundo donde pueda soñar\n",
      "\n",
      "¡Uhh! Debo saber si en verdad\n",
      "En algún lado estás\n",
      "Voy a buscar una señal, una canción\n",
      "¡Uhh! Debo saber si en verdad\n",
      "En algún lado estás\n",
      "Solo el amor que tu me das, me ayudará\n",
      "\n",
      "Al amanecer tu imagen se va\n",
      "Misteriosa mujer\n",
      "Dejaste en mí lujuria total\n",
      "Hermosa y sensual\n",
      "\n",
      "Corazón sin Dios, dame un lugar\n",
      "En ese mundo tibio, casi irreal\n",
      "Deberé buscar una señal\n",
      "En aquel camino por el que vas\n",
      "\n",
      "¡Uhh! Debo saber si en verdad\n",
      "En algún lado estás\n",
      "Voy a buscar una señal, una canción\n",
      "¡Uhh! Debo saber si en verdad\n",
      "En algún lado estás\n",
      "Solo el amor que tu me das, me ayudará\n",
      "\n",
      "Tu presencia marcó en mi vida el amor lo sé\n",
      "Es difícil pensar en vivir ya sin vos\n",
      "Corazón sin Dios, dame un lugar\n",
      "En ese mundo tibio, casi irreal\n",
      "\n",
      "¡Uhh! Debo saber si en verdad\n",
      "En algún lado estás\n",
      "Voy a buscar una señal, una canción\n",
      "¡Uhh! Debo saber si en verdad\n",
      "En algún lado estás\n",
      "Solo el amor que tu me das, me ayudará\n",
      "Estoy llorando en mi habitación\n",
      "Todo se nubla a mi alrededor\n",
      "Ella se fue con un niño pijo\n",
      "Tiene un Ford fiesta blanco\n",
      "Y un jersey amarillo\n",
      "\n",
      "Por el parque les veo pasar\n",
      "Cuando se besan lo paso fatal\n",
      "Voy a vengarme de ese marica\n",
      "Voy a llenarle el cuello\n",
      "Con polvos pica pica\n",
      "\n",
      "Sufre, mamón, devuélveme a mi chica\n",
      "O te retorcerás entre polvos pica pica\n",
      "Sufre, mamón, devuélveme a mi chica\n",
      "O te retorcerás entre polvos pica pica\n",
      "\n",
      "Le he quemado su jersey\n",
      "Y se ha comprado cinco o seis\n",
      "Voy a destrozarle el coche\n",
      "Lo tengo preparado, voy esta noche\n",
      "\n",
      "No te reirás nunca más de mi\n",
      "Lo siento, nene, vas a morir\n",
      "Tú me quitaste lo que más quería\n",
      "Y volverá conmigo volverá algún día\n",
      "\n",
      "Sufre, mamón, devuélveme a mi chica\n",
      "O te retorcerás entre polvos pica pica\n",
      "Sufre, mamón, devuélveme a mi chica\n",
      "O te retorcerás entre polvos pica pica\n",
      "\n",
      "(Sufre, mamón) sufre, mamón, devuélveme a mi chica\n",
      "O te retorcerás entre polvos pica pica\n",
      "(Sufre, mamón) sufre, mamón, devuélveme a mi chica\n",
      "O te retorcerás entre polvos pica pica\n",
      "Tantas cosas en la mente me aterran\n",
      "El pensar en todo y nada de una vez\n",
      "El estar dormido, el soñar con frío\n",
      "El permanecer perdido, buscándote\n",
      "\n",
      "Tras los muros de mi casa tan fría\n",
      "Que puedo pensar en algo para hacer calor\n",
      "El moverme me hace titubear y dudar\n",
      "Pero esa imagen no se irá jamás\n",
      "\n",
      "Y el pensar en ti me hace recordar\n",
      "El encanto que provoca tu fragilidad\n",
      "Quedarme sentado aquí me puede congelar\n",
      "El hablar de ti me puede delatar\n",
      "\n",
      "Podría gritar\n",
      "Que me dejes beber de tu sangre\n",
      "\n",
      "Y el pensar en ti me hace recordar\n",
      "El encanto que provoca tu fragilidad\n",
      "Quedarme sentado aquí me puede congelar\n",
      "El hablar de ti me puede delatar\n",
      "\n",
      "Podría gritar\n",
      "Que me dejes beber de tu sangre\n",
      "\n",
      "Podría gritar\n",
      "Que me dejes beber de tu sangre\n",
      "\n",
      "Podría gritar\n",
      "Los análisis dan alcohol\n",
      "Dicen que ha bebido nuestro conductor\n",
      "\n",
      "Debido a su mal estado, al final hemos chocado\n",
      "Después de tanto ruido\n",
      "Hemos salido como hemos podido\n",
      "El coche destrozado\n",
      "No entiendo nada estoy tan atontado\n",
      "\n",
      "No ha habido graves heridos\n",
      "De esta hemos salido vivos\n",
      "\n",
      "Y es que siempre estamos viviendo de noche\n",
      "Siempre tomando copas\n",
      "Viajando en coche\n",
      "Siempre acompañando a la madrugada\n",
      "Que a veces nos enseña su mala cara\n",
      "\n",
      "El disco esta cerradO\n",
      "Y como un loco el se lo ha pasado\n",
      "En las curvas siempre derrapando\n",
      "Continuamente se la esta jugando\n",
      "\n",
      "Unas luces vienen deslumbrando\n",
      "Cierro los ojos y ya estoy rodando\n",
      "Y un coche que pasa al lado\n",
      "Se para a ver la que se ha armado\n",
      "\n",
      "No ha habido graves heridos\n",
      "De esta hemos salido vivos\n",
      "\n",
      "Y es que siempre estamos viviendo de noche\n",
      "Siempre tomando copas\n",
      "Viajando en coche\n",
      "Siempre acompañando a la madrugada\n",
      "Que a veces nos enseña su mala cara\n",
      "Quisiera que me dijeras una y otra ves\n",
      "Te quiero baby te quiero\n",
      "Y siempre te querré\n",
      "Con esa lengua extranjera\n",
      "Que me ablanda las piernas\n",
      "\n",
      "Que tienes boca de azúcar\n",
      "Eso ya lo se\n",
      "Que besas con quemaduras\n",
      "De veneno y miel\n",
      "Que me has cambiado no hay duda\n",
      "Lo se también y me gusta\n",
      "\n",
      "Por eso voy a ser, por ti, por ti, por ti\n",
      "Eternamente bella, bella\n",
      "Con un hechizo de gitana\n",
      "Seré la princesa encantada\n",
      "Que te amara por siempre\n",
      "Desesperadamente, desesperadamente\n",
      "\n",
      "Eternamente bella, bella\n",
      "Y en plena noche de la iguana\n",
      "Hago un hechizo de gitana\n",
      "Para que sigas siempre\n",
      "Desesperadamente enamorado de mi\n",
      "\n",
      "Dispara y ya estas dispuesto\n",
      "A morir por mi\n",
      "Por que ten vendes tan caro\n",
      "Dime ya que si\n",
      "Tras esos lentes tan negros\n",
      "Que demonios piensas\n",
      "\n",
      "Así es la ruleta rusa\n",
      "Échale valor\n",
      "De que te sirven las dudas\n",
      "Has igual que yo\n",
      "Si encuentro algo que gusta\n",
      "Lo tomo y no me lo pienso\n",
      "\n",
      "Desde hoy prometo ser por ti, por ti, por ti\n",
      "Luz\n",
      "Roja es la luz\n",
      "Luz de neón\n",
      "Que anuncia el lugar\n",
      "Baile Kumbala Bar\n",
      "Y adentro la noche es\n",
      "Música y pasión\n",
      "\n",
      "Sol\n",
      "No entiendes lo que pasa aquí\n",
      "Esto es la noche\n",
      "Y de la noche son las cosas del amor\n",
      "El corazón a media luz\n",
      "Siempre se entregará\n",
      "\n",
      "Mar\n",
      "Todo el ambiente huele a mar\n",
      "Mucho calor\n",
      "Sudores en la piel, sudor sabor a sal\n",
      "Y en la pista una pareja\n",
      "Se vuelve a enamorar\n",
      "\n",
      "Una brisa, una caricia\n",
      "Y en la pista una pareja\n",
      "Se vuelve a enamorar\n",
      "Un sabroso y buen danzón\n",
      "A media luz el corazón\n",
      "Y en el Kumbala todo es\n",
      "Música y pasión\n",
      "Yo seré el viento que va\n",
      "Navegaré por tu oscuridad\n",
      "Tú rocío\n",
      "Beso frío\n",
      "Que me quemará\n",
      "Yo seré tormento y amor\n",
      "Tú la marea que arrastra a los dos\n",
      "\n",
      "Yo y tú\n",
      "Tú y yo\n",
      "No dirás que no\n",
      "No dirás que no\n",
      "No dirás que no\n",
      "Seré tu amante bandido, bandido\n",
      "Corazón, corazón malherido\n",
      "Seré tu amante cautivo, cautivo\n",
      "Seré\n",
      "\n",
      "Pasión privada, dorado enemigo\n",
      "Huracán, huracán abatido\n",
      "Me perderé en un momento contigo\n",
      "Por siempre\n",
      "Yo seré un hombre por ti\n",
      "Renunciaré a ser lo que fui\n",
      "Yo y tú\n",
      "Tú y yo\n",
      "Sin misterio\n",
      "Sin misterio\n",
      "Sin misterio\n",
      "\n",
      "Seré tu amante bandido, bandido\n",
      "Corazón, corazón malherido\n",
      "Seré tu amante cautivo, cautivo\n",
      "Seré\n",
      "\n",
      "Pasión privada, dorado enemigo\n",
      "Huracán, huracán abatido\n",
      "Me perderé en un momento contigo\n",
      "Por siempre\n",
      "Seré tu héroe de amor\n",
      "Seré el amante que muere rendido\n",
      "Corazón, corazón malherido\n",
      "\n",
      "Seré tu amante bandido, bandido\n",
      "Seré\n",
      "Y en un oasis prohibido, prohibido\n",
      "Por amor, por amor concebido\n",
      "Me perderé en un momento contigo\n",
      "Por siempre\n",
      "Seré tu héroe de amor\n",
      "No tengo ganas de hablar\n",
      "No tengo más que decir\n",
      "Que puedo ya declarar\n",
      "Sobre lo de Berlín\n",
      "No voy a hablar de Vietnam\n",
      "No se pelear ni mentir\n",
      "Solo me gusta mirar\n",
      "Debajo de tu piel\n",
      "No es solo una escusa\n",
      "\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "\n",
      "Aunque el cielo se ponga\n",
      "Rojo de tanto lucir\n",
      "Quiero contar hasta diez\n",
      "Quiero cantar para mi\n",
      "Vas a ayudarme a volar\n",
      "Vas a dejarme subir\n",
      "Solo te pido mirar\n",
      "Solo te pido mirar debajo de tu piel\n",
      "Es lo que me gusta\n",
      "\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "\n",
      "Y bombardearán una noche\n",
      "El aire traerá otro olor\n",
      "No comprenderán\n",
      "Que es lo que paso\n",
      "El cielo será\n",
      "Solo esta vez\n",
      "Solo vos y yo\n",
      "Solo vos y yo\n",
      "Solo vos y yo\n",
      "No es solo una escusa\n",
      "\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Te quiero tanto uo\n",
      "Te quiero tanto\n",
      "Es por amor\n",
      "Que al mudo yo le hago frente\n",
      "Y por amor\n",
      "Si caigo me levanto siempre\n",
      "Y al costado del camino\n",
      "Veo ángeles caídos\n",
      "\n",
      "Es por amor\n",
      "Que nunca voy a abandonarte\n",
      "Y por amor\n",
      "Espero lo que vas a darme\n",
      "Y al costado del camino\n",
      "Veo ángeles caídos\n",
      "\n",
      "Hay una fiesta\n",
      "Y es esta noche\n",
      "Baila conmigo\n",
      "Así te pido dame\n",
      "Uh uh uh\n",
      "Mirame\n",
      "Uh uh uh\n",
      "\n",
      "Es por amor\n",
      "Que uno hace lo que siente\n",
      "Y por amor\n",
      "Yo sigo y sigo aunque me cueste\n",
      "Y al costado del camino\n",
      "Veo ángeles caídos\n",
      "\n",
      "Hay una fiesta\n",
      "Y es esta noche\n",
      "Baila conmigo\n",
      "Así te pido dame\n",
      "Uh uh uh\n",
      "Mirame\n",
      "Uh uh uh\n",
      "Si yo fuera mujer\n",
      "Tendría que empezar\n",
      "Por abrir del todo\n",
      "\n",
      "El telón del fondo del mito virginal\n",
      "Y del hombre macho\n",
      "\n",
      "Si yo fuera mujer\n",
      "Podría publicar\n",
      "Miles de razones\n",
      "Del secreto de don juan\n",
      "Las carcajadas nos harían llorar\n",
      "\n",
      "Si yo fuera mujer\n",
      "A mi no me tocaba\n",
      "Un tonto con coche\n",
      "Música de fondo\n",
      "Y pose de john wayne\n",
      "Me daría el gusto de violarle a el\n",
      "\n",
      "Y así nada de igualdad\n",
      "Muerte al violador\n",
      "Premio a la infidelidad\n",
      "Desearía tomar eso\n",
      "Que ellos llaman nuestra\n",
      "Libertad\n",
      "Si yo fuera mujer\n",
      "Si yo fuera mujer\n",
      "Yo me tendría que querer\n",
      "\n",
      "Si yo fuera mujer\n",
      "No me casaría\n",
      "Nada de sostén\n",
      "Nada de pastillas\n",
      "Que las tome él\n",
      "Y ahora que lo sabes\n",
      "Ahora tómame\n",
      "\n",
      "Y así nada de igualdad\n",
      "Muerte al violador\n",
      "Premio a la infidelidad\n",
      "Desearía tomar eso\n",
      "Que ellos llaman nuestra\n",
      "Libertad\n",
      "Si yo fuera mujer\n",
      "Si yo fuera mujer\n",
      "Yo me tendría que querer\n",
      "\n",
      "Y así nada de igualdad\n",
      "Muerte al violador\n",
      "Premio a la infidelidad\n",
      "Desearía tomar eso\n",
      "Que ellos llaman nuestra\n",
      "Libertad\n",
      "Si yo fuera mujer\n",
      "Si fuera mujer\n",
      "Yo me tendría que querer\n",
      "\n",
      "Si yo fuera mujer\n",
      "Tendría que empezar\n",
      "Por abrir del todo\n",
      "El telón del fondo\n",
      "Del mito virginal\n",
      "Y del hombre macho\n",
      "\n",
      "Si yo fuera mujer\n",
      "Si yo fuera mujer\n",
      "Si yo fuera mujer\n",
      "La policía te está extorsionando (dinero)\n",
      "Pero ellos viven de lo que tú estás pagando\n",
      "Y si te tratan como a un delincuente (ladrón)\n",
      "No es tu culpa, dale gracias al regente\n",
      "\n",
      "Hay que arrancar el problema de raíz\n",
      "Y cambiar al gobierno de nuestro país\n",
      "A la gente que está en la burocracia\n",
      "A esa gente que le gustan las migajas\n",
      "\n",
      "Yo por eso me quejo y me quejo\n",
      "Porque aquí es donde vivo\n",
      "Y yo ya no soy un pendejo\n",
      "\n",
      "¿Qué no wachas los puestos del gobierno?\n",
      "Hay personas que se están enriqueciendo\n",
      "Gente que vive en la pobreza\n",
      "Nadie hace nada\n",
      "Porque a nadie le interesa\n",
      "\n",
      "Es la gente de arriba te detesta\n",
      "Hay más gente que quiere\n",
      "Que caigan sus cabezas\n",
      "Si le das más poder al poder\n",
      "Más duro te van a venir a coger\n",
      "\n",
      "Porque fuimos potencia mundial\n",
      "Somos pobres\n",
      "Nos manejan mal\n",
      "\n",
      "Dame, dame, dame, dame todo el power\n",
      "Para que te demos en la madre\n",
      "Gimme, gimme, gimme, gimme todo el poder\n",
      "So I can come around to joder\n",
      "Dame, dame, dame, dame todo el power\n",
      "Para que te demos en la madre\n",
      "Gimme, gimme, gimme, gimme todo el poder\n",
      "So I can come around to joder\n",
      "Dámele, dámele, dámele, dámele todo el poder\n",
      "Dámele, dámele, dámele, dámele todo el power\n",
      "\n",
      "(Así es puto!\n",
      "Fuck you puto baboso!)\n",
      "\n",
      "Porque no nacimos donde no hay que comer\n",
      "No hay porque preguntarnos como le vamos a hacer\n",
      "Si nos pintan como unos huevones\n",
      "No lo somos\n",
      "¡Viva México, cabrones!\n",
      "\n",
      "Que se sienta el power mexicano\n",
      "Que se sienta, todos juntos como hermanos\n",
      "Porque somos más, jalamos más parejo\n",
      "¿Por qué estar siguiendo a una bola de pendejos?\n",
      "Que nos llevan por donde les conviene\n",
      "Y es nuestro sudor lo que los mantiene\n",
      "Los mantiene comiendo pan caliente\n",
      "Ese pan, es el pan de nuestra gente\n",
      "\n",
      "Dame, dame, dame, dame todo el power\n",
      "Para que te demos en la madre\n",
      "Gimme, gimme, gimme, gimme todo el poder\n",
      "So I can come around to joder\n",
      "Dame, dame, dame, dame todo el power\n",
      "Para que te demos en la madre\n",
      "Gimme, gimme, gimme, gimme todo el poder\n",
      "So I can come around to joder\n",
      "Dame, dame, dame, dame el poder (¿cómo?)\n",
      "Dame, dame, dame, dame todo el power\n",
      "Dame, dame, dame, dame el poder (¿cómo?)\n",
      "Dame, dame, dame, dame todo el power\n",
      "\n",
      "¡El pueblo unido jamás será vencido!\n",
      "¡El tito y el huidos, jamás serán vencidos!\n",
      "\n",
      "Dame, dame, dame, dame el poder\n",
      "Dame, dame, dame, dame todo el power\n",
      "Tengo roto el corazón\n",
      "Desarmada la razón\n",
      "Podras tener mil romances\n",
      "Nunca con sinceridad\n",
      "\n",
      "Tengo tanto para amar\n",
      "Es como una enfermedad\n",
      "No tengas miedo a enamorarte\n",
      "No huyas, no huyas de mi\n",
      "Dolor de amor quiero contagiarte\n",
      "No huyas, no huyas de mi\n",
      "Soy un cometa que vuela a Marte esta noche\n",
      "\n",
      "Puedo hacerte sentir bien\n",
      "Tres seis cinco junto a mi\n",
      "Hay quiénes te prometen oro\n",
      "Yo te ofrezco el corazón\n",
      "\n",
      "Tengo tanto para amar\n",
      "Es como una enfermedad\n",
      "No tengas miedo a enamorarte\n",
      "No huyas, no huyas de mi\n",
      "Dolor de amor quiero contagiarte\n",
      "No huyas, no huyas de mi\n",
      "Soy un cometa que vuela a Marte\n",
      "\n",
      "Girando, volando de amor\n",
      "Girando, volando de amor\n",
      "\n",
      "No, no huyas de mi\n",
      "No, no, no huyas de mi\n",
      "\n",
      "Girando, volando por ti\n",
      "Girando, volando de amor\n",
      "Girando, volando a Marte\n",
      "\n",
      "No tengas miedo a enamorarte\n",
      "No huyas, no huyas de mi\n",
      "Dolor de amor quiero contagiarte\n",
      "No huyas, no huyas de mi\n",
      "Solos, solo tú y yo\n",
      "Soy un cometa que vuela a Marte\n",
      "Soy un cometa que vuela a Marte esta noche\n",
      "Hoy todo está fuera de sector\n",
      "Tal vez no estuvo nunca mejor\n",
      "Nadie regula mi decisión\n",
      "Nadie transforma mi satisfacción\n",
      "\n",
      "La mente se adelanta\n",
      "El cuerpo quiere ceder\n",
      "Aunque no ríen ni lloran\n",
      "Todo puede suceder\n",
      "Si tu quieres otra vez\n",
      "\n",
      "Hoy todo está fuera de sector\n",
      "Tu mente está fuera de control\n",
      "Tu cuerpo está fuera de control\n",
      "Hoy todo está fuera de sector\n",
      "\n",
      "Afuera es noche y brilla la ciudad\n",
      "Hay gente demente que siempre busca más\n",
      "Aunque ya no queda nada en que gastar\n",
      "Con demasiada paz y tanta soledad\n",
      "\n",
      "La mente se adelanta\n",
      "El cuerpo quiere ceder\n",
      "Aunque no ríen ni lloran\n",
      "Todo puede suceder\n",
      "Como la primera vez\n",
      "\n",
      "Hoy todo está fuera de sector\n",
      "Tu mente está fuera de control\n",
      "Tu cuerpo está fuera de control\n",
      "Hoy todo está fuera de sector\n",
      "\n",
      "Hoy todo está fuera de sector\n",
      "Tal vez no estuvo nunca mejor\n",
      "Nadie regula mi decisión\n",
      "Nadie transforma mi satisfacción\n",
      "\n",
      "Fuera de sector, fuera de sector\n",
      "Tu imaginación\n",
      "Me programa en vivo\n",
      "Llegó volando\n",
      "Y me arrojo sobre ti\n",
      "Salto en la música\n",
      "Entro en tu cuerpo\n",
      "Cometa Halley\n",
      "Cópula y ensueño\n",
      "\n",
      "Tuyo, tuyo Luna de miel\n",
      "Luna de miel\n",
      "\n",
      "Tu madre no podrá\n",
      "Interceptarme\n",
      "Perfecto, hermoso\n",
      "Veloz, luminoso\n",
      "\n",
      "Caramelos de miel entre tus manos\n",
      "Te prometo una cita ideal\n",
      "Adorando la vitalidad\n",
      "\n",
      "Tuyo, tuyo, Luna de miel\n",
      "Luna de miel\n",
      "\n",
      "Tu imaginación\n",
      "Me programa en vivo\n",
      "Llegó volando\n",
      "Y me arrojo sobre ti\n",
      "Salto en la música\n",
      "Entro en tu cuerpo\n",
      "Cometa Halley\n",
      "Cópula y ensueño\n",
      "\n",
      "Tuyo, tuyo Luna de miel\n",
      "Luna de miel\n",
      "\n",
      "Caramelos de miel entre tus manos\n",
      "Te prometo una cita ideal\n",
      "Adorando la vitalidad\n",
      "\n",
      "Gozo, tuyo Luna de miel\n",
      "Luna de miel\n",
      "Te salgo a buscar\n",
      "Y no te puedo encontrar\n",
      "Ya tus amigas me han dicho por qué\n",
      "\n",
      "Llegando a la fiesta\n",
      "Te veo besándote con otro\n",
      "Yo no lo quiero\n",
      "Hoy te tengo que olvidar\n",
      "\n",
      "Decías que me querías\n",
      "Que no era fácil poderme olvidar\n",
      "Regresame el retrato\n",
      "Se acabó\n",
      "\n",
      "Lo siento, es tarde\n",
      "Comprende este es el final\n",
      "Régresame el retrato\n",
      "Se acabó\n",
      "\n",
      "Llegando a la fiesta\n",
      "Te veo besándote con otro\n",
      "Yo no lo quiero\n",
      "Hoy te tengo que olvidar\n",
      "\n",
      "Decías que me querías\n",
      "Que no era fácil poderme olvidar\n",
      "Regresame el retrato\n",
      "Se acabó\n",
      "\n",
      "Es el final\n",
      "De nuestro amor\n",
      "No voy en tren, voy en avión\n",
      "No necesito a nadie\n",
      "A nadie alrededor\n",
      "No voy en tren, voy en avión\n",
      "No necesito a nadie\n",
      "A nadie alrededor\n",
      "\n",
      "Porque no hay nadie que mi piel resista\n",
      "Porque no hay nadie que yo quiera ver\n",
      "No veo televisión ni las revistas\n",
      "No veo ya nada que no pueda ser\n",
      "\n",
      "Por eso yo no voy en tren, voy en avión\n",
      "No necesito a nadie\n",
      "A nadie alrededor\n",
      "No voy en tren, voy en avión\n",
      "No necesito a nadie\n",
      "A nadie alrededor\n",
      "\n",
      "Cuando era niño nunca fui muy listo\n",
      "Tocaba el piano como un animal\n",
      "Yo sé que algunos piensan que soy mixto\n",
      "Pero yo tengo personalidad\n",
      "\n",
      "Yo soy de la cruz del sur\n",
      "Soy el que cierra y el que apaga la luz\n",
      "Yo soy de la cruz del sur\n",
      "Aquí y en everywhere\n",
      "\n",
      "No voy en tren, voy en avión\n",
      "En algún lugar de un gran país\n",
      "Olvidaron construir\n",
      "Un hogar donde no queme el Sol\n",
      "Y al nacer no haya que morir\n",
      "Y en las sombras\n",
      "Mueren genios sin saber\n",
      "De su magia\n",
      "Concedida, sin pedirlo\n",
      "Mucho tiempo antes de nacer\n",
      "\n",
      "No hay camino que\n",
      "Llegue hasta aquí\n",
      "Y luego pretenda salir\n",
      "Con el fuego de\n",
      "El atardecer arde la hierba\n",
      "\n",
      "En algún lugar de un gran país\n",
      "Olvidaron construir\n",
      "Un hogar donde no queme el Sol\n",
      "Y al nacer no haya que morir\n",
      "Un silbido cruza el pueblo\n",
      "Y se ve, un jinete\n",
      "Que se marcha con el viento\n",
      "Mientras grita\n",
      "Que no va a volver\n",
      "\n",
      "Y la tierra aquí\n",
      "Es de otro color\n",
      "El polvo lo debe saber\n",
      "Los hombres ya no\n",
      "Saben si lo son\n",
      "Pero lo quieren creer\n",
      "Las madres que ya\n",
      "No saben llorar\n",
      "Ven a sus hijos partir\n",
      "La tristeza aquí\n",
      "No tiene lugar\n",
      "Cuando lo triste es vivir\n",
      "Me verás volar, por la ciudad de la furia\n",
      "Donde nadie sabe de mí, y yo soy parte de todos\n",
      "Nada cambiará, con un aviso de curva\n",
      "En sus caras veo el temor, ya no hay fábulas\n",
      "En la ciudad de la furia\n",
      "\n",
      "Me verás caer como un ave de presa\n",
      "Me verás caer sobre terrazas desiertas\n",
      "Te desnudaré, por las calles azules\n",
      "Me refugiaré, antes que todos despierten\n",
      "Me dejarás dormir al amanecer\n",
      "Entre tus piernas, entre tus piernas\n",
      "Sabrás ocultarme bien y desaparecer\n",
      "Entre la niebla, entre la niebla\n",
      "Un hombre alado; extraña la tierra\n",
      "Me verás volar, por la ciudad de la furia\n",
      "Donde nadie sabe de mí; y yo soy parte de todos\n",
      "Con la luz del Sol, se derriten mis alas\n",
      "Solo encuentro en la oscuridad\n",
      "Lo que me une, con la ciudad de la furia\n",
      "\n",
      "Me verás caer; como una flecha salvaje\n",
      "Me verás caer; entre vuelos fugaces\n",
      "Buenos Aires se ve, tan susceptible\n",
      "Es el destino de furia (es), lo que en sus caras persiste\n",
      "Me dejarás dormir al amanecer\n",
      "Entre tus piernas, entre tus piernas\n",
      "Sabrás ocultarme bien y desaparecer\n",
      "Entre la niebla, entre la niebla\n",
      "Un hombre alado prefiere la noche\n",
      "\n",
      "Me verás volver, me verás volver\n",
      "¡Te están buscando matador!\n",
      "\n",
      "Me dicen el matador, nací en barracas\n",
      "Si hablamos de matar mis palabras matan\n",
      "No hace mucho tiempo que cayó el león santillán\n",
      "Y ahora sé que en cualquier momento me la van a dar\n",
      "Mah matador, mah matador ¿dónde estas matador?\n",
      "Mah matador, mah matador\n",
      "\n",
      "Me dicen el matador me están buscando\n",
      "En una fría pensión los estoy esperando\n",
      "Agazapado en lo más oscuro de mi habitación\n",
      "Fuzil en mano, espero mi final\n",
      "Mah matador, mah matador\n",
      "Mah matador, mah matador\n",
      "La cana te busca matador\n",
      "La cana te prende matador\n",
      "\n",
      "¡Hey, hey!\n",
      "¡Hey, hey!\n",
      "\n",
      "¡Matador, matador!\n",
      "¿Dónde estas matador?\n",
      "¡Matador! Matador\n",
      "No te vayas matador\n",
      "Matadooooooor!!\n",
      "¡Oh yeah!\n",
      "¡Matador,matador!\n",
      "\n",
      "Viento de libertad sangre combativa\n",
      "En los bolsillos del pueblo la vieja herida\n",
      "De pronto el día se me hace de noche\n",
      "Murmullos, corridas y el golpe en la puerta\n",
      "Llegó la fuerza policial\n",
      "\n",
      "Mah matador, mah matador\n",
      "Mirá hermano en que terminaste\n",
      "Por pelear por un mundo mejor\n",
      "¿Qué suenan? Son balas, me alcanzan\n",
      "Me atrapan, resiste, ¡Victor jara no calla!\n",
      "¡Matador! ¡matador! Matador te está buscando\n",
      "¡Matador! ¡matador! Matador te están matando\n",
      "¡Matador, oh yeah!\n",
      "¡Matador, matador!\n",
      "Valiente matador\n",
      "\n",
      "Me dicen el matador de los 100 barrios porteños\n",
      "No tengo por que tener miedo mis palabras son balas\n",
      "Balas de paz, balas de justicia\n",
      "Soy la voz de los que hicieron callar sin razón\n",
      "Por el solo hecho de pensar distinto ¡ay dios!\n",
      "Santa Maria de los buenos aires si todo estuviera mejor\n",
      "¡Matador! ¡matador! Si todo estuviera mejor\n",
      "¡Matador! ¡matador! ¿a dónde vas matador?\n",
      "¡Matador, oh yeah!\n",
      "¡Matador, matador!\n",
      "Voy a tomar por vos\n",
      "Pasa un trago para olvidar\n",
      "Que el miedo te comio los pies\n",
      "Y que ahora sos un tipo mas\n",
      "Y que poco a poco te fuiste yendo\n",
      "Y que poco a poco te fuiste yendo de nuestro lugar\n",
      "\n",
      "Te sienta bien el sol,\n",
      "Te sienta bien ser cool,\n",
      "Te sienta bien el mal,\n",
      "Te sienta bien ser dios,\n",
      "Te sienta bien mentir y decir\n",
      "Que te fuiste yendo de nuestro lugar\n",
      "\n",
      "Que es lo que ha pasado con tu corazon\n",
      "Ya no marca el paso que marcaba ayer\n",
      "Nunca fuiste libre y esa es la razon\n",
      "Siempre hay un idiota para convencer\n",
      "Hablas toda la noche como un boy scout\n",
      "Hablas sobre mi vida como tu papa\n",
      "\n",
      "Los cadillacs tocando para vos\n",
      "Los cadillacs tocando para vos\n",
      "Los cadillacs tocando para vos\n",
      "Los cadillacs tocando para vos\n",
      "Mamá compró y se le rompió\n",
      "El forro del que naci yo\n",
      "La plata no pudo juntar\n",
      "Y el embarazo cancelar\n",
      "\n",
      "Ella invirtió en mi educación\n",
      "Pero con una condición\n",
      "Porque le tuve que jurar\n",
      "Que de vieja no la iba a internar\n",
      "\n",
      "Dificil de creer\n",
      "Dificil de explicar\n",
      "\n",
      "Dijo un troyano ojo con un griego que trae regalos\n",
      "\n",
      "Sea con dinero o no\n",
      "Siempre se paga un favor\n",
      "Y si veo que algo es facil\n",
      "Yo dudo enseguida\n",
      "\n",
      "Pague antes o despues\n",
      "La cuenta va a aparecer\n",
      "\n",
      "Y esta claro de que nada es gratis en la vida\n",
      "\n",
      "Papá pago una mina en un bar\n",
      "Cuando me llevo a debutar\n",
      "Y por curarme se endeudó\n",
      "De la peste que me contagió\n",
      "\n",
      "Sí sí ya se\n",
      "Esperma done\n",
      "Pero pobrecito el destinatario\n",
      "Yo tengo alzheimer hereditario\n",
      "\n",
      "Y como el jefe comento\n",
      "Despues que mi sueldo aumento\n",
      "\n",
      "Si la limosna es de cuatía\n",
      "Hasta el santo desconfía\n",
      "\n",
      "Sea con dinero o no\n",
      "Siempre se paga un favor\n",
      "Y si veo que algo es facil\n",
      "Yo dudo enseguida\n",
      "\n",
      "Pague antes o despues\n",
      "La cuenta va a aparecer\n",
      "\n",
      "Y esta claro de que nada es gratis en la vida\n",
      "Si sera asi que lo jodi\n",
      "Al diablo cuando le vendi\n",
      "Mi alma que no vale un billete\n",
      "Se la canjee por un clarete\n",
      "\n",
      "Ni honorario ni voluntario\n",
      "Soy un sicario y cobro salario\n",
      "Y no pidan solidaridad\n",
      "Que yo no hago caridad\n",
      "\n",
      "No es gratis mi salud\n",
      "Ni gratis sera mi ataud\n",
      "\n",
      "Si es que no pide su tajada\n",
      "Es que no vale nada\n",
      "\n",
      "Sea con dinero o no\n",
      "Siempre se paga un favor\n",
      "Y si veo que algo es facil\n",
      "Yo dudo enseguida\n",
      "\n",
      "Pague antes o despues\n",
      "La cuenta va a aparecer\n",
      "\n",
      "Y esta claro de que nada es gratis en la vida\n",
      "\n",
      "... nada es gratis en la vida\n",
      "... nada es gratis en la vida\n",
      "... nada es gratis en la vida\n",
      "... nada es gratis en la vida\n",
      "Hoy estoy raro, y no entiendo por qué,\n",
      "Si nada extraño me tuvo a maltraer.\n",
      "Hoy estoy raro, no sé lo que hacer.\n",
      "\n",
      "Será que hoy me puse a recordar\n",
      "los días de mi infancia cuando siempre estaba mal\n",
      "hijo único de la casualidad\n",
      "mi padre era hippie y mi madre era punk\n",
      "\n",
      "Ah, capaz...fue por esa niñera\n",
      "que para que no llorara ponía en mi mamadera\n",
      "valium, y sali'un día con sus amigos\n",
      "y volvió con esa manga de drogados,\n",
      "y acelerados, en un rito satánico\n",
      "después de torturar a mi hamster cocinaron.\n",
      "Fue un infierno, me lo hicieron probar.\n",
      "¡Y no era tierno!\n",
      "\n",
      "Depende, ahí yo era un jopende,\n",
      "como dijo mi tío que es un tipo que me entiende:\n",
      "el que no sufre no aprende,\n",
      "y ahí me bajó un diente de una patada\n",
      "y me robó la plata que el ratón dejó bajo mi almohada.\n",
      "Todos se reían cuando arrastraba la erre.\n",
      "Mi abuela me pedía que si moría no la entierre\n",
      "y que subiera más:\n",
      "\"Quizás, quizás, quizás\"\n",
      "\n",
      "Hoy estoy raro, y no entiendo por qué\n",
      "si nada extraño me tuvo a maltraer\n",
      "Hoy estoy raro no se lo que hacer.\n",
      "Sentarme a esperar, que se me pase y chau\n",
      "\n",
      "Y ta, capaz, fue que quede marcado\n",
      "por ser hijo de padres divorciados.\n",
      "¡Qué tarado!, no lo había pensado,\n",
      "pero si fuera así todos seriamos traumados.\n",
      "\n",
      "Y yo a media luz, ponía un blues\n",
      "y la abuela a Jesús le pedía que Gardel\n",
      "no fuera de Toulousse.\n",
      "Yo pinchaba con su cruz, los granos de pus\n",
      "por mi alergia al mousse.\n",
      "\n",
      "Achus!!! Será que fui a cenar\n",
      "con la novia de mi padre,\n",
      "que me invitó pero me hizo lavar las cacerolas,\n",
      "y al ver que mi hermana desfilaba medio en bolas\n",
      "me dijo: Mirá, las modelos son todas trolas.\n",
      "\n",
      "Y se enfurece,\n",
      "¡justo ella!, que cuando toma se emputece.\n",
      "Me tuve que rajar cuando después del cuarto vino\n",
      "me empezó a toquetear\n",
      "y se rió y le vino...hipo\n",
      "\n",
      "Y me contó como anticipo\n",
      "que va a dejar al viejo por el tipo\n",
      "que le pagó la lipo.\n",
      "Será por eso que estoy sensible,\n",
      "la vida es impredecible.\n",
      "\n",
      "Hoy estoy raro, y no entiendo por qué,\n",
      "si nada extraño me tuvo a maltraer.\n",
      "Hoy estoy raro no se lo que hacer.\n",
      "Sentarme a esperar, que se me pase y chau\n",
      "\n",
      "Capaz que no le hizo gracia\n",
      "al de la farmacia\n",
      "cuando dije que yo defiendo a muerte a la eutanasia.\n",
      "Decía que si todos se morían se fundía,\n",
      "y me tiró con un frasco de homeopatía.\n",
      "\n",
      "O en una de esas,\n",
      "como decía el peyote estoy mal de la cabeza.\n",
      "Pero no, el doctor que me curó me juró\n",
      "que la herida del frascazo en la nuca ya cicatrizó.\n",
      "\n",
      "Será ese copetín que tomé en el cafetín,\n",
      "picando un salamín, escuchando led zepellin\n",
      "o fue esa moza, con pinta de viciosa\n",
      "que de babosa echó en mi vaso alguna cosa\n",
      "\n",
      "¡Qué pedazo de guaso!\n",
      "Si rompió el vaso\n",
      "cuando mi faso\n",
      "le quemó el brazo,\n",
      "y por mi torpeza\n",
      "dejó el barril gigante de cerveza mal cerrado\n",
      "y el bar quedó inundado.\n",
      "Qué acertado,\n",
      "pensar que yo me quise levantar a la nami\n",
      "hablando del tsunami,\n",
      "y baldeando me dijo: \"¿Viste? Volvé por donde viniste,\n",
      "el cielo no existe\".\n",
      "\n",
      "Hoy estoy raro, y no entiendo por qué\n",
      "si nada extraño me tuvo a maltraer.\n",
      "Hoy estoy raro no se lo que hacer.\n",
      "Sentarme a esperar, que se me pase y chau.\n",
      "No tengo penas, ni tengo amores\n",
      "Y así no sufro de sinsabores\n",
      "Con todo el mundo estoy a mano\n",
      "Como no juego, ni pierdo ni gano\n",
      "\n",
      "No tengo mucho, ni tengo poco\n",
      "Como no opino, no me equivoco\n",
      "Y como metas yo no me trazo\n",
      "Nunca supe lo que es un fracaso\n",
      "\n",
      "Alegría y tristeza es lo mismo para mí\n",
      "Que no me interesa sentir\n",
      "Porque, en el ángulo de la vida\n",
      "Yo he decidido ser la bisectriz\n",
      "\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "\n",
      "No me involucro en la pareja\n",
      "Y así no sufro cuando me dejan\n",
      "A nadie quise jamás en serio\n",
      "Y entonces nunca lloro en los entierros!\n",
      "\n",
      "No pasa nada, si no me muevo\n",
      "Por eso, todo me chupa un huevo!\n",
      "Y no me mata la indecisión\n",
      "Si: Should I stay or should I go\n",
      "\n",
      "Ojos que no ven, corazón que no siente!\n",
      "Dijo un ciego cornudo una vez\n",
      "Y no soy como Hamlet Perez\n",
      "No me importa nada si ser o no ser!\n",
      "\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "\n",
      "Dirán algunos: \"ay, qué insensible!\"\n",
      "Otros dirán: \"qué vacío y simple!\"\n",
      "Y esas palabras las lleva el viento\n",
      "Como no escucho, no me caliento!\n",
      "\n",
      "No estoy ni arriba ni abajo\n",
      "Ya ni mejoro ni voy a empeorar!\n",
      "Y como nunca empiezo nada\n",
      "No me pone ansioso poder terminar!\n",
      "\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "(Ooohh)\n",
      "Así soy yo!\n",
      "Yendo un weekend a lo de Damián\n",
      "Tenía urgencia de hablar con el man\n",
      "Camine porque pinché mi van\n",
      "Vi una mina de la que soy fan\n",
      "\n",
      "Una que sale por el canal Sony\n",
      "En una serie que esta con un pony\n",
      "Y en mi casa del barrio marconi\n",
      "Siempre la veo tomándome un Johnny\n",
      "\n",
      "La salude pero me hecho flit\n",
      "Porque el programa era en mtv\n",
      "Hacia un spot de care free\n",
      "Y un jingle de los jeans lee\n",
      "\n",
      "Le dije a mi me gusta el rock\n",
      "Pero quedo en estado de shock\n",
      "Cuando escribí en una hoja de block\n",
      "Que era más fea que el señor spock\n",
      "\n",
      "Y que se rellena el sutien\n",
      "Con corn beef y chow mien\n",
      "Y a pesar de que usa channel\n",
      "Toma un cóctel con nafta de shell\n",
      "\n",
      "El security se puso heavy\n",
      "Era malo pero usaba levis\n",
      "Y me tiro desde la limousine\n",
      "En el ojo un vaso con gin\n",
      "\n",
      "Ahh, ahh\n",
      "Yendo a la casa de Damián\n",
      "Ahh, ahh\n",
      "Camino por el boulevard\n",
      "Ahh, ahh\n",
      "Yendo a la casa de Damián\n",
      "No sé si es que ya no veo\n",
      "Que ya no entiendo\n",
      "Porque me cuesta tanto llegar\n",
      "\n",
      "Cruzando la calle quede de flash\n",
      "Cuando vi dos niñas fumando hash\n",
      "Escuchaban trash y the clash\n",
      "Jugando quien tomaba más splash\n",
      "\n",
      "Y como una vez en un vernisagge\n",
      "Me dio un ataque de surmenage\n",
      "Cuando dijeron por diez pesos cash\n",
      "Hacemos juntos los tres un menash\n",
      "\n",
      "De los nervios me vino un tic\n",
      "En el fondo siempre fui un freak\n",
      "Le di fuego con yesquero bic\n",
      "Pero me pareció poco chic\n",
      "\n",
      "Que pasaran por una crush\n",
      "Con un nerd de media de plush\n",
      "Que le pintó los labios con rouge\n",
      "Yo le escupí su t-shirt de bush\n",
      "\n",
      "Con mi gargajo en la cara de George\n",
      "Se subió con las chicas a un porsche\n",
      "\n",
      "Se pensaba que era un tipo vip\n",
      "Masticando una papa chip\n",
      "Cuando empezó a hacer un strip\n",
      "Y quedaba solo en slip\n",
      "Le clavo en el ojo un clip\n",
      "Y con tu tumba va a decir rip\n",
      "\n",
      "Ahh, ahh\n",
      "Yendo a la casa de Damián\n",
      "Ahh, ahh\n",
      "Camino por el boulevard\n",
      "Ahh, ahh\n",
      "Yendo a la casa de Damián\n",
      "No sé si es que ya no veo\n",
      "Que ya no entiendo\n",
      "Porque me cuesta tanto llegar\n",
      "\n",
      "Era happy hour en el cabaret\n",
      "Era fashion y tenia moquete\n",
      "Como un pub cool y con pool\n",
      "El dueño es de Liverpool\n",
      "\n",
      "Y después de un breve impasse\n",
      "Entre a ver un show con freepass\n",
      "De un master que tocaba jazz\n",
      "A pesar de tener un bypass\n",
      "\n",
      "Vino a hablarme uno medio gay\n",
      "Yo ponía stop y el ponía play\n",
      "\n",
      "Le gustaba el big mac y tupac\n",
      "Vendía crack y tomaba prozac\n",
      "Y gritó escupiendo un snack\n",
      "El master hace playback\n",
      "Lo destriparon como hacia Jack\n",
      "Sin poder terminar su cognac\n",
      "\n",
      "Pero cayeron desde un penthouse\n",
      "En mi ojo un teclado y un mouse\n",
      "\n",
      "Ciego y perdido por el stress\n",
      "Peor que en un secuestro express\n",
      "Yo que en ingles solo sé decir yes\n",
      "Pensé en el libro de Herman Hess\n",
      "\n",
      "Soy un loser como boy scout\n",
      "Y de la vida me declaré out\n",
      "\n",
      "Ahh, ahh\n",
      "Yendo a la casa de damián\n",
      "Ahh, ahh\n",
      "Camino por el boulevard\n",
      "Ahh, ahh\n",
      "Yendo a la casa de damián\n",
      "No sé si es que ya no veo\n",
      "\n",
      "Ahh, ahh, ahh, ahh, ahh, ahh\n",
      "No sé si es que ya no veo\n",
      "Que ya no entiendo\n",
      "Porque me cuesta tanto llegar\n",
      "Papito tiene que ir a trabajar no quiere\n",
      "Papá no quiere ir pero tiene que ir igual\n",
      "Papito dice el ocio es lo que papi adora\n",
      "Papito no nació para las 8 horas\n",
      "\n",
      "Papá no quiere trabajar pero lo obligan\n",
      "Papito prefiere quedarse panza arriba\n",
      "Papito quiere una vida mas relajada\n",
      "Papá quiere quedarse en casa y no hacer nada\n",
      "\n",
      "Pobre papá (pobre papá)\n",
      "Pobre papá (pobre papá)\n",
      "A él no le gusta trabajar\n",
      "Pobre papito (pobre papito)\n",
      "Pobrecito papa (pobre papá)\n",
      "Nunca lo dejan descansar\n",
      "\n",
      "Papito no quiere trabajar tan seguido\n",
      "Papá preferiría ser un mantenido\n",
      "Papá piensa que un día manda todo al carajo\n",
      "Pero no encara eso porque es mucho trabajo\n",
      "\n",
      "Pobre papá (pobre papá)\n",
      "Pobre papá (pobre papá)\n",
      "A él no le gusta trabajar\n",
      "Pobre papito (pobre papito)\n",
      "Pobrecito papa (pobre papá)\n",
      "Nunca lo dejan descansar\n",
      "\n",
      "Siempre pensé que trabajar\n",
      "No era moderno\n",
      "Si el trabajo es salud\n",
      "Que trabajen los enfermos\n",
      "Si el trabajo es salud\n",
      "Que trabajen los enfermos\n",
      "Ya tuve que ir obligado a misa\n",
      "Ya toqué en el piano Para Elisa\n",
      "Ya aprendí a falsear mi sonrisa\n",
      "Ya caminé por la cornisa\n",
      "Ya cambié de lugar mi cama\n",
      "Ya hice comedia, ya hice drama\n",
      "Fui concreto y me fui por las ramas\n",
      "Ya me hice el bueno y tuve mala fama\n",
      "\n",
      "Ya fui ético y fui errático\n",
      "Ya fui escéptico y fui fanático\n",
      "Ya fui abúlico, fui metódico\n",
      "Ya fui impúdico y fui caótico\n",
      "\n",
      "Ya leí Arthur Conan Doyle\n",
      "Ya me pasé de nafta a gasoil\n",
      "Ya leí a Bretón y a Molière\n",
      "Ya dormí en colchón y en sommier\n",
      "Ya me cambié el pelo de color\n",
      "Ya estuve en contra y estuve a favor\n",
      "Lo que me daba placer ahora me da dolor\n",
      "Ya estuve al otro lado del mostrador\n",
      "\n",
      "Y oigo una voz que dice sin razón:\n",
      "Vos siempre cambiando\n",
      "¡Ya no cambiás más!\n",
      "Y yo estoy cada vez más igual\n",
      "Ya no sé qué hacer conmigo\n",
      "\n",
      "Ya me ahogué en un vaso de agua\n",
      "Ya planté café en Nicaragua\n",
      "Ya me fui a probar suerte a U.S.A.\n",
      "Ya jugué a la ruleta rusa\n",
      "Ya creí en los marcianos\n",
      "Ya fui ovolactovegetariano\n",
      "Sano, fui quieto y fui gitano\n",
      "Ya estuve tranqui'\n",
      "Y estuve hasta las manos\n",
      "\n",
      "Hice el curso de Mitología\n",
      "Pero de mí los dioses se reían\n",
      "Orfebrería lo salvé raspando\n",
      "Y Ritmología aquí la estoy aplicando\n",
      "Ya probé, ya fumé, ya tomé, ya dejé\n",
      "Ya firmé, ya viajé, ya pegué\n",
      "Ya sufrí, ya eludí, ya huí, ya asumí\n",
      "Ya me fui, ya volví, ya fingí, ya mentí\n",
      "Y entre tantas falsedades\n",
      "Muchas de mis mentiras ya son verdades\n",
      "Hice fácil las adversidades\n",
      "Y me compliqué en las nimiedades\n",
      "\n",
      "Y oigo una voz que dice con razón:\n",
      "Vos siempre cambiando\n",
      "¡Ya no cambiás más!\n",
      "Y yo estoy cada vez más igual\n",
      "Ya no sé qué hacer conmigo\n",
      "\n",
      "¡Adentro!\n",
      "\n",
      "Ya me hice un lifting\n",
      "Me puse un piercing\n",
      "Fui a ver al Dream Team\n",
      "Y no hubo feeling\n",
      "Me tatué al Che en una nalga\n",
      "Arriba de mami para que no se salga\n",
      "Ya me reí y me importó un bledo\n",
      "De cosas y gente que ahora me dan miedo\n",
      "Ayuné por causas al pedo\n",
      "Ya me empaché con pollo al spiedo\n",
      "\n",
      "Ya fui al psicólogo, fui al teólogo\n",
      "Fui al astrólogo, fui al enólogo\n",
      "Ya fui alcohólico y fui lambeta\n",
      "Ya fui anónimo y ya hice dieta\n",
      "Ya lancé piedras y escupitajos\n",
      "Al lugar donde ahora trabajo\n",
      "Y mi legajo cuenta a destajo\n",
      "Que me porté bien y que armé relajo\n",
      "\n",
      "Y oigo una voz que dice sin razón:\n",
      "Vos siempre cambiando\n",
      "¡Ya no cambias más!\n",
      "Y yo estoy cada vez más igual\n",
      "Ya no sé qué hacer conmigo\n",
      "\n",
      "Y oigo una voz que dice con razón:\n",
      "Vos siempre cambiando\n",
      "¡Ya no cambias más!\n",
      "Y yo estoy cada vez más igual\n",
      "Ya no sé qué hacer conmigo\n",
      "Para poder dormir\n",
      "Tengo que estar sedado\n",
      "Para ir a estudiar\n",
      "Tengo que estar tomado\n",
      "\n",
      "En la navidad\n",
      "Tengo que estar dopado\n",
      "Para no pensar\n",
      "Tengo que estar boleado\n",
      "\n",
      "Al trabajo\n",
      "Tengo que ir sedado\n",
      "A la provisión\n",
      "Tengo que ir tomado\n",
      "\n",
      "A lo de mi madre\n",
      "Tengo que ir dopado\n",
      "Si salgo de casa\n",
      "Tengo que ir boleado\n",
      "\n",
      "Y no me puedo quejar\n",
      "Después de todo no me va tan mal\n",
      "Llevando una vida así, tan natural\n",
      "\n",
      "Para funcionar\n",
      "Tengo que estar sedado\n",
      "Si quiero agradar\n",
      "Tengo que estar tomado\n",
      "\n",
      "Para no enloquecer\n",
      "Tengo que estar dopado\n",
      "Para sentir placer\n",
      "Tengo que estar boleado\n",
      "\n",
      "A mi cumpleaños\n",
      "Tengo que ir sedado\n",
      "Cualquier decisión\n",
      "La tomo dopado\n",
      "\n",
      "A pagar impuestos\n",
      "Tengo que ir dopado\n",
      "Si tengo un velorio\n",
      "Tengo que ir boleado\n",
      "\n",
      "Y no me puedo quejar\n",
      "Después de todo no me va tan mal\n",
      "Llevando una vida así, tan natural\n",
      "Llevando una vida así, tan natural\n",
      "\n",
      "(¡Ahhhh!)\n",
      "\n",
      "Para no llorar\n",
      "Tengo que estar sedado\n",
      "Para no arrugar\n",
      "Tengo que estar tomado\n",
      "\n",
      "Para olvidar\n",
      "Tengo que estar dopado\n",
      "Para recordar\n",
      "Tengo que estar boleado\n",
      "\n",
      "Y no me puedo quejar\n",
      "Después de todo no me va tan mal\n",
      "Llevando una vida así, tan natural\n",
      "Llevando una vida así, tan natural\n",
      "Llevando una vida así, tan natural\n",
      "\n",
      "(¡Ahhhh!)\n",
      "\n",
      "Tengo que estar sedado\n",
      "Tengo que estar tomado\n",
      "Tengo que estar dopado\n",
      "Tengo que estar boleado\n",
      "\n",
      "Tengo que estar sedado\n",
      "Tengo que estar tomado\n",
      "Tengo que estar dopado\n",
      "Para poder vivir\n",
      "Tengo que estar boleado\n",
      "Un invierno que dolía el frío\n",
      "Mi cuerpo ya no era el mío\n",
      "Iba en el ómnibus resfriado\n",
      "Mirando por el vidrio empañado\n",
      "\n",
      "Era linda aunque con mal aliento, pero le cedí la mitad de mi asiento\n",
      "Lo lamento me dijo con acento al lado de un degenerado no me siento\n",
      "\n",
      "Ah, rubia te hizo mal la lluvia\n",
      "O tenes la mente turbia\n",
      "Soñas que te sigue un paparazzi\n",
      "Con lentes negros de noche pareces un nazi\n",
      "No te acompaño el sentimiento\n",
      "Vas a morir de un ataque de pensamientos\n",
      "Y le grité en la cara congelada\n",
      "Otra rubia tarada\n",
      "\n",
      "Uh oh oh oh oh\n",
      "Alguien que de calor\n",
      "Uh oh oh oh oh\n",
      "Le pido por favor\n",
      "Uh oh oh oh oh\n",
      "Maldito invierno del 92\n",
      "\n",
      "Me noté el ganglio inflamado\n",
      "Y un auto no frenó porque estaba mojado\n",
      "Atropelló a un niño sin piedad\n",
      "Lo que mata es la humedad\n",
      "Como hermano menor había heredado, solo este buzo agujereado\n",
      "Y sabía que al tipo de al lado, le sobraba un acolchado\n",
      "\n",
      "Cuando lo vi caminando\n",
      "Por la acera de enfrente lo fui llamando\n",
      "Primero hizo como pilar miró\n",
      "Después como Robinson cruzo\n",
      "Pero me dijo señorito\n",
      "Que en el acolchado dormía su conejito\n",
      "Que sabrá lo que es un ghetto\n",
      "Otro ecologista cheto\n",
      "\n",
      "Uh oh oh oh oh\n",
      "Alguien que de calor\n",
      "Uh oh oh oh oh\n",
      "Le pido por favor\n",
      "Uh oh oh oh oh\n",
      "Maldito invierno del 92\n",
      "\n",
      "Iba en la niebla con mi dilema\n",
      "En el pulmón me salió un edema\n",
      "Y con mi aspecto de calavera\n",
      "Fui a que me viera una enfermera\n",
      "\n",
      "Parecía que yo deliraba\n",
      "Decía que era porque de fiebre volaba\n",
      "Volar, dije mirando un termo\n",
      "El sueño de los hombres y los pájaros enfermos\n",
      "\n",
      "Esa curandera rea\n",
      "Que en una asamblea de la OEA\n",
      "El hígado me dejó como paté\n",
      "Porque me contagió con hepatitis B\n",
      "Le descubrí a esa rastrera\n",
      "Un muñeco vudú mío en la heladera\n",
      "Le llené de flema la caldera\n",
      "Otra perra traicionera\n",
      "\n",
      "Uh oh oh oh oh\n",
      "Alguien que de calor\n",
      "Uh oh oh oh oh\n",
      "Le pido por favor\n",
      "Uh oh oh oh oh\n",
      "Maldito invierno del 92\n",
      "\n",
      "Va a ser una larga espera\n",
      "Hasta que llegue la primavera\n",
      "Aunque de frió voy tiritando\n",
      "Yo me sigo calentando\n",
      "\n",
      "Uh oh oh oh oh\n",
      "Alguien que de calor\n",
      "Uh oh oh oh oh\n",
      "Le pido por favor\n",
      "Uh oh oh oh oh\n",
      "Maldito invierno del 92\n",
      "El profesor pidió a su alumna\n",
      "Que le repita\n",
      "Aquella oscura elegía\n",
      "Densa e ignota\n",
      "Voy a hacer un playback de Rey\n",
      "Y los de Ricota\n",
      "En el karaoke de mi noviecita\n",
      "\n",
      "Y mientras ella el curioso\n",
      "Poema recita\n",
      "Le va falsificando\n",
      "El pasaje aéreo\n",
      "Voy a hacer un playback\n",
      "De Soda Stereo\n",
      "En el karaoke de mi noviecita\n",
      "\n",
      "En el karaoke de mi noviecita\n",
      "Ella me descifra\n",
      "Y después se complica\n",
      "En el karaoke de mi wachecita\n",
      "Playback de mi vida\n",
      "Canción problemita\n",
      "\n",
      "El profesor pidió silencio\n",
      "A su favorita\n",
      "Para tener un solo minuto\n",
      "De vida tranqui\n",
      "Voy a hacer un playback\n",
      "De Atahualpa Yupanqui\n",
      "En el karaoke de noviecita\n",
      "\n",
      "En el karaoke de mi noviecita\n",
      "Ella me descifra\n",
      "Y después se complica\n",
      "En el karaoke de mi wachecita\n",
      "Playback de mi vida\n",
      "Canción problemita\n",
      "\n",
      "Esa noche me tomé\n",
      "Hasta el agua bendita\n",
      "Mi penúltima curva\n",
      "Y para siempre me perdí\n",
      "Voy a hacer un playback\n",
      "De Giuseppe Verdi\n",
      "En el karaoke de noviecita\n",
      "\n",
      "En el karaoke de mi noviecita\n",
      "Ella me descifra\n",
      "Y después se complica\n",
      "En el karaoke de mi wachecita\n",
      "Playback de mi vida\n",
      "Canción problemita\n",
      "Todo lo que me gusta\n",
      "Es pecado o hace mal\n",
      "Todo lo que me gusta\n",
      "Es muy caro o ilegal\n",
      "Me mete en problemas\n",
      "Que no tienen solución\n",
      "Se me vuelve peligroso\n",
      "O trae una complicación\n",
      "Entonces no sé nunca que tengo que hacer\n",
      "Me pregunto y no me puedo responder\n",
      "\n",
      "Porque si me hace bien\n",
      "Porque si me hace bien\n",
      "Porque si me hace bien\n",
      "Me hace mal\n",
      "\n",
      "Todo lo que me da placer\n",
      "Es raro o inmoral\n",
      "Todo lo que me da placer\n",
      "No se puede contar\n",
      "Y ando haciendo cosas\n",
      "Que no puedo impedir\n",
      "Y a veces al despertarme\n",
      "Me tuve que arrepentir\n",
      "Entonces no sé nunca que tengo que hacer\n",
      "Me pregunto y no me puedo responder\n",
      "\n",
      "Porque si me hace bien\n",
      "Porque si me hace bien\n",
      "Porque si me hace bien\n",
      "Me hace mal\n",
      "\n",
      "Porque lo prohibido para mi es mejor\n",
      "Pero después me hace sentir peor\n",
      "Entonces no sé nunca que tengo que hacer\n",
      "Me pregunto y no me puedo responder\n",
      "\n",
      "Porque si me hace bien\n",
      "Porque si me hace bien\n",
      "Porque si me hace bien\n",
      "Me hace mal\n",
      "\n",
      "Y como veo que ya es tarde\n",
      "Para decidir\n",
      "Me tomo el último trago\n",
      "Y me acuesto a dormir\n",
      "Me tomo el último trago\n",
      "Y me acuesto a dormir\n",
      "Yo vivo en un pueblo podrido\n",
      "en donde todo està podrido\n",
      "y voy de noche siempre a oscuras\n",
      "caminando entre la basura.\n",
      "\n",
      "No voy a llegar muy lejos\n",
      "en un ómnibus lleno de viejos\n",
      "porque me asaltan con un caño\n",
      "delincuentes de doce años.\n",
      "\n",
      "Así quiero estar\n",
      "\n",
      "Los zapatos se me mojan\n",
      "pisando las baldosas flojas\n",
      "y la calle no me da tregua\n",
      "esquivando bosta de yegua\n",
      "\n",
      "Y a los chorros tanto les da\n",
      "Si es facil comprar, la autoridad\n",
      "Y cuando en casa busco abrigo\n",
      "Tengo que entrar pateando mendigos\n",
      "\n",
      "Así quiero estar\n",
      "\n",
      "Acá ya no hay nada que hacer\n",
      "El que se quedó es porque no se fue\n",
      "Y en la esquina hay feo olor\n",
      "Si no hace frío, hace calor\n",
      "\n",
      "Lunes de noche no hay donde ir\n",
      "Igual mejor para que salir\n",
      "Si me pegan los vecinos\n",
      "si no les doy plata para el vino\n",
      "\n",
      "Y si me pregunta algún podrido\n",
      "Por que no te vas de este pueblo podrido\n",
      "Le digo no me hagas poner violento\n",
      "y escuchá lo que estoy diciendo.\n",
      "\n",
      "Así quiero estar\n",
      "Las manos apoyadas en la mesa\n",
      "las rótulas temblando en el calor\n",
      "y en el tercer impulso se enderezan\n",
      "la van llevando\n",
      "\n",
      "Las casa tiene puertas muy pesadas\n",
      "y el cuarto está lejos del comedor\n",
      "por el pasillo se van sosteniendo\n",
      "la van llevando\n",
      "\n",
      "Con mucho esfuerzo se abre la ventana\n",
      "el polvo iluminado por el sol\n",
      "se van acomodando en os sillones\n",
      "la van llevando\n",
      "\n",
      "Los árboles tapan el paisaje\n",
      "y el mar está en las chapas de un galpon\n",
      "y mientras van mirando lo que pueden\n",
      "se van quedando\n",
      "\n",
      "Y vendrán autos nuevos y colchones blandos\n",
      "Y vendrán a buscarnos y a sacarnos a pasear\n",
      "\n",
      "El personal muy tarde fue alertado\n",
      "inútil la carrera en el calor\n",
      "se van distribuyendo en la vvereda\n",
      "y van buscando\n",
      "\n",
      "El día transcurre sin novedades\n",
      "y vuelven derrrotados por el corredor\n",
      "inventan una excusa para el mundo\n",
      "y la van llevando\n",
      "\n",
      "Y vendrán autos nuevos y colchones blandos\n",
      "Y vendrán a buscarnos y a sacarnos a pasear\n",
      "Vengan, vengan, síganme\n",
      "Vamos todos juntos todos a la vez\n",
      "Siempre hacia adelante no importa para qué\n",
      "Cero compromiso, cero estrés\n",
      "\n",
      "Salgan del agujero y recorramos el camino\n",
      "Arrasando a nuestro paso, devorando sin respiro\n",
      "Una marabunta sin discurso ni sentido\n",
      "Acá el que piensa pierde el que piensa está perdido\n",
      "\n",
      "Ya no hay mañana ni ayer\n",
      "Solo es lo que pase hoy\n",
      "Y sin lógica y razón\n",
      "Acá todos queremos lo mismo\n",
      "\n",
      "Y ellos nos ven deambular\n",
      "Sintiendo el miedo en la piel\n",
      "Porque nunca van a saber\n",
      "De donde venimos\n",
      "\n",
      "Somos su imagen más real\n",
      "Lo que nunca esperaron ver\n",
      "Su reflejo más aterrador\n",
      "Que los habrá de convencer\n",
      "Que hay poco por hacer en este apocalipsis zombi\n",
      "\n",
      "Ah, este simulacro virtual\n",
      "Copiar y pegar, usar y tirar\n",
      "Seguimos la jauría, la horda desalmada\n",
      "Exigiendo más de todo pero sin pensar en nada\n",
      "\n",
      "Ellos nos crearon pero ahora nos tienen miedo\n",
      "Porque no pueden manipular lo que queremos\n",
      "Solo por instinto es que vamos al extremo\n",
      "Y nos multiplicamos por contagio y sin deseo\n",
      "\n",
      "Y no pueden tolerar\n",
      "Que nos resbale el poder\n",
      "Y con su falsa moral\n",
      "Nunca podrán someternos\n",
      "\n",
      "Porque este virus letal\n",
      "Les roba su identidad\n",
      "Igual eso era normal\n",
      "Antes de aparecernos\n",
      "\n",
      "Somos su imagen más real\n",
      "Lo que nunca esperaron ver\n",
      "Su reflejo más aterrador\n",
      "Que los habrá de convencer\n",
      "Que hay poco por hacer en este apocalipsis\n",
      "\n",
      "Zombi filmando su propia sombra\n",
      "Zombi aplaudiendo al zombi de moda\n",
      "Zombi autómata, zombi mediático\n",
      "Zombi viral, zombi superstar\n",
      "Zombi que mira a otro zombi sin alma\n",
      "Que le dice desde la pantalla\n",
      "\n",
      "No seas así, dejate morder\n",
      "\n",
      "Somos su imagen más real\n",
      "Lo que nunca esperaron ver\n",
      "Su reflejo más aterrador\n",
      "Que los habrá de convencer\n",
      "Que hay poco por hacer en este apocalipsis zombi\n",
      "\n",
      "No seas así, dejate morder\n",
      "No seas así, dejate morder\n",
      "\n",
      "Agregar a la playlist\n",
      "Tamaño\n",
      "A\n",
      "A\n",
      "Cifrado\n",
      "Imprimir\n",
      "Corregir\n",
      "Nada por aquí, nada por allá\n",
      "Nada que decir, nada que explicar\n",
      "Hoy no me va a ver ni el Sol\n",
      "Nada que mostrar, nada que fingir\n",
      "Nada que juzgar, nada que eludir\n",
      "Hoy nadie va a oír mi voz\n",
      "\n",
      "Tantas luces, tantas miradas\n",
      "¿Qué tienen tanto para mirar?\n",
      "Tanta oscuridad, tanta oscuridad\n",
      "\n",
      "Porque es cierto, que me siento invisible\n",
      "Las veces que prefiero que me puedan ver\n",
      "Y en el fondo, solo busco que me encuentren\n",
      "Las veces que prefiero desaparecer\n",
      "\n",
      "Siento el poder de ver sin ser visto\n",
      "Cuando nadie se fija en mí es\n",
      "Cuando sé que existo\n",
      "No soy Mefisto (¡eh!)\n",
      "Ni el Anticristo (¡ah!)\n",
      "\n",
      "No me oculto por placer sino por necesidad\n",
      "Como Houdini, impredecible\n",
      "Sin magia ni hechizo me vuelvo invisible\n",
      "Y cavo impasible la trinchera de mi guerra\n",
      "Suplicando: ¡Trágame tierra!\n",
      "\n",
      "Puedo ser real, puedo ser ficción\n",
      "Solo material o solo ilusión\n",
      "Pero tengo el control\n",
      "\n",
      "Y aunque sé que nunca lo voy a ver\n",
      "Sé que hay alguien más que debe tener\n",
      "La misma intención que yo\n",
      "\n",
      "Lo esencial no lo ven los ojos, por eso hay días que elijo no estar\n",
      "\n",
      "Y esa es mi verdad, y esa es mi verdad\n",
      "\n",
      "Porque es cierto, que me siento invisible\n",
      "Las veces que prefiero que me puedan ver\n",
      "Y en el fondo, solo busco que me encuentren\n",
      "Las veces que prefiero desaparecer\n",
      "\n",
      "Me he acostumbrado a ser transparente\n",
      "Entre la multitud que no me ve aunque esté presente\n",
      "\n",
      "Y que me siento ausente solo cuando me esfumo\n",
      "Envuelto en mi bomba de humo\n",
      "Me describió Wells, me pintó Dalí\n",
      "Pero nadie entiende porque soy así\n",
      "Si preguntan cómo hago, nadie contesta\n",
      "¡No todo tiene respuesta!\n",
      "\n",
      "Porque es cierto, que me siento invisible\n",
      "Las veces que prefiero que me puedan ver\n",
      "Y en el fondo, solo busco que me encuentren\n",
      "Las veces que prefiero desaparecer\n",
      "Las veces que prefiero desaparecer\n",
      "Las veces que prefiero desaparecer\n",
      "No lo nombren, no\n",
      "\n",
      "Toquen madera y quemen benjuí\n",
      "Miren quien se acerca, miren quien viene ahí\n",
      "Es él, el yeta, el que agita avisperos\n",
      "El que todos dicen que es un pájaro de mal agüero\n",
      "\n",
      "Su presencia arruina cualquier celebración\n",
      "Y siempre al invocarlo una desgracia sucedió\n",
      "Dicen que es así, que así fue y será\n",
      "Y que atrae desastres como si fuera un I'mán\n",
      "\n",
      "Que no nos vea, ni que no nos toque\n",
      "Que a nadie se le ocurra saludar\n",
      "No vayan a gritar su nombre\n",
      "Porque llama a la fatalidad\n",
      "\n",
      "No lo nombren, no\n",
      "\n",
      "Todo lo que toca lo echa a perder\n",
      "Igual que el rey midas, pero al revés\n",
      "Fue el, lo acusan cuando pasa algo grave\n",
      "Pero lo cierto es que en verdad nadie sabe si él sabe\n",
      "\n",
      "Cuando su fama comenzó? Como el rumor se propagó?\n",
      "Quién fue el primero que lo estigmatizó?\n",
      "Porque una vez marcado siempre lo señalarán\n",
      "Quien se hace piedra, piedra morirá\n",
      "\n",
      "Toda la vida cargará ese peso\n",
      "Y ese peso acabará con él\n",
      "Y un poco en broma un poco en serio\n",
      "Será el blanco de una risa cruel\n",
      "\n",
      "No lo nombren, no\n",
      "\n",
      "No tiene explicación y es anti-racional\n",
      "Como en la inquisición, cazando brujas por cazar\n",
      "Y quién dice que no,que uno no será también\n",
      "Sin justificación, otro innombrable a quien temer\n",
      "\n",
      "Escondemos en un saco roto\n",
      "La cobardía de no aceptar\n",
      "Cargándole la culpa a otros\n",
      "De las cosas que nos salen mal\n",
      "\n",
      "No lo nombren, no\n",
      "Tranquilo, ya sé que estás en un lío\n",
      "Y que todo es hastío, sombrío, vacío, y el frío te parte\n",
      "Vine para ayudarte y le traje un masaje a tu alma, un vendaje a tu orgullo\n",
      "Un arrullo que aquiete tu alto voltaje\n",
      "\n",
      "Aquí estoy para apaciguarte, y tratar de que mi voz y mi presencia te impulsen\n",
      "La paciencia tiene la raíz amarga pero da frutos dulces\n",
      "\n",
      "Calma vladimir, son cosas que pasan\n",
      "Respira bien hondo y mantené la calma\n",
      "Calma vladimir, no pierdas el tino\n",
      "Para razonar hay que estar tranquilo\n",
      "\n",
      "Es feo, creéme que te creo, ese olor a nada, el deseo en cero\n",
      "Y sentís que es un placebo lo que ves y oís por ahí\n",
      "Y decís, que nadie te quiere asistir, que nadie te puede entender\n",
      "Que es fácil hablar con cordura sin estar en tu piel\n",
      "\n",
      "Vine para darle a tu espíritu un mensaje que lo relaje y lo tranquilice\n",
      "Uno es dueño de lo que calla pero esclavo de lo que dice\n",
      "\n",
      "Calma vladimir, son cosas que pasan\n",
      "Respira bien hondo y mantené la calma\n",
      "Calma vladimir, no pierdas el tino\n",
      "Para razonar hay que estar tranquilo\n",
      "\n",
      "Pará de gritar, para de correr, no dramatices\n",
      "Poné tu infierno en el freezer para que tu ira exorcice\n",
      "Tan solo eso quise, pero no me dejás, me estás poniendo nervioso, me estás haciendo enojar\n",
      "No entendiste nada lo que te quise explicar\n",
      "\n",
      "La serenidad es lo único para aceptar lo que ya no puede cambiarse\n",
      "Y si se pierde en el camino habrá que gritar para salvarse\n",
      "\n",
      "Calma\n",
      "\n",
      "Calma vladimir, son cosas que pasan\n",
      "Respira bien hondo y mantené la calma\n",
      "Calma vladimir, no pierdas el tino\n",
      "Para razonar hay que estar tranquilo\n",
      "\n",
      "Calma vladimir\n",
      "Este gaucho no se agacha\n",
      "Con la frente en alto marcha\n",
      "Y ante cualquier situación\n",
      "No se rinde fácil no\n",
      "\n",
      "En la adversidad se agranda\n",
      "Y aunque no es de presumir\n",
      "Sabe que lleva el coraje en sus andas\n",
      "Ah, si, si, si\n",
      "\n",
      "Y abraza su libertad porque la supo perder\n",
      "Y la tierra que más ama es la tierra que lo vio nacer\n",
      "Cuando le toca sufrir, su valor lo hace crecer\n",
      "Contagia ese poder\n",
      "\n",
      "Todo el mundo sabe tengo el gaucho power\n",
      "Con él vivo y lucho\n",
      "Y lo llevo donde voy\n",
      "\n",
      "Cuando no hay escape uso el gaucho power\n",
      "No te acerques mucho\n",
      "Si te toco te lo doy\n",
      "\n",
      "Cuando siente que hay desprecio\n",
      "En la mirada de algún necio\n",
      "Él no le presta interés\n",
      "Porque él sabe bien quien es\n",
      "\n",
      "La tradición enciende el fuego\n",
      "Y no la ceniza gris\n",
      "Y así su llama flamea en el tiempo\n",
      "Así, si si, si\n",
      "\n",
      "No le importa disimular su rudeza y su altivez\n",
      "Cuando se arrodilla firme ante el amor de una mujer\n",
      "Y si alguien toca su honor, su garra habla por él\n",
      "Contagia ese poder\n",
      "\n",
      "Todo el mundo sabe tengo el gaucho power\n",
      "Con él vivo y lucho\n",
      "Y lo llevo donde voy\n",
      "\n",
      "Cuando no hay escape uso el gaucho power\n",
      "No te acerques mucho\n",
      "Si te toco te lo doy\n",
      "Y en la noche me guía la cruz del sur\n",
      "Soy toro en mi rodeo y torazo en ruedo ajeno\n",
      "No me encandila la luz mala\n",
      "Contagia ese poder\n",
      "\n",
      "Todo el mundo sabe tengo el gaucho power\n",
      "Con él vivo y lucho\n",
      "Y lo llevo donde voy\n",
      "\n",
      "Cuando no hay escape uso el gaucho power\n",
      "No te acerques mucho\n",
      "Si te toco te lo doy\n",
      "Ojos vinílicos, deseos elásticos\n",
      "Alma de acrílico, sonrisa de plástico\n",
      "Labios de melamina, besos virtuales\n",
      "Palabras de licra y caricias de látex\n",
      "\n",
      "Y con su voz de celofán dice que es su forma de poder enfrentar\n",
      "Sin armas autenticas (sin armas autenticas) a esta realidad sintética\n",
      "\n",
      "Tan real, tan común en su juego\n",
      "Tan artificial que no parece extraño\n",
      "Y así va con sus brazos de velcro\n",
      "Corazón de teflón y mirada de nylon\n",
      "\n",
      "Risa de cármica, lagrimas cínicas\n",
      "Pose de cámara, emociones químicas\n",
      "Planes de silicona, nervios de PVC\n",
      "Amores de neopreno y amigos.jpg\n",
      "\n",
      "Y con su andar de maniquí dice que es su forma de poder existir\n",
      "Sin gestos auténticos (sin gestos auténticos)\n",
      "En un entorno sintético\n",
      "\n",
      "Tan real, tan común en su juego\n",
      "Tan artificial que no parece extraño\n",
      "Y así va con sus brazos de velcro\n",
      "Corazón de teflón y mirada de nylon\n",
      "\n",
      "Cuidado que el fuego derrite ese plástico oh oh oh\n",
      "(Por que la pasión no se enciende con fósforos)\n",
      "(No, no, no, no)\n",
      "\n",
      "Tan real, tan común en su juego\n",
      "Tan artificial que no parece extraño\n",
      "Y así va con sus brazos de velcro\n",
      "Corazón de tefrón y mirada de nylon\n",
      "\n",
      "Cuidado que el fuego derrite ese plástico oh oh oh\n",
      "Hay unas verdades que mejor no demostrar\n",
      "Lo que le presté a la vida, la vida me pagará\n",
      "Y todo lo que di, para bien o para mal\n",
      "De la misma manera me lo devolverá\n",
      "\n",
      "Mi madre me decía que no hay peor dolor\n",
      "Que cuando el amor se vuelve odio, y el odio, temor\n",
      "Y que quien hizo mal irá de mal en peor\n",
      "Y que es más feliz el que más amó\n",
      "\n",
      "Y es que todo vuelve, como un eco, sin ruido ni voz\n",
      "Yo camino siguiendo a mi corazón\n",
      "\n",
      "Ah, sembrando un beso\n",
      "Ah, guardando el arma\n",
      "Ah, adiós destino\n",
      "Ah, hola karma\n",
      "\n",
      "Nadie escapa de sí mismo, adonde vaya ahí estaré\n",
      "Cada acción me condiciona aunque no lo quiera ver\n",
      "Libre de elegir, libre de escoger\n",
      "Con cada decisión decido quien quiero ser\n",
      "\n",
      "Abrazo mis valores cuando me toca cambiar\n",
      "Es con el universo mi forma de negociar\n",
      "Y dice la ley que aunque no se mire atrás\n",
      "Al que sembró viento le espera una tempestad\n",
      "\n",
      "Y es que todo vuelve, como un eco, sin ruido ni voz\n",
      "Yo camino siguiendo a mi corazón\n",
      "\n",
      "Ah, sembrando un beso\n",
      "Ah, guardando el arma\n",
      "Ah, adiós destino\n",
      "Ah, hola karma\n",
      "\n",
      "Cada paso, cada huella que dejamos atrás\n",
      "Son como una cuerda vibrando en la eternidad\n",
      "Sin miedo a perderme ni a cambiar de dirección\n",
      "Yo camino siguiendo a mi corazón\n",
      "\n",
      "Ah, sembrando un beso\n",
      "Ah, guardando el arma\n",
      "Ah, adiós destino\n",
      "Ah, hola karma\n",
      "¿Hay alguien ahí?\n",
      "¿Hay alguien ahí?\n",
      "\n",
      "Acá estoy, otra vez\n",
      "Viéndome cambiar de piel\n",
      "Diciendo cosas que no siento\n",
      "Haciendo cosas sin querer\n",
      "\n",
      "Alguien debería atarme\n",
      "Alguien debería callarme\n",
      "Y llevarme a otro lugar\n",
      "Antes de que sea demasiado tarde\n",
      "\n",
      "Sé que ya volveré a la tranquilidad\n",
      "Y que me espera un día de calma y paz\n",
      "Pero también sé que nunca estaré\n",
      "Libre del animal preso en mi ser\n",
      "Porque cualquier frase o gesto hostil\n",
      "Logran poner fuera de sí, a la bestia que hay en mí\n",
      "\n",
      "(La bestia que hay en mí)\n",
      "(¿Hay alguien ahí?)\n",
      "\n",
      "Y aunque no me crezcan garras\n",
      "Ni colmillos me aparezcan\n",
      "Y que no me cubra la bruma\n",
      "Ni esté aullándole a la luna\n",
      "\n",
      "Alguien debería frenarme\n",
      "Alguien debería encerrarme\n",
      "Porque puedo lastimar\n",
      "Y ser peligroso aunque no corra sangre\n",
      "\n",
      "Sé que ya volveré a la tranquilidad\n",
      "Y que me espera un día de calma y paz\n",
      "Pero también sé que nunca estaré\n",
      "Libre del animal preso en mi ser\n",
      "Porque cualquier frase o gesto hostil\n",
      "Logran poner fuera de sí, a la bestia que hay en mí\n",
      "\n",
      "¡Bestia!\n",
      "¡Bestia! Alguien que me ayude a volver a ser yo\n",
      "¡Bestia! Alguien que me ayude a volver a ser yo\n",
      "¡Bestia! Alguien que me ayude a volver a ser yo\n",
      "\n",
      "Sé que ya volveré a la tranquilidad\n",
      "Y que me espera un día de calma y paz\n",
      "Pero también sé que nunca estaré\n",
      "Libre del animal preso en mi ser\n",
      "Porque cualquier frase o gesto hostil\n",
      "Logran poner fuera de sí a la bestia que hay en mí\n",
      "\n",
      "Alguien que me ayude a volver a ser yo\n",
      "Alguien que me ayude a volver a ser yo\n",
      "Alguien que me ayude a volver a ser yo\n",
      "Alguien que me ayude a volver a ser yo\n",
      "Alguien que me ayude a volver a ser yo (¡bestia!)\n",
      "Alguien que me ayude a volver a ser yo (¡bestia!)\n",
      "Alguien que me ayude a volver a ser yo (¡bestia!)\n",
      "Alguien que me ayude a volver a ser yo (¡bestia!)\n",
      "\n",
      "¡¿Hay alguien ahí?!\n",
      "Le puse un nombre a mi inseguridad\n",
      "Le di una cara, ojos y una voz\n",
      "\n",
      "Cuando la invoco siempre acude a mi llamado\n",
      "Y así puedo hablarle y sentirme acompañado\n",
      "Cuando quedo frente a una decisión\n",
      "A veces pienso mucho\n",
      "\n",
      "Esto me pasa cuando pienso demasiado\n",
      "Esto me pasa cuando pienso de más (a veces pienso mucho oh-uh-oh-uh)\n",
      "Esto me pasa cuando pienso demasiado\n",
      "Esto me pasa cuando pienso de más (a veces pienso mucho oh-uh-oh-uh)\n",
      "\n",
      "Le puse un nombre a mi soledad\n",
      "A la nostalgia, al miedo y al dolor\n",
      "\n",
      "Y así cuando aparecen como sombras en mi espalda\n",
      "Puedo enfrentarlos solo sin escudo y sin espada\n",
      "Porque también le puse nombre a mi valor\n",
      "A veces pienso mucho (hah)\n",
      "\n",
      "Esto me pasa cuando pienso demasiado\n",
      "Esto me pasa cuando pienso de más (a veces pienso mucho oh-uh-oh-uh)\n",
      "Esto me pasa cuando pienso demasiado\n",
      "Esto me pasa cuando pienso de más\n",
      "\n",
      "Y así mis temores reconocí\n",
      "Los enfrente y pude dormir\n",
      "Los puedo nombrar y los puedo ver\n",
      "Les puedo hablar y los puedo oír\n",
      "\n",
      "Y así deje de huir y ser su rehén\n",
      "Y los bautice con los nombres que yo mismo les elegí\n",
      "Para que fueran como un talismán\n",
      "\n",
      "Que me protegieran del mal\n",
      "Que difícil es a veces comprender\n",
      "Quién es quién\n",
      "\n",
      "Esto me pasa cuando pienso demasiado\n",
      "Esto me pasa cuando pienso de más (a veces pienso mucho oh-uh-oh-uh)\n",
      "Esto me pasa cuando pienso demasiado\n",
      "Esto me pasa cuando pienso de más (a veces pienso mucho oh-uh-oh-uh)\n",
      "Parece que por fin el cielo esta aclarando\n",
      "Parece que el camino al fin se enderezó\n",
      "Siento a la fortuna andando a mi lado\n",
      "Jugando a mi favor\n",
      "\n",
      "Y las piedras con que tropecé, hoy solo arena son\n",
      "Y la lluvia que me cegaba ya paró y se convirtió, en luz\n",
      "\n",
      "Así que hoy me quiero sentir, libre de celebrar\n",
      "Por si mañana no tengo de nuevo al rey y al as\n",
      "Pero esta partida sin fin ¿cuánto puede durar?\n",
      "Solo la luna sabe cuanto cuanto cuanto más\n",
      "\n",
      "La suerte nunca apunta pero da en el blanco\n",
      "Y el blanco es el que menos la esperó\n",
      "Y muchas veces puede hacernos pagar caro\n",
      "Lo que creemos que nos regaló\n",
      "\n",
      "Por eso cuando cambia la pisada\n",
      "No me pongo a cuestionar\n",
      "Porque antes de cambiar de nuevo\n",
      "Nunca me lo va a avisar\n",
      "\n",
      "Así que hoy me quiero sentir, libre de celebrar\n",
      "Por si mañana no tengo de nuevo al rey y al as\n",
      "Pero esta partida sin fin, ¿cuánto puede durar?\n",
      "Solo la luna sabe cuanto cuanto cuanto más\n",
      "Cuanto más, cuanto más, cuanto más\n",
      "\n",
      "Dicen que lo que ha de suceder, entonces sucederá\n",
      "Pero es dueño de su destino, quien nada espera del azar\n",
      "Y aunque me cueste creer que todo tiene una razón\n",
      "La suerte es un desenlace pero no una explicación\n",
      "\n",
      "Así que hoy me quiero sentir, libre de celebrar\n",
      "Por si mañana no tengo de nuevo al rey y al as\n",
      "Pero esta partida sin fin ¿cuánto puede durar?\n",
      "Solo la luna sabe cuanto cuanto cuanto más\n",
      "Cuanto más, cuanto más, cuanto más\n",
      "Con ella\n",
      "Estoy adicto a su sexy amor\n",
      "Para mi en su velar, me hace alucinar\n",
      "Soy un convicto de tu amor\n",
      "Y es que te beso en la cocina\n",
      "Te hago el amor en la oficina\n",
      "No logro evitar, voy a penetrar\n",
      "Ese arcoiris me fascina\n",
      "\n",
      "Suben, mis labios quieren subir hasta tus caderas\n",
      "Mis labios quieren bajar, hasta tu pecera\n",
      "Mami soy un adicto de tu amor, no lo puedo negar\n",
      "Eres mi pasión, eres mi obsesión\n",
      "Eres tu mi adicción, eres tu mi sol\n",
      "Soy adicto de tu amor, no lo puedo negar\n",
      "Soy adicto de tu amor\n",
      "\n",
      "Eres mi pasión, eres mi obsesión\n",
      "Eres tu mi adicción, eres tu mi sol\n",
      "Addict, no lo puedo negar\n",
      "Addict\n",
      "Que manera hermosa como muerdes\n",
      "Hay algo de sexy en tu mirar\n",
      "Soy como un volcán y tu falda cae\n",
      "Estamos empapados en amor\n",
      "\n",
      "Suben, mis labios quieren subir hasta tus caderas\n",
      "Mis labios quieren bajar, hasta tu pecera\n",
      "Mami soy un adicto de tu amor, no lo puedo negar\n",
      "Eres mi pasión, eres mi obsesión\n",
      "Eres tu mi adicción, eres tu mi sol\n",
      "Soy adicto de tu amor, no lo puedo negar\n",
      "Soy adicto de tu amor\n",
      "\n",
      "Eres mi pasión, eres mi obsesión\n",
      "Eres tu mi adicción, eres tu mi sol\n",
      "Addict, no lo puedo negar\n",
      "Te amaría noche y día\n",
      "Te amaría de por vida\n",
      "Es una adicción\n",
      "No lo puedo negar!\n",
      "No lo puedo negar\n",
      "\n",
      "Eres mi pasión, eres mi obsesión\n",
      "Eres tu mi adicción, eres tu mi sol\n",
      "No lo puedo negar, no lo puedo negar\n",
      "Adicción, obsesión, adicción\n",
      "Pierdo, pierdo la razón\n",
      "Se que soy adicto\n",
      "Adicto de tu amor\n",
      "No lo puedo negar\n",
      "Incendiado estoy\n",
      "Pretty baby desolado estoy\n",
      "Incendiado\n",
      "It's connection\n",
      "Y seducir sabes incendiar\n",
      "Eres una adivina en la conexion\n",
      "It's connection\n",
      "Y sé que besa rico allá con otro chico\n",
      "I saw you con otro wey, no, and that's not right\n",
      "No, no, no that's no right\n",
      "\n",
      "Me tienes, me tienes, me tienes\n",
      "La cama incendiada en el fuego de tu amor\n",
      "Y sin dormir\n",
      "Estoy alucinado mi amor\n",
      "Y no puedo más, más, más\n",
      "No importan tus engaños\n",
      "Te extraño y no puedo sin ti\n",
      "La cama incendiada sin ti\n",
      "\n",
      "Mi gatita, mi pasión, mi respiración\n",
      "Regrésame en los labios de tu conexión\n",
      "It's connection\n",
      "Labios, labios que tienes, tienes tú\n",
      "Labios, labios que tienes en el sur\n",
      "Labios al sur del ombligo en el sur\n",
      "\n",
      "Y sé que besa rico allá con otro chico\n",
      "I saw you con otro wey, no, and that's not right\n",
      "No, no, no that's not right\n",
      "Me tienes, me tienes, me tienes\n",
      "La cama incendiada en el fuego de tu amor\n",
      "Y sin dormir\n",
      "Estoy alucinado mi amor\n",
      "Y no puedo más, más, más\n",
      "No importan tus engaños\n",
      "Te extraño y no puedo sin ti\n",
      "La cama incendiada sin ti\n",
      "\n",
      "La cama, la cama\n",
      "La cama incendiada y yo alucinado\n",
      "Angustiado estoy, amor, y sin dormir\n",
      "Estoy desesperado mi amor\n",
      "Extrañándote a murir\n",
      "No, no, no, no\n",
      "No importan tus engaños\n",
      "Te extraño y no puedo sin ti\n",
      "La cama incendiada sin ti\n",
      "La cama incendiada sin ti\n",
      "Sin ti yo no puedo vivir\n",
      "No, no\n",
      "\n",
      "It's connection\n",
      "It's connection\n",
      "It's connection\n",
      "No regreso a tu cárcel\n",
      "No regreso a tu prisión\n",
      "A la opresión\n",
      "Que por miedo a perderte\n",
      "El silencio me invadió\n",
      "Y mi vida encarceló\n",
      "Quiero ahogarme en\n",
      "Otros labios, en otro sol, liberación\n",
      "Voy a liberarme, voy a rescatarme\n",
      "No regreso a tu prisión\n",
      "\n",
      "No, no, no mi amor\n",
      "No, no, no regreso a tu cárcel\n",
      "Oh no, no mi amor\n",
      "No, no, no regreso a tu cárcel\n",
      "No regreso corazón, a la prisión, no volveré\n",
      "Voy a liberarme hoy\n",
      "Uoh, uoh, yeah\n",
      "\n",
      "Fui cayendo en la demencia con la urgencia\n",
      "De escapar para no volver jamás\n",
      "Ya no aguanto las paredes\n",
      "Ni las redes ni el control\n",
      "No soporto tu prisión\n",
      "Quiero ahogarme en otro\n",
      "Labios, en otro sol, liberación\n",
      "Voy a liberarme, voy a rescatarme\n",
      "No regreso a tu prisión\n",
      "\n",
      "No, no, no mi amor\n",
      "No, no, no regreso a tu cárcel\n",
      "No, no, no mi amor\n",
      "No, no, no regreso a tu cárcel\n",
      "No regreso corazón\n",
      "A la prisión\n",
      "No volveré\n",
      "Voy a liberarme hoy\n",
      "Uoh, uoh, yeah\n",
      "\n",
      "No mi amor\n",
      "Jamás regreso a tu cárcel no\n",
      "No regreso corazón\n",
      "A la prisión\n",
      "No volveré\n",
      "A tu cárcel no\n",
      "Voy a liberarme hoy\n",
      "Uoh, uoh, yeah\n",
      "\n",
      "No regreso a tu prisión, oh no\n",
      "No regreso a tu prisión\n",
      "No regreso a las paredes\n",
      "A las redes, al control\n",
      "No mi amor\n",
      "Qué ironía de la vida el amor que duele noche y día\n",
      "Que te alegra en abundancia o te quiebra del dolor\n",
      "Ahora que no vas a andar conmigo\n",
      "Ahora que solo seré tu amigo\n",
      "Ilumina la distancia, ilumíname el dolor\n",
      "Cómo olvidar, cómo regresar\n",
      "Qué ironía del amor\n",
      "\n",
      "Qué ironía si es la vida inundada de dolor\n",
      "El amor glorifico, el amor nos arrancó\n",
      "Tantas risas tanto llanto\n",
      "¿Qué le lloro? ¿qué le canto? Que nos va a matar\n",
      "Qué ironía que manera de llorar, por un amor\n",
      "Y en mis tristes manos, guardo el vacío de tu olor\n",
      "Y tan solo espero ya mi amor, amanecer\n",
      "\n",
      "Como el cielo y el infierno\n",
      "Tu amor que hiere y que es muy tierno\n",
      "Estoy tan lleno de tu vida y vacío de tu amor\n",
      "Y es que es absurdo estando enamorados\n",
      "Que triste amor estar así de separados\n",
      "Y perdona la insistencia pero muero del dolor\n",
      "Cómo olvidar, cómo regresar\n",
      "Qué ironía del amor ehhh\n",
      "\n",
      "Qué ironía si es la vida inundada de amor\n",
      "El amor glorificó, el amor nos condenó\n",
      "Uno ama pa estar vivo y uno muere en el vacío\n",
      "En las guerras del amor\n",
      "Qué ironía, que manera de quebrarse amor\n",
      "Y en mis tristes manos, guardo el vacío de tu olor\n",
      "Y solo espero ya mi amor\n",
      "\n",
      "Amanecer, guardas el secreto del amor\n",
      "Sigo yo abrazando la esperanza,\n",
      "Abrazando la demencia, qué ironía de la vida,\n",
      "Amanecer, ¿cuál es el secreto del amor?\n",
      "Sigo en la esperanza o será pura demencia,\n",
      "Qué le voy a hacer, ¿cuál es el secreto del amor?\n",
      "Hay mentiras en los labios\n",
      "Hay mentiras en la piel\n",
      "¡Qué dolor!\n",
      "\n",
      "Hay mentiras, hay amantes\n",
      "Que por instantes de placer\n",
      "Ponen su vida a temblar\n",
      "\n",
      "Hay mentiras compasivas\n",
      "Hay mentiras por piedad\n",
      "Que no quieren lastimar\n",
      "\n",
      "Hay mentiras que nos hieren\n",
      "De verdad\n",
      "¡Ay, ay, ay!\n",
      "\n",
      "Y hay engaños que por años\n",
      "Ocultaron la verdad\n",
      "Haciendo mucho daño\n",
      "\n",
      "Ay, yo me voy a refugiar\n",
      "A la tierra de tu amor\n",
      "Mi verdad\n",
      "\n",
      "Tú eres mi amor, mi alegría\n",
      "La verdad de mi vida\n",
      "Mi bebé que me salta a los brazos, de prisa\n",
      "Tú eres mi refugio y mi verdad\n",
      "\n",
      "Oh, yeah\n",
      "\n",
      "Tú eres mi amor, mi alegría\n",
      "La verdad de mi vida\n",
      "Mi bebé que me calma el alma con risas\n",
      "Tú eres mi refugio y mi verdad\n",
      "\n",
      "Hay mentira en la mirada\n",
      "Hay mentiras en la piel\n",
      "Dibujadas\n",
      "\n",
      "Hay mentiras, hay amantes\n",
      "Que por instantes de placer\n",
      "Ponen su vida a temblar\n",
      "\n",
      "Hay doctrinas y oradores\n",
      "Dictadores sin piedad\n",
      "Que gobiernan sin verdad\n",
      "\n",
      "Y hay mentiras en los diarios\n",
      "En las redes y en el bar\n",
      "¡Ay, ay, ay!\n",
      "\n",
      "Hay engaños que por años\n",
      "Ocultaron la verdad\n",
      "Hiriendo de dolor\n",
      "\n",
      "Ay, yo me voy a refugiar\n",
      "Al oasis de tu amor\n",
      "\n",
      "Tú eres mi amor, mi alegría\n",
      "La verdad de mi vida\n",
      "Mi bebé que me salta a los brazos, de prisa\n",
      "Tú eres mi refugio y mi verdad\n",
      "\n",
      "Oh, yeah\n",
      "\n",
      "Tú eres mi amor, mi alegría\n",
      "La verdad de mi vida\n",
      "Mi bebé que me calma el alma con risas\n",
      "Tú eres mi refugio y mi verdad\n",
      "\n",
      "(¡Ay, Dios santo!)\n",
      "\n",
      "En un mundo tan irreal\n",
      "No sé en qué creer\n",
      "(Sé, oh)\n",
      "Y, amor, sé que tú eres mi verdad\n",
      "Eres mi verdad\n",
      "\n",
      "Tú eres la luz de mi vida\n",
      "Tú eres la voz que me calma\n",
      "Tú eres la lluvia de mi alma\n",
      "Y eres toda mi verdad\n",
      "\n",
      "Tú eres la luz de mi vida\n",
      "Tú eres la voz que me calma\n",
      "Tú eres la lluvia de mi alma\n",
      "Y eres toda mi verdad\n",
      "\n",
      "Y eres toda mi verdad\n",
      "Solo quiero vivir en tus playas, tu mar\n",
      "Trátame con mucho amor, yo no quiero sufrir\n",
      "Y solo quiero hundirme en tu agua de mar\n",
      "Hundirme en tu placer, piel canela, piel de mar\n",
      "Mueve tu cuerpo te va a gustar\n",
      "Mueve tu cuerpo te va a gustar\n",
      "Habré tu cuerpo que te voy a dar\n",
      "Amor!\n",
      "\n",
      "Ay amor, que delicia, amanecer con tu sonrisa hoy\n",
      "Te amo tanto piel canela, dame suavecito amor\n",
      "Mi amorcito si curas y sanas tanto dolor del corazón\n",
      "Te lo pido, te lo digo, suavecito, suavecito, suavecito\n",
      "Solo quiero un beso de bajo del mar\n",
      "Y bailame suave amor, suavecito en el mar\n",
      "Yo solo quiero mojarme de tu húmeda\n",
      "Mojarme de tu placer piel canela, piel de mar\n",
      "\n",
      "Mueve tu cuerpo te va a gustar\n",
      "Mueve tu cuerpo te va a gustar\n",
      "Habré tu cuerpo que te voy a dar\n",
      "Amor!\n",
      "\n",
      "Ay amor, que delicia, amanecer con por tu sonrisa hoy\n",
      "Te amo tanto piel canela, dame suavecito amor\n",
      "Mi amorcito si curas y sanas tanto dolor del corazón\n",
      "Te lo pido, te lo digo, suavecito\n",
      "Por ahí por allá, como baila la morena, esa reina\n",
      "No paren el ritmo que baila super rico, esa reina\n",
      "Por ahí por allá, como baila la morena, esa reina\n",
      "No paren el ritmo que baila super rico, esa reina\n",
      "\n",
      "En puerto rico, por ahí por allá\n",
      "Habré tu cuerpo que te voy a dar amor\n",
      "Dame suave tus labios de mar\n",
      "Y dame suave todo mi morena\n",
      "Dame suave otro besito y de\n",
      "A poquito borrar las penas\n",
      "Estaba hundido, estaba en\n",
      "El olvido y hoy bañado de tu amor\n",
      "De corazón te lo pido, suavecito, suavecito, suavecito\n",
      "\n",
      "Te mueves suavecito\n",
      "Te mueves suavecito\n",
      "Te mueves suavecito\n",
      "Te mueves suavecito\n",
      "Por qué lloras mi amor\n",
      "Qué te fluye en la piel\n",
      "Te despiertas en el llanto\n",
      "Con espantos de dolor\n",
      "\n",
      "Son los monstruos del ayer\n",
      "Son tus miedos corazón\n",
      "Sabes bien que yo te amo\n",
      "Y te pido que tengas fe\n",
      "\n",
      "No sufras más por mi bebé\n",
      "Eres la mariposa\n",
      "Que vuela hacia el huracán\n",
      "Cuéntame de tu pesar\n",
      "Suelta todo tu dolor, dímelo\n",
      "\n",
      "Aaaaaaaaaa amor\n",
      "Un huracán y una mariposa\n",
      "Llegan se dan la cara\n",
      "En medio de la mar\n",
      "\n",
      "Lluvia de esperanza\n",
      "Lluvia al corazón\n",
      "Siempre ahí estaré\n",
      "No te fallaré\n",
      "Desde el cielo lluvia al corazón\n",
      "Sol que lanza la esperanza\n",
      "La esperanza y la luz\n",
      "No importa lo que pase\n",
      "No importa jamás no no\n",
      "Lluvia al corazón\n",
      "\n",
      "Fluye la desilusión\n",
      "Muda desesperación\n",
      "Pero todo tiene alivio\n",
      "Menos el decir adiós\n",
      "\n",
      "Y si te vas así yo moriré\n",
      "Y te amarras a tu piano\n",
      "Y te vas al altamar\n",
      "Y te quieres escapar\n",
      "Y te quieres diluir\n",
      "No mi amor\n",
      "\n",
      "Aaaaaaaaaa amor\n",
      "Un huracán y una mariposa\n",
      "Llegan se dan la cara\n",
      "En medio de la mar\n",
      "\n",
      "Lluvia de esperanza\n",
      "Lluvia al corazón\n",
      "Siempre ahí estaré\n",
      "No te fallaré\n",
      "Desde el cielo lluvia al corazón\n",
      "Sol que lanza la esperanza\n",
      "La esperanza y la luz\n",
      "No importa lo que pase\n",
      "No importa jamás no no\n",
      "Lluvia al corazón\n",
      "\n",
      "La esperanza al corazón\n",
      "La esperanza al corazón\n",
      "Que te sane que te alivie el dolor\n",
      "No importa lo que pase\n",
      "No importa jamás no no\n",
      "Lluvia al corazón\n",
      "Eres inevitable, amor\n",
      "Casi como respirar\n",
      "Casi como respirar\n",
      "\n",
      "Llegué a tus playas impuntual\n",
      "Pero no me rendiré\n",
      "Soy tu amor clandestino\n",
      "Soy el viento sin destino\n",
      "Que se cuela en tu faldas mi amor\n",
      "Un soñador, un clandestino\n",
      "Que se juega hasta la vida mi amor\n",
      "Clandestino, amada, amada amor\n",
      "\n",
      "No, no no no\n",
      "\n",
      "Mi amor clandestino en el silencio, el dolor\n",
      "Se nos cae todo el cielo de esperar\n",
      "Inevitable casi como respirar\n",
      "Se nos cae todo el cielo\n",
      "De tanto esperar\n",
      "Clandestino\n",
      "\n",
      "El universo conspiró inevitable corazón\n",
      "Clandestino eterno amor\n",
      "\n",
      "Pero me duele no gritar tu nombre en toda libertad\n",
      "Bajo sospecha hay que callar\n",
      "\n",
      "Y te sueño piel con piel\n",
      "Ahogado en besos y tus risas amor\n",
      "Y me hundo en el calor\n",
      "Que hay en tus muslos, en tu mar\n",
      "Llorando en silencio, temblando tu ausencia\n",
      "Rogándole al cielo y finjiendo estar muy bien\n",
      "\n",
      "No, no no no\n",
      "\n",
      "Mi amor clandestino en el silencio, el dolor\n",
      "Se nos cae todo el cielo de tanto esperar\n",
      "Inevitable caasi como respirar\n",
      "Se nos cae todo el cielo\n",
      "De tanto esperar\n",
      "Clandestino\n",
      "\n",
      "No te engañes más, ya no te mientas\n",
      "Si aire ya pasó, ya pasó\n",
      "Y verdad ya no tengas miedo\n",
      "Sólo tu mantienes mi respiración\n",
      "\n",
      "Hace tanto que yo esperaba al viento, amor\n",
      "Cae el llanto del cielo de esperar\n",
      "Hace tanto que yo esperé tu luz, amor\n",
      "Ay amor, ay amor, ¡ay amor!\n",
      "\n",
      "Se nos cae todo el cielo\n",
      "Se nos cae todo el cielo de tanto esperar\n",
      "Mi amor, ya no te engañes\n",
      "No te mientas corazón\n",
      "Se nos cae todo el cielo\n",
      "Entiéndelo, amor\n",
      "Vas por el mundo destrozando corazones\n",
      "Podrás tener más de mil hombres a tus pies\n",
      "Pero mi amor ya lo verás no lo repones\n",
      "Óyeme nena tú mi reina te me vas a volar\n",
      "\n",
      "Cuando me vaya empezarás a valorarme\n",
      "Amor del bueno nunca es fácil encontrar\n",
      "De ti mi vida ya no vuelvo a enamorarme\n",
      "Vete al infierno y te me pintas a volar\n",
      "\n",
      "Prefiero solo que atado, mi reina del dolor\n",
      "Prefiero solo que engañado, que tengas suerte amor\n",
      "Te digo adiós, bye bye,\n",
      "Mi reina del dolor\n",
      "\n",
      "Hoy me pregunto por qué quieres humillarme\n",
      "Nunca me amaste por favor déjame en paz\n",
      "Y aunque me pidas de rodillas voy a amarte\n",
      "Hoy me di cuenta de mi triste realidad\n",
      "Hoy me di cuenta de mi error\n",
      "Lo sé mi reina del dolor\n",
      "\n",
      "Prefiero solo que atado, mi reina del dolor\n",
      "Prefiero solo que engañado, que tengas suerte amor\n",
      "Te digo adiós, bye bye,\n",
      "Mi reina del dolor\n",
      "\n",
      "No me hieras más\n",
      "No mi amor\n",
      "Mi sirena del dolor\n",
      "Hoy me doy cuenta del vacío quedas ya en el olvido\n",
      "Prefiero solo que engañado mi reina del amor\n",
      "\n",
      "Y aunque me implores y me llores jamás yo volveré\n",
      "Y aunque me pidas de rodillas jamás yo volveré\n",
      "Te digo adiós, bye bye,\n",
      "Mi reina del dolor\n",
      "\n",
      "No me hieras más no mi amor\n",
      "Mi sirena del dolor\n",
      "\n",
      "Prefiero solo que engañado mi reina del dolor\n",
      "Mi reina del dolor\n",
      "Con duda yo pensaba si lo haría\n",
      "Si era vida ahi de regreso\n",
      "El espejo seductor en su reflejo lo tenía que cruzar\n",
      "Lo toco con la punta mi miedo\n",
      "Que se hunde en el mercurio, del cristal\n",
      "Lo cruzo y lo dejo a mis espaldas\n",
      "No hay regreso es tan fatal\n",
      "\n",
      "Quede atrapado\n",
      "En un espejo azul\n",
      "Que voy a hacer dios mio\n",
      "Estoy perdiendo la razón\n",
      "Quede atrapado\n",
      "Quede fundido\n",
      "En otro tiempo\n",
      "En otra dimensión\n",
      "\n",
      "Voy caminando por el hall\n",
      "Del monasterio medieval\n",
      "El padre aurelio me instruyó, bienvenido pase ya\n",
      "Todo lo que vea es de usted se lo voy a regalar\n",
      "Me dijo el cura sin piedad usted pudo llegar hasta aquí y jamas podrá\n",
      "Escapar\n",
      "Uooohhh uooohh\n",
      "Por pecar y blasfemar\n",
      "Uooohhh uooohh\n",
      "Con la vida pagarán\n",
      "\n",
      "Quede atrapado\n",
      "En un espejo azul\n",
      "Que voy a hacer dios mio\n",
      "Estoy perdiendo la razón\n",
      "Quede atrapado\n",
      "Quede fundido\n",
      "En otro tiempo\n",
      "En otra dimensión\n",
      "\n",
      "Cayendo, huyendo\n",
      "Están equivocados\n",
      "Maligno, mezquino, me grita un fraile bizantino\n",
      "Y en el río\n",
      "La jauría de los frailes me seguía\n",
      "Me atraparon, me golpearon\n",
      "De regreso a la abadía\n",
      "Y en el patio del convento exorcistas me gritaban\n",
      "No hay remedio, a la hoguera, no lo hagan no\n",
      "\n",
      "No me maten por piedad (nooo)\n",
      "No me maten por piedad (nooo)\n",
      "No me maten por favor (nooo)\n",
      "No por piedad (nooo)\n",
      "Quedé atrapado\n",
      "Detrás del muro en un convento\n",
      "Hay un sueño en la piel\n",
      "Sor maría se disfraza como el viento\n",
      "Sueña y vuela va con él\n",
      "\n",
      "Sor María encerrada\n",
      "Le prohibieron libertad\n",
      "Las hermanas le advirtieron con espanto\n",
      "Es pecado enamorarse\n",
      "Es virtud la castidad\n",
      "\n",
      "Se lo dijo el padre aurelio\n",
      "Sor maría pliega el vuelo\n",
      "Hija mía ponte en paz\n",
      "Ella dijo ya no puedo padre aurelio\n",
      "Si la luz entra en el agua\n",
      "Se le olvida el cielo\n",
      "\n",
      "Una mujer enamorada decidida\n",
      "Pasma el aire el universo y la razón\n",
      "Si la luz entra en el agua\n",
      "Olvida el cielo\n",
      "Va con un sueño en la piel\n",
      "\n",
      "Hablando sola con su sombra\n",
      "Inventando estar con él\n",
      "Suelta un beso en el aire y lo nombra\n",
      "Labios llenos de su miel\n",
      "\n",
      "Sor maría enamorada sin remedio\n",
      "Trae ardiendo el corazón\n",
      "Está inundada de sus sueños\n",
      "De sus ganas\n",
      "Ignorarlo es contra natura\n",
      "Por piedad no me juzguen reventó\n",
      "\n",
      "Una mujer enamorada decidida\n",
      "Pasma el aire el universo y la razón\n",
      "Si la luz entra en el agua\n",
      "Olvida el cielo\n",
      "Va con un sueño en la piel\n",
      "\n",
      "En huída el padre aurelio\n",
      "Y sor maría fatal\n",
      "Los sorprendieron en pecado capital\n",
      "Los fusilaron a los dos\n",
      "Mano con mano hasta el final\n",
      "Como los árboles que mueren de pie\n",
      "\n",
      "Y se soñaba\n",
      "Con la luz de la mañana en la bañera\n",
      "Que le besa el vientre\n",
      "Y los labios y los pies\n",
      "Se sonroja y se le encienden\n",
      "Las mejillas\n",
      "Se murió con un sueño en la piel\n",
      "Con un sueño en la piel\n",
      "Te fuiste a un viaje a las estrellas\n",
      "Te fuieste al cielo mi amor\n",
      "Te hiciste luz bella de estrella\n",
      "Y yo aqui, me quede con dolor\n",
      "\n",
      "Tu eres mi angel de la guarda\n",
      "Que me cuida, que me aguarda\n",
      "Que esta dentro de mi\n",
      "\n",
      "Tu eres el arbol en el rio\n",
      "Y las flores de naranjo\n",
      "El ave que esta aqui\n",
      "\n",
      "No te olvido paloma\n",
      "Me haces falta mi vida\n",
      "Algun dia, yo te vere\n",
      "Ya no lloro paloma\n",
      "Ya no lloro mi vida\n",
      "Gracias por tanto amor\n",
      "\n",
      "Gracias a la vida por tenerte\n",
      "Guerrero de la luz del amor\n",
      "Tu cuerpo ya no pudo sostenerte\n",
      "Yo te voy a encontrar en el cielo mi amor\n",
      "\n",
      "Vuela, vuela libre mi paloma\n",
      "Vuela, vuela libre mi amor\n",
      "Tu luz y bendicion no me abandonan\n",
      "Si volviera a nacer seria contigo amor\n",
      "\n",
      "No lloro mi paloma\n",
      "Ya no lloro, no lloro pajarito mi amor\n",
      "Voy con la fe, y con la esperanza\n",
      "Porque te amo mi amor\n",
      "Y yo te voy a encontrar\n",
      "\n",
      "Quisiera estar contigo en la playa\n",
      "Y bailando despacito, tu mirada entrando en mi\n",
      "Te fuiste y llego la primavera\n",
      "Que le digo a tus rosales\n",
      "Que le digo al colibri\n",
      "\n",
      "No te olvido paloma\n",
      "Me haces fallta mi vida\n",
      "Algun dia, yo te vere\n",
      "Tengo el corazon inundado\n",
      "Corazon inundado\n",
      "Gracias por tanto amor\n",
      "\n",
      "Tu eres mi faro en la tormenta\n",
      "Que ilumina mis espacios de luz\n",
      "Tu eres angel vida\n",
      "Y en el cielo mi amor... Yo te voy a encontrar\n",
      "\n",
      "Vuela, vuela libre mi paloma\n",
      "Vuela, vuela libre mi amor\n",
      "Tu luz y bendicion no me abandonan\n",
      "Si volviera a nacer seria contigo amor\n",
      "\n",
      "No lloro mi paloma\n",
      "Ya no lloro, no lloro pajarito amor mio\n",
      "Voy con la fe, y con la esperanza\n",
      "Porque te amo mi amor\n",
      "Yo te voy a encontrar\n",
      "Va a amanecer\n",
      "Va a sanar\n",
      "No te me rindas mi vida\n",
      "Duerme esperando otro día\n",
      "Que saldrá el sol\n",
      "No te rindas amor\n",
      "Resistir al dolor\n",
      "Yo que te quiero a morir\n",
      "\n",
      "\n",
      "Voy a sembrar en tu herida una flor\n",
      "Yo trataré de curar\n",
      "Todo ese dolor\n",
      "Tenme fe corazón\n",
      "Esperanza y valor\n",
      "Yo que te quiero a morir\n",
      "\n",
      "\n",
      "Va a amanecer\n",
      "Va a sanar\n",
      "Te voy a curar\n",
      "Extrañas tanto tanto\n",
      "Pero aguanta corazón\n",
      "Tu soledad se va\n",
      "Te voy a curar\n",
      "\n",
      "\n",
      "No te rindas mi vida\n",
      "Siembra unas flores\n",
      "De amor en tu herida\n",
      "Ay corazón\n",
      "Siempre habrá un nuevo amanecer\n",
      "Te amo a morir\n",
      "No te rajes mi vida\n",
      "Siempre la suerte nos cambia nos gira\n",
      "Ay corazón\n",
      "Siempre habrá un nuevo amanecer\n",
      "Sale el sol\n",
      "\n",
      "\n",
      "No te me rajes mi vida mi amor\n",
      "Eres un roble valiente\n",
      "Con la cara al sol\n",
      "Vamos a resistir\n",
      "Como el árbol de pie\n",
      "Ponte de pie hasta morir\n",
      "\n",
      "\n",
      "Va a amanecer\n",
      "Yo sé que te pega el dolor\n",
      "Tú sabes te amamos\n",
      "Lo sabes corazón\n",
      "Tu soledad se va\n",
      "Se va se va\n",
      "\n",
      "\n",
      "No te rindas mi vida\n",
      "Siembra unas flores\n",
      "De amor en tu herida\n",
      "Ay corazón\n",
      "Siempre habrá un nuevo amanecer\n",
      "Te amo a morir\n",
      "\n",
      "\n",
      "No te rajes mi vida\n",
      "Niempre la suerte nos cambia nos gira\n",
      "Ay corazón\n",
      "Siempre habrá un nuevo amanecer\n",
      "Sale el sol\n",
      "\n",
      "\n",
      "No te rindas mi amor\n",
      "Es la vida un milagro de dios\n",
      "Ve cantando las penas\n",
      "Y suelta el dolor\n",
      "Va a amanecer\n",
      "Pronto llega el sol\n",
      "Con la esperanza de amanecer\n",
      "De renacer\n",
      "No te rindas amor\n",
      "¡Alerta! Esto es un llamado\n",
      "Es valiosa su atención\n",
      "Estan discriminando latinos\n",
      "No me parece que tienen razón\n",
      "\n",
      "Somos gente que nunca se raja\n",
      "Ante cualquier situación\n",
      "¡Vamos a mostrar quienes somos!\n",
      "Con coraje y valor\n",
      "\n",
      "No vamos\n",
      "No vamos\n",
      "A quejarnos\n",
      "¡Jamás!\n",
      "\n",
      "¡Latino tu!\n",
      "¡Latino yo!\n",
      "La misma sangre y corazón\n",
      "Esto es mi Latinoamérica\n",
      "¡Hay que luchar!\n",
      "Latinoamérica\n",
      "\n",
      "Y si nos quieren marginar\n",
      "¡Nunca nos vamos a dejar!\n",
      "Sólo existe una América\n",
      "¡Hay que soñar!\n",
      "Latinoamérica\n",
      "\n",
      "Si no aprendemos de nuestra história\n",
      "No habrá forma de progresar\n",
      "Cometeremos los mismos errores\n",
      "Atrasados nos vamos a quedar\n",
      "\n",
      "¡Ahora es nuestro momento!\n",
      "De brillar como el Sol\n",
      "Tenemos todo para hacerlo\n",
      "Con cojones, dignidad y valor\n",
      "\n",
      "No vamos\n",
      "No vamos\n",
      "A quejarnos\n",
      "¡Jamás!\n",
      "\n",
      "¡Latino tu!\n",
      "¡Latino yo!\n",
      "La misma sangre y corazón\n",
      "Esto es mi Latinoamérica\n",
      "¡Hay que luchar!\n",
      "Latinoamérica\n",
      "\n",
      "Y si nos quieren marginar\n",
      "¡Nunca nos vamos a dejar!\n",
      "Sólo existe una América\n",
      "¡Hay que soñar!\n",
      "Latinoamérica\n",
      "\n",
      "¡Jamás! Se te olviden tus raíces\n",
      "¡Jamás! Se te olviden tus raíces\n",
      "¡Jamás! Se te olviden tus raíces\n",
      "¡Jamás! Se te olviden tus raíces\n",
      "\n",
      "¡Latino tu!\n",
      "¡Latino yo!\n",
      "La misma sangre y corazón\n",
      "Esto es mi Latinoamérica\n",
      "¡Hay que luchar!\n",
      "Latinoamérica\n",
      "\n",
      "Y si nos quieren marginar\n",
      "¡Nunca nos vamos a dejar!\n",
      "Sólo existe una América\n",
      "¡Hay que soñar!\n",
      "Latinoamérica\n",
      "\n",
      "¡Hey!\n",
      "¡Hey!\n",
      "¡Hey!\n",
      "\n",
      "¡Jamás! Se te olviden tus raíces\n",
      "(Se te olviden tus raíces)\n",
      "¡Jamás! ¡Jamás! Nunca Más\n",
      "¡Jamás se te olviden tus raíces!\n",
      "(Se te olviden tus raíces)\n",
      "Vamos mi gente no nos vamos a rajar\n",
      "¡Jamás se te olviden tus raíces!\n",
      "(Se te olviden tus raíces)\n",
      "¡No te rindas Latinoamérica!\n",
      "¡Jamás se te olviden tus raíces!\n",
      "(Se te olviden tus raíces)\n",
      "¡Hay que echar pa'lante!\n",
      "\n",
      "¡Hay que luchar Latinoamérica!\n",
      "¡Hay que soñar Latinoamérica!\n",
      "¡Hay que pensar Latinoamérica!\n",
      "¡Hay que lograr Latinoamérica!\n",
      "¡Yeah! ¡Yeah! ¡Yeah! ¡Yeah!\n",
      "Vas mi vida\n",
      "Perdiendo el suelo\n",
      "Te vas sin despedida\n",
      "Te vas hiriendo el cielo\n",
      "Te di mi vida\n",
      "Te amaba tanto\n",
      "Dragones en el viento\n",
      "Que rompieron\n",
      "Nuestro encanto\n",
      "No podía y no leía\n",
      "Las líneas tan heridas\n",
      "Tatuadas en tu alma\n",
      "Te vas fugaz a la eternidad\n",
      "\n",
      "Dragón parece un dragón\n",
      "Tus recuerdos quedaron\n",
      "Salpicando fuego\n",
      "Dragón parece un dragón\n",
      "Va salpicando el fuego\n",
      "Va hiriendo el cielo\n",
      "Dragón parece un dragón\n",
      "Tus recuerdos quedaron\n",
      "Salpicando fuego\n",
      "Dragón parece un dragón\n",
      "Hiriendo la eternidad\n",
      "\n",
      "Veneno y penas\n",
      "Fluyen por tus venas\n",
      "Ficticio paraíso\n",
      "Y yo sin darme cuenta\n",
      "Dolor por dentro\n",
      "Dragones en el viento\n",
      "Clavaron sus colmillos\n",
      "La adicción y el sufrimiento\n",
      "Te vas fugaz a la eternidad\n",
      "\n",
      "Dragón parece un dragón\n",
      "Tus recuerdos quedaron\n",
      "Salpicando fuego\n",
      "Dragón parece un dragón\n",
      "Va salpicando el fuego\n",
      "Va hiriendo el cielo\n",
      "Dragón parece un dragón\n",
      "Tus recuerdos quedaron\n",
      "Salpicando fuego\n",
      "Dragón parece un dragón\n",
      "Hiriendo la eternidad\n",
      "\n",
      "Te vas fugaz a la eternidad\n",
      "\n",
      "Dragón parece un dragón\n",
      "La adicción clava sus colmillos en el cuello\n",
      "Dragón parece un dragón\n",
      "Va salpicando el fuego\n",
      "Va hiriendo el cielo\n",
      "Dragón parece un dragón\n",
      "Tus recuerdos quedaron\n",
      "Salpicando fuego\n",
      "Dragón parece un dragón\n",
      "Hiriendo la eternidad\n",
      "Tienes todos los espacios\n",
      "Inundados de tu ausencia\n",
      "Inundados de silencio\n",
      "No hay palabras no hay perdón\n",
      "\n",
      "Tú me tienes olvidado\n",
      "No respondes al llamado\n",
      "No eches tierra a la palabra\n",
      "Me condenas a la nada\n",
      "No me entierres sin perdón\n",
      "\n",
      "Mira corazón que es el engaño\n",
      "Se revierte y hace daño\n",
      "Se revienta en el aire\n",
      "Como pompas de jabón\n",
      "Cómo pude haberte yo herido\n",
      "Engañarte y ofendido\n",
      "Alma gemela no te olvido\n",
      "Aunque me arranque el corazón\n",
      "\n",
      "Ay el rencor que nos envenena\n",
      "Nos hace daño\n",
      "Aunque no regreses corazón\n",
      "Haz de perdonarme\n",
      "\n",
      "El verdadero amor perdona\n",
      "No abandona\n",
      "No se quiebra no aprisiona\n",
      "No revienta como pompas de jabón\n",
      "\n",
      "Un error es algo humano\n",
      "No justifico la traición\n",
      "Los amantes verdaderos\n",
      "Se comprenden se aman y se\n",
      "Olvidan del rencor\n",
      "\n",
      "La noche empieza a amotinarse\n",
      "De sueños rotos y el dolor\n",
      "Y me revuelco en la cama\n",
      "Aferrándome a la nada\n",
      "Implorando tu perdón\n",
      "\n",
      "Mira corazón cuánto te extraño\n",
      "Pasan días pasan años\n",
      "Y mi vida se revienta\n",
      "Como pompas de jabón\n",
      "Cómo pude haberte yo herido\n",
      "Engañarte y ofendido\n",
      "Alma gemela no te olvido\n",
      "Aunque me arranque el corazón\n",
      "\n",
      "Ay el rencor que nos envenena\n",
      "Nos hace daño\n",
      "Aunque no regreses corazón\n",
      "Haz de perdonarme\n",
      "\n",
      "El verdadero amor perdona\n",
      "No abandona\n",
      "No se quiebra no aprisiona\n",
      "No revienta como pompas de jabón\n",
      "\n",
      "Un verdadero amor perdona\n",
      "Un verdadero amor perdona\n",
      "Si el amor es verdadero\n",
      "No se quiebra no abandona\n",
      "Si el amor es verdadero\n",
      "No se quiebra no abandona\n",
      "Me he vuelto adicto a tu veneno\n",
      "Me he vuelto adicto a tu tersa piel\n",
      "Está trenzada mi sed mi locura\n",
      "A tu cintura amor\n",
      "Soy un preso irremediable\n",
      "Del deseo que me aferra a ti\n",
      "\n",
      "Ella me tiene envenenado\n",
      "Ella me tiene intoxicado\n",
      "Óyeme nena envenéname\n",
      "\n",
      "Erizada mi piel de sensaciones\n",
      "Quisiera liberar mis emociones hoy\n",
      "Y nos bebimos cada beso cada vena\n",
      "Los suspiros tu veneno amor\n",
      "Ella me tiene envenenado\n",
      "De tentaciones y de amor\n",
      "\n",
      "Ella me tiene envenenado\n",
      "Ella me tiene intoxicado\n",
      "Óyeme nena envenéname\n",
      "\n",
      "Ella me tiene envenenado\n",
      "Ella me tiene intoxicado\n",
      "Óyeme nena envenéname\n",
      "\n",
      "Adicción a tus labios tengo adicción\n",
      "Intoxícame de tu amor\n",
      "Envenéname\n",
      "\n",
      "Adicción no te puedo evitar amor\n",
      "A tus labios tu risa tus muslos\n",
      "Tus pechos\n",
      "Envenéname\n",
      "\n",
      "Ella me tiene envenenado\n",
      "Ella me tiene intoxicado\n",
      "Óyeme nena envenéname\n",
      "\n",
      "Ella me tiene envenenado\n",
      "Ella me tiene intoxicado\n",
      "Óyeme nena envenéname\n",
      "Va a amanecer\n",
      "Va a sanar\n",
      "No te me rindas mi vida\n",
      "Duerme esperando otro día\n",
      "Que saldrá el sol\n",
      "No te rindas amor\n",
      "Resistir al dolor\n",
      "Yo que te quiero a morir\n",
      "\n",
      "\n",
      "Voy a sembrar en tu herida una flor\n",
      "Yo trataré de curar\n",
      "Todo ese dolor\n",
      "Tenme fe corazón\n",
      "Esperanza y valor\n",
      "Yo que te quiero a morir\n",
      "\n",
      "\n",
      "Va a amanecer\n",
      "Va a sanar\n",
      "Te voy a curar\n",
      "Extrañas tanto tanto\n",
      "Pero aguanta corazón\n",
      "Tu soledad se va\n",
      "Te voy a curar\n",
      "\n",
      "\n",
      "No te rindas mi vida\n",
      "Siembra unas flores\n",
      "De amor en tu herida\n",
      "Ay corazón\n",
      "Siempre habrá un nuevo amanecer\n",
      "Te amo a morir\n",
      "No te rajes mi vida\n",
      "Siempre la suerte nos cambia nos gira\n",
      "Ay corazón\n",
      "Siempre habrá un nuevo amanecer\n",
      "Sale el sol\n",
      "\n",
      "\n",
      "No te me rajes mi vida mi amor\n",
      "Eres un roble valiente\n",
      "Con la cara al sol\n",
      "Vamos a resistir\n",
      "Como el árbol de pie\n",
      "Ponte de pie hasta morir\n",
      "\n",
      "\n",
      "Va a amanecer\n",
      "Yo sé que te pega el dolor\n",
      "Tú sabes te amamos\n",
      "Lo sabes corazón\n",
      "Tu soledad se va\n",
      "Se va se va\n",
      "\n",
      "\n",
      "No te rindas mi vida\n",
      "Siembra unas flores\n",
      "De amor en tu herida\n",
      "Ay corazón\n",
      "Siempre habrá un nuevo amanecer\n",
      "Te amo a morir\n",
      "\n",
      "\n",
      "No te rajes mi vida\n",
      "Niempre la suerte nos cambia nos gira\n",
      "Ay corazón\n",
      "Siempre habrá un nuevo amanecer\n",
      "Sale el sol\n",
      "\n",
      "\n",
      "No te rindas mi amor\n",
      "Es la vida un milagro de dios\n",
      "Ve cantando las penas\n",
      "Y suelta el dolor\n",
      "Va a amanecer\n",
      "Pronto llega el sol\n",
      "Con la esperanza de amanecer\n",
      "De renacer\n",
      "No te rindas amor\n",
      "Ella usó mi cabeza como un revolver\n",
      "E incendió mi conciencia con sus demonios.\n",
      "Me ví llegando tarde tarde a todo.\n",
      "\n",
      "Después de un baño cerebral\n",
      "Estaba listo para ser amado\n",
      "\n",
      "Pasa el tiempo y ahora creo\n",
      "Que el vacío es un lugar normal\n",
      "Ella usó mi cabeza como un revolver\n",
      "\n",
      "No creerias las cosas que he hecho por ella\n",
      "Cobardemente fueron sin vergüenza\n",
      "Era una piedra en el agua seca por dentro\n",
      "\n",
      "Así se siente cuando la verdad\n",
      "Es la palabra sometida\n",
      "\n",
      "Fui tan dócil como un guante y tan sincero como pude\n",
      "Ella usó mi cabeza como un revolver\n",
      "\n",
      "No creerias las cosas que he hecho por ella\n",
      "Me salí fuera de contexto\n",
      "Practicar no te hace perfecto\n",
      "Poner un disco eterno y moverme tornasol\n",
      "Un espíritu\n",
      "A veces seguro\n",
      "Otras veces incierto\n",
      "Quiero descubrir\n",
      "Por qué este deseo crece\n",
      "\n",
      "Entre los dos pasa un meridiano\n",
      "Latitud de vida paralelas\n",
      "Abrir el sueño stereo crear la dimensión\n",
      "Sin disimular\n",
      "Me voy desnudando\n",
      "Con cada sonido\n",
      "Alta fidelidad\n",
      "Cuando este deseo crece\n",
      "\n",
      "Un espíritu\n",
      "A veces seguro\n",
      "Otras veces incierto\n",
      "Vengo a descubrir\n",
      "Por qué este deseo crece\n",
      "Quiero un zoom anatómico,\n",
      "Quiero el fin del secreto,\n",
      "Entre tus labios de plata\n",
      "Y mi acero inolvidable\n",
      "Quiero un loop protagónico.\n",
      "\n",
      "Pruébame y verás que todos somos adictos\n",
      "A estos fuegos de artificio.\n",
      "Voy a hacerte un macro porno intenso,\n",
      "Lo que seduce nunca suele estar\n",
      "Donde se piensa.\n",
      "\n",
      "Zoom\n",
      "\n",
      "Por aqui ya estuve,\n",
      "Te largas a reir.\n",
      "Tus comisuras\n",
      "Dame un zoom\n",
      "\n",
      "Luz, cámara y acción.\n",
      "Calenté la cama y te di de comer\n",
      "Mi príncipe no se da por vencido\n",
      "Sobrevolando...\n",
      "El ojo de la tormenta, mi ser\n",
      "Siempre encuentras la calma para ver\n",
      "Va girando a tu alrededor\n",
      "Como la tierra\n",
      "La tierra es el mundo\n",
      "El mundo es la bola\n",
      "La bola es tu juego\n",
      "\n",
      "Ahora cierra los ojos, mi ser\n",
      "Este fue un día agitado\n",
      "Ya lo sé\n",
      "No hay nada, nada a lo que debas temer\n",
      "\n",
      "Regresé a mi pieza y encendí la tv\n",
      "En esta hiperhistoria\n",
      "Todos quieren un flash\n",
      "Y pocos algo para ver\n",
      "En el ojo de la tormenta, mi ser\n",
      "El centro del centro es la ausencia\n",
      "Y tu poder es más\n",
      "\n",
      "Más de lo que puedes creer\n",
      "Oye la frecuencia decaer\n",
      "Cada vez que me dejas\n",
      "Te perseguiría hasta el sol\n",
      "Pero hoy es sólo inercia\n",
      "\n",
      "Y un milenio pasa...\n",
      "\n",
      "Oye el arco suena a lágrimas\n",
      "Cada vez que lo tensas\n",
      "Y oye las sirenas en el mar\n",
      "Si es que aún no lo entiendes\n",
      "\n",
      "Es el efecto doppler\n",
      "Cuando te alejas de mí\n",
      "\n",
      "Es el efecto doppler\n",
      "Cuando te alejas de mí\n",
      "Vuelve... Vuelve...\n",
      "\n",
      "Sostenido por una ilusión\n",
      "Cae la frecuencia de tu amor\n",
      "Mañana es mejor!!!!\n",
      "\n",
      "Que ahora es hora de colgar\n",
      "Estoy perdido en la línea\n",
      "Son las dos y te llamé\n",
      "Desespero\n",
      "Pero es mejor decir adiós\n",
      "E incrementar Mañana\n",
      "\n",
      "Ahora es hora de volver\n",
      "Este noche soy un Robocop\n",
      "Todo el tiempo me encontré\n",
      "Dando culpas\n",
      "Es extraña esta ciudad\n",
      "O yo estoy fuera de escala\n",
      "\n",
      "Que Ahora es hora y no fue ayer\n",
      "mis amigos\n",
      "He cambiado, pero aún mi corazón\n",
      "Permanece intacto, tan intacto como ayer\n",
      "Solo para Decir:\n",
      "\n",
      "Hasta Mañana!!!!!!!\n",
      "(Suena el mar)\n",
      "prefiero seguir tus pasos\n",
      "(Suena el mar)\n",
      "prefiero seguirte...\n",
      "\n",
      "Tengo mal de alturas\n",
      "y aquí vuelan pájaros de oro\n",
      "si me mareé, es por devoción\n",
      "Yo prefiero seguir tus pasos\n",
      "\n",
      "Es igual a un láser\n",
      "la pasión actúa por reflejo\n",
      "de 1 a 2, de 2 a 3\n",
      "Yo prefiero seguir tus pasos\n",
      "\n",
      "Suena el mar\n",
      "Suena el mar\n",
      "Y yo prefiero seguir tus pasos\n",
      "Ahí va la tempestad\n",
      "Ya parece un paisaje habitual\n",
      "Un árbol color sodio\n",
      "Y la caída de un ángel eléctrico\n",
      "\n",
      "Hoy tengo estática\n",
      "Y no querría lastimarte de nuevo\n",
      "Volví sólo y cansado\n",
      "Por la caída de otro ángel eléctrico\n",
      "\n",
      "Enredado en cables\n",
      "Estoy al filo de la resignación\n",
      "Debe ser el hábito\n",
      "De esperar que algo quiebre el unísono\n",
      "\n",
      "Un nuevo acorde\n",
      "Te hace mirarme a los ojos\n",
      "Aún tengo al sol para besar tu sombra\n",
      "Hoy caí, al dejarte sola\n",
      "Ya pagué, por quebrar la calma\n",
      "Lo que irradia esta noche es especial\n",
      "Sobre el lago resplandece\n",
      "Esperaba una tenue aparición\n",
      "Nebulosa como siempre\n",
      "\n",
      "E imaginé, su rostro vívido\n",
      "Cuando está oscuro todo empieza a verse más claro\n",
      "En mi constelación\n",
      "\n",
      "Recordé su gustos, conversación astral\n",
      "Las canciones que oíamos\n",
      "Su cuerpo lunar, refugio celestial\n",
      "\n",
      "Y el PH de su saliva\n",
      "Y me perdí en la inmensa quietud\n",
      "Una crema de estrellas parece cubrirlo todo\n",
      "En mi constelación\n",
      "\n",
      "Recordé su gustos, conversación astral\n",
      "Las canciones que oíamos\n",
      "Y subí\n",
      "Y subí\n",
      "Sabía Savia por mi cuerpo\n",
      "Como oro de Acapulco\n",
      "Voy preparándome\n",
      "No sé que me pasa\n",
      "Ya no puedo volver\n",
      "(Al oír, al oír)\n",
      "\n",
      "Tanto irme por las ramas\n",
      "Ahora recorro las heridas\n",
      "No fue suficiente fe\n",
      "Una vez por semana\n",
      "Ya no puedo volver\n",
      "(Al oír, al oír)\n",
      "\n",
      "Mi voz vegetal\n",
      "Necesito hoy tener amarrados los pies\n",
      "En el aire sé que soy nada más que menos\n",
      "De lo que podría ser\n",
      "Me resisto\n",
      "A empujarte a otro juego de azar\n",
      "En el aire reverbera el ansiar de mi voz\n",
      "Mi voz vegetal\n",
      "Vegetal\n",
      "Amor vegetal\n",
      "Me siento tan laxo, me siento moiré\n",
      "Pastillas de zen instantáneo calman mi sed\n",
      "El dolor clandestino se desvanece\n",
      "Hay cuarto menguante\n",
      "suaviza mi voz...\n",
      "suaviza mi voz...\n",
      "\n",
      "Cerrá la escotilla nena que no hay gravedad\n",
      "afuera oigo truenos lejanos y el mundo al revés\n",
      "ODIOS vs TE AMO\n",
      "OH DIOS\n",
      "TE AMO\n",
      "Cómo quieres ser mi amiga\n",
      "Si, por ti, daría la vida\n",
      "Si confundo tu sonrisa\n",
      "Por camelo si me miras\n",
      "\n",
      "Razón y piel\n",
      "Difícil mezcla\n",
      "Agua y sed\n",
      "Serio problema\n",
      "\n",
      "Cómo quieres ser mi amiga\n",
      "Si, por ti, me perdería\n",
      "Si confundo tus caricias\n",
      "Por camelo si me mimas\n",
      "\n",
      "Pasión y ley\n",
      "Difícil mezcla\n",
      "Agua y sed\n",
      "Serio problema\n",
      "\n",
      "Cuando uno tiene sed\n",
      "Pero el agua no está cerca\n",
      "Cuando uno quiere beber\n",
      "Pero el agua no está cerca\n",
      "\n",
      "¿Qué hacer?\n",
      "Tú lo sabes\n",
      "Conservar\n",
      "La distancia\n",
      "\n",
      "Renunciar\n",
      "A lo natural\n",
      "Y dejar\n",
      "Que el agua corra\n",
      "\n",
      "Cómo vas a ser mi amiga\n",
      "Cuando esta carta recibas\n",
      "Un mensaje hay entre lineas\n",
      "Cómo quieres ser mi amiga\n",
      "\n",
      "Cuando uno tiene sed\n",
      "Pero el agua no está cerca\n",
      "Cuando uno quiere beber\n",
      "Pero el agua no está cerca\n",
      "Ahora, que empiezo de cero\n",
      "Que el tiempo es humo, que el tiempo es incierto\n",
      "Ahora, que ya no me creo\n",
      "Que la vida será un sueño\n",
      "\n",
      "Ahora, que solo el ahora\n",
      "Es lo único que tengo\n",
      "Ahora, que solo me queda\n",
      "Esperar a que llegue la hora\n",
      "\n",
      "Ahora, que cada suspiro\n",
      "Es un soplo de vida robada a la muerte\n",
      "Ahora, que solo respiro\n",
      "Porque así podré volver a verte\n",
      "\n",
      "Ahora, que ya no me importa\n",
      "Que la vida se vista de negro\n",
      "Porque a nada le tengo miedo\n",
      "Porque a nada le tengo fe\n",
      "\n",
      "A nada le tengo fe\n",
      "Ni miedo, ni fe\n",
      "A nada le tengo fe\n",
      "\n",
      "Ahora, que ya no me quiero\n",
      "Que no me conozco, que me abandono\n",
      "Abrázame, mi amor, te lo ruego\n",
      "Abrázame fuerte por última vez\n",
      "\n",
      "Ahora, que ya nada espero\n",
      "Ni siento, ni anhelo, ni nada me sé\n",
      "Abrázame fuerte, amor, te lo ruego\n",
      "Por si esta fuera la última vez\n",
      "\n",
      "Ahora, que solo el ahora\n",
      "Es lo único que tengo\n",
      "Ahora, que solo me queda\n",
      "Esperar a que llegue la hora\n",
      "\n",
      "Ahora, que ya no me importa\n",
      "Que la vida se vista de negro\n",
      "Porque a nada le tengo miedo\n",
      "Porque a nada le tengo fe\n",
      "\n",
      "A nada le tengo fe\n",
      "Ni miedo, ni fe\n",
      "A nada le tengo fe\n",
      "\n",
      "Ahora, que empiezo de cero\n",
      "Que el tiempo es humo, que el tiempo es incierto\n",
      "Abrázame fuerte, amor, te lo ruego\n",
      "Por si esta fuera la última vez\n",
      "Bonito\n",
      "Todo me parece bonito\n",
      "Bonita mañana, bonito lugar\n",
      "Bonita la cama, qué bien se ve el mar\n",
      "\n",
      "Bonito es el día\n",
      "Que acaba de empezar\n",
      "Bonita la vida\n",
      "Respira, respira, respira\n",
      "\n",
      "El teléfono suena, mi pana se queja\n",
      "La cosa va mal, la vida le pesa\n",
      "Que vivir así ya no le interesa\n",
      "Que seguir así no vale la pena\n",
      "\n",
      "Se perdió el amor, se acabó la fiesta\n",
      "Ya no anda el motor que empuja la tierra\n",
      "La vida es un chiste con triste final\n",
      "El futuro no existe, pero yo le digo\n",
      "\n",
      "Bonito\n",
      "Todo me parece bonito\n",
      "Bonito\n",
      "Todo me parece bonito\n",
      "\n",
      "Bonita la paz, bonita la vida\n",
      "Bonito volver a nacer cada día\n",
      "Bonita la verdad cuando no suena a mentira\n",
      "Bonita la amistad, bonita la risa\n",
      "\n",
      "Bonita la gente cuando hay calidad\n",
      "Bonita la gente que no se arrepiente\n",
      "Que gana y que pierde, que habla y no miente\n",
      "Bonita la gente, por eso yo digo\n",
      "\n",
      "Bonito\n",
      "Todo me parece bonito\n",
      "Bonito\n",
      "Todo me parece bonito\n",
      "\n",
      "Que bonito que te va\n",
      "Cuando te va bonito\n",
      "Que bonito que te va\n",
      "\n",
      "Que bonito que te va\n",
      "Cuando te va bonito\n",
      "Que bonito que te va\n",
      "\n",
      "Bonito\n",
      "Todo me parece bonito\n",
      "La mar la mañana, la casa, la samba\n",
      "La tierra, la paz y la vida que pasa\n",
      "\n",
      "Bonito\n",
      "Todo me parece bonito\n",
      "Tu calma, tu salsa, la mancha en la espalda\n",
      "Tu cara, tus ganas, el fin de semana\n",
      "\n",
      "Bonita la gente que viene y que va\n",
      "Bonita la gente que no se detiene\n",
      "Bonita la gente que no tiene edad\n",
      "Que escucha, que entiende, que tiene y que da\n",
      "\n",
      "Bonito Portet, bonito Peret\n",
      "Bonita la rumba, bonito José\n",
      "Bonita la brisa que no tiene prisa\n",
      "Bonito este día, respira, respira\n",
      "\n",
      "Bonita la gente cuando es de verdad\n",
      "Bonita la gente que es diferente\n",
      "Que tiembla, que siente, que vive el presente\n",
      "Bonita la gente que estuvo y no está\n",
      "\n",
      "Bonito\n",
      "Todo me parece bonito\n",
      "(Todo me parece bonito)\n",
      "\n",
      "Que bonito que te va\n",
      "Cuando te va bonito\n",
      "Que bonito que te va\n",
      "\n",
      "Qué bonito que se está\n",
      "Cuando se está bonito\n",
      "Qué bonito que se está\n",
      "\n",
      "Que bonito que te va\n",
      "Cuando te va bonito\n",
      "Que bonito que te va\n",
      "\n",
      "Qué bonito que se está\n",
      "Cuando se está bonito\n",
      "Qué bonito que se está\n",
      "Eso que tú me das\n",
      "Es mucho más de lo que pido\n",
      "Todo lo que me das\n",
      "Es lo que ahora necesito\n",
      "\n",
      "Eso que tú me das\n",
      "No creo lo tenga merecido\n",
      "Por todo lo que me das\n",
      "Te estaré siempre agradecido\n",
      "\n",
      "Así que gracias por estar\n",
      "Por tu amistad y tu compañía\n",
      "Eres lo, lo mejor\n",
      "Que me ha dado la vida\n",
      "\n",
      "Por todo lo que recibí\n",
      "Estar aquí, vale la pena\n",
      "Gracias a ti, seguí\n",
      "Remando contra la marea\n",
      "\n",
      "Por todo lo que recibí\n",
      "Ahora sé que no estoy solo\n",
      "Ahora te tengo a ti\n",
      "Amigo mío, mi tesoro\n",
      "\n",
      "Así que gracias por estar\n",
      "Por tu amistad y tu compañía\n",
      "Eres lo, lo mejor\n",
      "Que me ha dado la vida\n",
      "\n",
      "Todo te lo voy a dar\n",
      "Por tu calidad, por tu alegría\n",
      "Me ayudaste a remontar\n",
      "A superarme día a día\n",
      "\n",
      "Todo te lo voy a dar\n",
      "Fuiste mi mejor medicina\n",
      "Todo te lo daré\n",
      "Sea lo que sea lo que pidas\n",
      "\n",
      "Y eso que tú me das\n",
      "Es mucho más\n",
      "Es mucho más\n",
      "De lo que nunca te he pedido\n",
      "\n",
      "Todo lo que me das\n",
      "Es mucho más\n",
      "Es mucho más\n",
      "De lo que nunca he merecido\n",
      "\n",
      "Eso que tú me das\n",
      "Eso que tú me das\n",
      "Hace días que te observo\n",
      "Y he contado con los dedos\n",
      "Cuántas veces te has reído\n",
      "Ni una mano me ha valido\n",
      "\n",
      "Hace días que me fijo\n",
      "No sé qué guardas ahí dentro\n",
      "Y a juzgar por lo que veo\n",
      "Nada bueno, nada bueno\n",
      "\n",
      "De qué tienes miedo\n",
      "A reír y a llorar luego\n",
      "A romper el hielo\n",
      "Que recubre tu silencio\n",
      "\n",
      "Suéltate ya y cuéntame\n",
      "Que aquí estamos para eso\n",
      "Pa' lo bueno y pa' lo malo\n",
      "Llora ahora y ríe luego\n",
      "\n",
      "Si salgo corriendo\n",
      "Tú me agarras por el cuello\n",
      "Y si no te escucho\n",
      "Grita\n",
      "\n",
      "Te tiendo la mano\n",
      "Tú agarras todo el brazo\n",
      "Y si quieres más, pues\n",
      "Grita\n",
      "\n",
      "Hace tiempo alguien me dijo\n",
      "Cuál era el mejor remedio\n",
      "Cuando, sin motivo alguno\n",
      "Se te iba el mundo al suelo\n",
      "\n",
      "Y si quieres, yo te explico\n",
      "En qué consiste el misterio\n",
      "Que no hay cielo, mar ni tierra\n",
      "Que la vida es un sueño\n",
      "\n",
      "Si salgo corriendo\n",
      "Tú me agarras por el cuello\n",
      "Y si no te escucho\n",
      "Grita\n",
      "\n",
      "Te tiendo la mano\n",
      "Tú agarras todo el brazo\n",
      "Y si quieres más, pues\n",
      "Grita\n",
      "\n",
      "Grita\n",
      "Grita\n",
      "Grita\n",
      "\n",
      "Si salgo corriendo\n",
      "Tú me agarras por el cuello\n",
      "Y si no te escucho\n",
      "Grita\n",
      "\n",
      "Te tiendo la mano\n",
      "Tú agarras todo el brazo\n",
      "Y si quieres más, pues\n",
      "Grita\n",
      "Como una barca de papel\n",
      "Que cuando se moja se hunde\n",
      "Como una manzana que al morder\n",
      "La cabeza me confunde\n",
      "Como una veleta que se mueve\n",
      "Y que al viento no obedece\n",
      "Me gusta como eres\n",
      "\n",
      "Como la balanza que mide el tiempo\n",
      "La soledad y el silencio\n",
      "Como un agujero en el cielo\n",
      "Por donde se van los sueños\n",
      "Como esa cesta que tanto cuesta llenar\n",
      "Y que se vacía al momento\n",
      "Me gusta como eres\n",
      "\n",
      "Como una herida en el corazón que no me duele\n",
      "Tú me gusta como eres\n",
      "Como una ventana que al cerrar deja correr el aire\n",
      "Una niña, una madre, una mujer en mi vida\n",
      "\n",
      "Como una nube cargada de agua\n",
      "Que moja la tierra seca\n",
      "Como la manta que me protege\n",
      "Cuando el invierno llega\n",
      "Como la vela que se prende\n",
      "Y me rescata de la oscuridad\n",
      "Me gusta como eres\n",
      "\n",
      "Como la calle que siempre me lleva\n",
      "A ese sitio al que quiero llegar\n",
      "Como ese bar en la carretera\n",
      "En el que me paro a descansar\n",
      "Como esa península sin bandera\n",
      "En la que me siento libre\n",
      "Me gusta como eres\n",
      "\n",
      "Como una herida en el corazón que no me duele\n",
      "Tú me gusta como eres\n",
      "Como una ventana que al cerrar deja correr el aire\n",
      "Una niña, una madre, una mujer en mi vida\n",
      "\n",
      "Como una herida en el corazón que no me duele\n",
      "Tú me gusta como eres\n",
      "Como una ventana que al cerrar deja correr el aire\n",
      "Una niña, una madre, una mujer en mi vida\n",
      "\n",
      "Como una barca de papel\n",
      "Que cuando se moja se hunde\n",
      "Como una manzana que al morder\n",
      "La cabeza me confunde\n",
      "Como una veleta que se mueve\n",
      "Y que al viento no obedece\n",
      "Que el blanco sea blanco\n",
      "Que el negro sea negro\n",
      "Que uno y uno sean dos\n",
      "Como exactos son los números\n",
      "Depende\n",
      "\n",
      "Que aquí estamos de presta'o\n",
      "Que el cielo esta nubla'o\n",
      "Que uno nace y luego muere\n",
      "Y este cuento se ha acaba'o\n",
      "Depende\n",
      "\n",
      "Depende\n",
      "¿De qué depende?\n",
      "De según cómo se mire\n",
      "Todo depende\n",
      "\n",
      "Depende\n",
      "¿De qué depende?\n",
      "De según cómo se mire\n",
      "Todo depende\n",
      "\n",
      "Que bonito es el amor\n",
      "Más que nunca en primavera\n",
      "Que mañana sale el Sol\n",
      "Porque estamos en agosto\n",
      "Depende\n",
      "\n",
      "Que con el paso del tiempo\n",
      "El vino se hace bueno\n",
      "Que to' lo que sube baja\n",
      "De abajo a arriba y de arriba a abajo\n",
      "Depende\n",
      "\n",
      "Depende\n",
      "¿De qué depende?\n",
      "De según cómo se mire\n",
      "Todo depende\n",
      "\n",
      "Depende\n",
      "¿De qué depende?\n",
      "De según cómo se mire\n",
      "Todo depende\n",
      "\n",
      "Que no has conocido a nadie\n",
      "Que te bese como yo\n",
      "Que no hay otro hombre en tu vida\n",
      "Que de ti se beneficie\n",
      "Depende\n",
      "\n",
      "Y si quieres decir sí\n",
      "Cada vez que abres la boca\n",
      "Que te hace muy feliz\n",
      "Que sea el día de tu boda\n",
      "Depende\n",
      "\n",
      "Depende\n",
      "¿De qué depende?\n",
      "De según cómo se mire\n",
      "Todo depende\n",
      "\n",
      "Depende\n",
      "¿De qué depende?\n",
      "De según cómo se mire\n",
      "Todo depende\n",
      "\n",
      "Depende\n",
      "¿De qué depende?\n",
      "De según cómo se mire\n",
      "Todo depende\n",
      "\n",
      "Depende\n",
      "¿De qué depende?\n",
      "De según cómo se mire\n",
      "Todo depende\n",
      "\n",
      "Depende\n",
      "¿De qué depende?\n",
      "De según cómo se mire\n",
      "Todo depende\n",
      "\n",
      "Depende\n",
      "¿De qué depende?\n",
      "De según cómo se mire\n",
      "Todo depende\n",
      "Y yo, que hasta ayer solo fui un holgazán\n",
      "Y hoy soy el guardián de sus sueños de amor\n",
      "La quiero a morir\n",
      "\n",
      "Podéis destrozar todo aquello que veis\n",
      "Porque ella de un soplo lo vuelve a crear\n",
      "Como si nada, como si nada\n",
      "La quiero a morir\n",
      "\n",
      "Ella borra las horas de cada reloj\n",
      "Y me enseña a pintar transparente el dolor\n",
      "Con su sonrisa\n",
      "\n",
      "Levanta una torre desde el cielo hasta aquí\n",
      "Y me cose unas alas y me ayuda a subir\n",
      "A toda prisa, a toda prisa\n",
      "La quiero a morir\n",
      "\n",
      "Conoce bien cada guerra\n",
      "Cada herida, cada ser\n",
      "Conoce bien cada guerra\n",
      "De la vida y del amor también\n",
      "\n",
      "Me dibuja un paisaje y me lo hace vivir\n",
      "En un bosque de lápiz se apodera de mí\n",
      "La quiero a morir\n",
      "\n",
      "Y me atrapa en un lazo que no aprieta jamás\n",
      "Como un hilo de seda que no puedo soltar\n",
      "No puedo soltar, no quiero soltar\n",
      "La quiero a morir\n",
      "\n",
      "Cuando trepo a sus ojos, me enfrento al mar\n",
      "Dos espejos de agua, encerrada en cristal\n",
      "La quiero a morir\n",
      "\n",
      "Solo puedo sentarme, solo puedo charlar\n",
      "Solo puedo enredarme, solo puedo aceptar\n",
      "Ser solo suyo, tan solo suyo\n",
      "La quiero a morir\n",
      "\n",
      "Conoce bien cada guerra\n",
      "Cada herida, cada ser\n",
      "Conoce bien cada guerra\n",
      "De la vida y del amor también\n",
      "\n",
      "Conoce bien cada guerra\n",
      "Cada herida, cada ser\n",
      "Conoce bien cada guerra\n",
      "De la vida y del amor también\n",
      "\n",
      "Conoce bien cada guerra\n",
      "Cada herida, cada ser\n",
      "Conoce bien cada guerra\n",
      "De la vida y del amor también\n",
      "\n",
      "Y yo, que hasta ayer solo fui un holgazán\n",
      "Y hoy soy el guardián de sus sueños de amor\n",
      "La quiero a morir\n",
      "\n",
      "Podéis destrozar todo aquello que veis\n",
      "Porque ella de un soplo lo vuelve a crear\n",
      "Como si nada, como si nada\n",
      "La quiero a morir\n",
      "Hay dos días en la vida\n",
      "Para los que no nací\n",
      "Dos momentos en la vida\n",
      "Que no existen para mí\n",
      "Ciertas cosas en la vida\n",
      "No se hicieron para mí\n",
      "Hay dos días en la vida\n",
      "Para los que no nací\n",
      "\n",
      "El primero de esos días\n",
      "Fue cuando te conocí\n",
      "Me atraparon tus mentiras\n",
      "Y me enamoré de ti\n",
      "Del camelo de tus risas\n",
      "De tus ganas de vivir\n",
      "De la crueldad de tus caricias\n",
      "Por las que creí morir\n",
      "\n",
      "Hay dos días en la vida\n",
      "Para los que no nací\n",
      "Dos momentos en la vida\n",
      "Que no existen para mí\n",
      "Ciertas cosas en la vida\n",
      "No se hicieron para mí\n",
      "Hay dos días en la vida\n",
      "Para los que no nací\n",
      "\n",
      "El segundo de esos días\n",
      "Fue justo el que te perdí\n",
      "Se fue tu cara bonita\n",
      "Y mis ganas de vivir\n",
      "Se acabaron las mentiras\n",
      "Y de todo aprendí\n",
      "Que hay dos días en la vida\n",
      "Para los que no nací\n",
      "\n",
      "Hay dos días en la vida\n",
      "Para los que no nací\n",
      "Dos momentos en la vida\n",
      "Que no existen para mí\n",
      "Ciertas cosas en la vida\n",
      "No se hicieron para mí\n",
      "Hay dos días en la vida\n",
      "Para los que no nací\n",
      "\n",
      "Me tragué todo el veneno\n",
      "El que llevaban tus besos\n",
      "Me empapé del sufrimiento\n",
      "Que escondía tu sonrisa\n",
      "Descubrí que con el tiempo\n",
      "Me perdí todo el respeto\n",
      "Compraste mis sentimientos\n",
      "Con tus labios de carmín\n",
      "\n",
      "Y hay dos días en la vida\n",
      "Para los que no nací\n",
      "Dos momentos en la vida\n",
      "Que no existen para mí\n",
      "Ciertas cosas en la vida\n",
      "No se hicieron para mí\n",
      "Hay dos días en la vida\n",
      "Para los que no nací\n",
      "\n",
      "Y hay dos días en la vida\n",
      "Dos momentos en mi vida\n",
      "Y hay dos días en la vida\n",
      "Dos momentos en mi vida\n",
      "Y hay dos días días en la vida\n",
      "Dos momentos en mi vida\n",
      "Y hay dos días en la vida\n",
      "Dos momentos en mi vida\n",
      "Y hay dos días en la vida\n",
      "Dos momentos en mi vida\n",
      "Y hay dos días en la vida\n",
      "Hoy, el mundo da otra vuelta\n",
      "Pero nadie me ha avisa'o\n",
      "Hoy, el tiempo me ha pilla'o\n",
      "Con un lío en la cabeza\n",
      "\n",
      "Tira'o en la cama\n",
      "Con ganas de nada\n",
      "Hoy el tiempo se ha para'o\n",
      "En la hora que no era\n",
      "\n",
      "Hoy el mundo da una vuelta\n",
      "Pero no me ha pregunta'o\n",
      "Hoy estoy desafina'o\n",
      "Hoy estoy de calavera\n",
      "\n",
      "Y el alma partida\n",
      "La pena encendida\n",
      "En la acera, me he senta'o\n",
      "A esperar la primavera\n",
      "\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "\n",
      "Hoy, el mundo da otra vuelta\n",
      "Pero no me ha desperta'o\n",
      "Hoy me levanté gira'o\n",
      "Hoy me levanté de vuelta\n",
      "\n",
      "De capa caída\n",
      "Peleo con la vida\n",
      "Hoy no estoy pa' nadie\n",
      "Hoy estoy de vuelta\n",
      "\n",
      "De vuelta de todo\n",
      "De vuelta de nada\n",
      "De vuelta y vuelta\n",
      "Tan joven y de vuelta\n",
      "\n",
      "De vuelta de todo\n",
      "De vuelta de nada\n",
      "De vuelta y vuelta\n",
      "Tan joven y de vuelta\n",
      "\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "Primavera que no llega\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "\n",
      "¿A dónde vas\n",
      "Con tu vestido nuevo?\n",
      "¿A dónde vas\n",
      "Con ese balanceo?\n",
      "¿A dónde vas?\n",
      "Me gusta lo que veo\n",
      "Tú, ¿a dónde vas?\n",
      "\n",
      "Tú, ¿de qué vas, animal\n",
      "Con ese desespero?\n",
      "No tengas prisa, chaval\n",
      "Sedúceme primero\n",
      "\n",
      "Lo estás haciendo muy mal\n",
      "Guárdate tu dinero\n",
      "No quiero un chico formal\n",
      "Yo busco un marinero\n",
      "\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me sepa conquistar\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me vuelva a enamorar\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me quiera de verdad\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "\n",
      "¿A dónde vas?\n",
      "Vamos a hablar primero\n",
      "¿A dónde vas?\n",
      "Voy a serte sincero\n",
      "¿A dónde vas?\n",
      "Quiero invitarte y luego\n",
      "Tú, ¿a dónde vas?\n",
      "\n",
      "Te voy a dar\n",
      "Otra oportunidad de nuevo\n",
      "Mejor será, chico\n",
      "Que me trates con esmero\n",
      "\n",
      "Ya no me preguntes más\n",
      "Ya me contaste el cuento\n",
      "Ve con cuidado, chaval\n",
      "Yo busco marinero\n",
      "\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me quiera acariciar\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me vuelva a interesar\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me quiera de verdad\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me sepa convencer\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que tendrá algo que ofrecer\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me haga enloquecer\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "\n",
      "¿A dónde vas?\n",
      "Voy a serte sincero\n",
      "Lo estás haciendo muy mal\n",
      "Sedúceme primero\n",
      "\n",
      "¿A dónde vas?\n",
      "Me gustas sin remedio\n",
      "No tengas prisa, chaval\n",
      "Yo busco marinero\n",
      "\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me sepa conquistar\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me vuelva a enamorar\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me quiera de verdad\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me quiera acariciar\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me vuelva a interesar\n",
      "Oh, oh, oh-oh-oh-ooh\n",
      "Alguien que me quiera de verdad\n",
      "Déjame vivir\n",
      "Libre como las palomas\n",
      "Que anidan en mi ventana\n",
      "Mi compañía cada vez que tú te vas\n",
      "Cada vez que tú te vas\n",
      "\n",
      "Déjame vivir\n",
      "Libre, libre como el aire\n",
      "Me enseñaste a volar\n",
      "Y, ahora, me cortas las alas\n",
      "\n",
      "Y volver a ser yo mismo\n",
      "Y que tú vuelvas a ser tú\n",
      "Libre\n",
      "Libre como el aire\n",
      "\n",
      "Déjame vivir\n",
      "Libre, pero a mi manera\n",
      "Y volver a respirar\n",
      "De ese aire que me vuelve a la vida\n",
      "Pero a mi manera\n",
      "Pero a mi manera\n",
      "\n",
      "Y volver a ser yo mismo\n",
      "Y que tú vuelvas a ser tú\n",
      "Libre\n",
      "Pero a tu manera\n",
      "\n",
      "Y volver a ser yo mismo\n",
      "Y que tú vuelvas a ser tú\n",
      "Libre (libre)\n",
      "Libre como el aire\n",
      "\n",
      "Pero a mi manera\n",
      "Pero a mi manera\n",
      "Déjame vivir\n",
      "Pero a mi manera\n",
      "Pero a mi manera\n",
      "Pero a mi manera\n",
      "So-So-So-Somos lo que somos\n",
      "So-So-So-Somos lo que somos\n",
      "\n",
      "Mira, hermano, aquí somos los que estamos\n",
      "Y aunque hacemos lo que podemos\n",
      "No aprendemos, no avanzamos\n",
      "El mundo se hace pequeño (so-so-so)\n",
      "Y la vida nos sigue pesando (somos lo que somos)\n",
      "\n",
      "La Tierra enferma, y tú con ella, bro\n",
      "Mira, el hombre arrasa con todo lo que le dio\n",
      "Digo paz, verdad, justicia, libertad\n",
      "Digo amor, respeto, conciencia, dignidad\n",
      "\n",
      "Mira, somos lo que somos, no lo que queremos\n",
      "Patrones, esclavos, humanos, imperfectos\n",
      "Somos raza, cultura, humanidad\n",
      "So-So-So-Somos lo que somos\n",
      "\n",
      "Saca la mentira pa' fuera de tu vida\n",
      "El amor es el camino que cambie tu destino\n",
      "Que cambie la dirección que abra tu corazón\n",
      "Esta calle sí tiene salida, libérate y respira\n",
      "\n",
      "Somos monos inteligentes\n",
      "Animales racionales con carnet de identidad\n",
      "Seres humanos indiferentes\n",
      "Víctimas supervivientes de la propia raza humana\n",
      "\n",
      "Yo', somos lo que somos, no lo que queremos\n",
      "Individuos vigilados con derechos controlados\n",
      "We are what we are, no what we wanna be\n",
      "So-So-So-Somos lo que somos\n",
      "\n",
      "Somos monos, somos locos\n",
      "Somos raros, somos cocos\n",
      "Somos rotos, somos chotos\n",
      "Somos nacos, somos jotos\n",
      "\n",
      "Somos monos, somos locos\n",
      "Somos raros, somos cocos\n",
      "Somos rotos, somos chotos\n",
      "Somos nacos, somos jotos\n",
      "Somos homos, somos rotos\n",
      "Somos falsos, somos bobos\n",
      "So-So-So-Somos lo que somos\n",
      "\n",
      "Calma, tú tienes la palabra\n",
      "La fuerza de la vida reside en la esperanza\n",
      "Reside en la energía, que brota de tu alma\n",
      "En tu mente positiva, no tengas miedo\n",
      "Avanza, libérate y respira\n",
      "\n",
      "Lo que sí te digo, amigo\n",
      "Es que ya estoy preparado\n",
      "No me gusta lo que veo\n",
      "Voy a empezar a hacer algo\n",
      "\n",
      "Voy a empezar a quererte\n",
      "Sin que importe lo que haya pasado\n",
      "Voy a empezar a ser libre\n",
      "Estrechándote la mano\n",
      "\n",
      "En la vida, algo me he propuesto (yo')\n",
      "Seguir adelante sin miedo (flow)\n",
      "Vivir y avanzar compartiendo\n",
      "Con la gente a la que yo quiero\n",
      "\n",
      "A pesar de nuestros defectos\n",
      "Algunas virtudes tenemos (de pana)\n",
      "Somos ángeles, somos buenos (mira)\n",
      "So-So-So-Somos lo que somos\n",
      "\n",
      "Saca la mentira pa' fuera de tu vida\n",
      "El amor es el camino que cambie tu destino\n",
      "Que cambie la dirección que abra tu corazón\n",
      "Esta calle sí tiene salida (so-so-so-somos lo que somos)\n",
      "\n",
      "Somos Tierra, somos paz\n",
      "Somos fuego, destino y verdad\n",
      "Somos sangre, hermanos, amigos\n",
      "Y en el tiempo andamos perdidos (so-so-so-somos lo que somos)\n",
      "\n",
      "A pesar de nuestros defectos\n",
      "Algunas virtudes tenemos\n",
      "Somos ángeles, somos buenos\n",
      "So-So-So-Somos lo que somos\n",
      "\n",
      "Monos, locos, raros, cocos\n",
      "So-So-So-Somos lo que somos\n",
      "Rotos, chotos, nacos, jotos\n",
      "So-So-So-Somos lo que somos\n",
      "Fotos, cortos, chapos, votos\n",
      "So-So-So-Somos lo que somos\n",
      "Homos, rostros, falsos, bobos\n",
      "So-So-So-Somos lo que somos\n",
      "Yin yang, menos es más\n",
      "Polos opuestos que nunca se juntan\n",
      "Yin yang, vienen y van\n",
      "Líneas paralelas que nunca se cruzan\n",
      "\n",
      "Bien, mal, madera o metal\n",
      "Puntos de vista que no se preguntan\n",
      "Tal cual, azúcar o sal\n",
      "Dos que se oyen, pero no se escuchan\n",
      "\n",
      "Yin yang, Eva y Adán\n",
      "Desequilibrio por una manzana\n",
      "Yin yang, bastos o espadas\n",
      "Palos opuestos en una baraja\n",
      "\n",
      "Yin yang, salir o entrar\n",
      "De un laberinto lleno de puertas\n",
      "Yin yang, delante o detrás\n",
      "Dos que se buscan, pero no se encuentran\n",
      "\n",
      "Cómo vas, cómo lo ves\n",
      "Si tu veleta y la mía señalan rumbos distintos\n",
      "Cómo vas, cómo lo ves\n",
      "Si tu maleta y la mía viajan en vuelos distintos\n",
      "\n",
      "Yin yang, menos es más\n",
      "Polos opuestos que nunca se juntan\n",
      "Yin yang, vienen y van\n",
      "Líneas paralelas que nunca se cruzan\n",
      "\n",
      "Bien, mal, madera o metal\n",
      "Puntos de vista que no se preguntan\n",
      "Tal cual, azúcar o sal\n",
      "Dos que se oyen, pero no se escuchan\n",
      "\n",
      "Yin yang, Eva y Adán\n",
      "Desequilibrio por una manzana\n",
      "Yin yang, bastos o espadas\n",
      "Palos opuestos en una baraja\n",
      "\n",
      "Yin yang, salir o entrar\n",
      "De un laberinto lleno de puertas\n",
      "Yin yang, delante o detrás\n",
      "Dos que se buscan, pero no se encuentran\n",
      "\n",
      "Cómo vas, cómo lo ves\n",
      "Si tu veleta y la mía señalan rumbos distintos\n",
      "Cómo vas, cómo lo ves\n",
      "Si tu maleta y la mía viajan en vuelos distintos\n",
      "\n",
      "Cómo vas, cómo lo ves\n",
      "Si tu receta y la mía tienen sabores distintos\n",
      "Cómo vas, cómo lo ves\n",
      "Si tu cabeza y la mía viven paisajes distintos\n",
      "Soy un completo incompleto\n",
      "Incompleto por amor\n",
      "La costilla que me falta\n",
      "Cuelga de tu corazón\n",
      "\n",
      "Un seguro inseguro\n",
      "Media persona en el mundo\n",
      "Un amante incompleto\n",
      "Cada vez que te deseo\n",
      "\n",
      "Soy un completo incompleto\n",
      "Si me giro y no te veo\n",
      "Como una persona a medias\n",
      "Sabes a que me refiero\n",
      "\n",
      "Soy un acorde incompleto\n",
      "Menor y desafinado\n",
      "Que va persiguiendo notas\n",
      "Sin lograr una canción\n",
      "\n",
      "Un rosal sin hojas secas\n",
      "Un perfume sin olor\n",
      "Una película de cine\n",
      "Sin final en el guión\n",
      "\n",
      "Soy un completo incompleto\n",
      "Si me giro y no te veo\n",
      "Como una persona a medias\n",
      "Sabes a que me refiero\n",
      "\n",
      "Soy un completo incompleto\n",
      "Si me giro y no te veo\n",
      "Como una persona a medias\n",
      "Sabes a que me refiero\n",
      "\n",
      "Sin ti en mi corazón\n",
      "\n",
      "Soy un completo incompleto\n",
      "Se me para el corazón\n",
      "Si me giro y no te veo\n",
      "Sabes a que me refiero\n",
      "\n",
      "Un seguro inseguro\n",
      "Media persona en el mundo\n",
      "Un amante incompleto\n",
      "Sin ti en mi corazón\n",
      "Mira qué cosa más linda, más llena de gracia\n",
      "Es esa muchacha, que viene y que pasa\n",
      "Con su balanceo, camino del mar\n",
      "\n",
      "Niña de cuerpo dorado, del Sol de Ipanema\n",
      "Con su balanceo, es todo un poema\n",
      "La chica más linda que he visto pasar\n",
      "\n",
      "Ay, ¿por qué estoy tan solo?\n",
      "Ay, ¿por qué me siento triste?\n",
      "Ay, la belleza que existe\n",
      "Belleza que no es solo mía\n",
      "Que ahora pasea solita\n",
      "\n",
      "Oh, vida mía, se supieras que cuando tú pasas\n",
      "El mundo entero se llena de gracia\n",
      "Con tu balanceo, camino del mar\n",
      "\n",
      "Mira qué cosa más linda, más llena de gracia\n",
      "Es esa muchacha, que viene y que pasa\n",
      "Con su balanceo, camino del mar\n",
      "\n",
      "Niña de cuerpo dorado, del Sol de Ipanema\n",
      "Con su balanceo, es todo un poema\n",
      "La chica más linda que he visto pasar\n",
      "\n",
      "Ay, ¿por qué estoy tan solo?\n",
      "Ay, ¿por qué me siento triste?\n",
      "Ay, la belleza que existe\n",
      "Belleza que no es solo mía\n",
      "Que ahora pasea solita\n",
      "\n",
      "Oh, vida mía, se supieras que cuando tú pasas\n",
      "El mundo entero se llena de gracia\n",
      "Con tu balanceo, camino del mar\n",
      "\n",
      "Ay, ¿por qué estoy tan solo?\n",
      "Ay, ¿por qué me siento triste?\n",
      "Ay, la belleza que existe\n",
      "Belleza que no es solo mía\n",
      "Que ahora pasea solita\n",
      "\n",
      "Mira\n",
      "Qué cosa más linda\n",
      "Más llena de gracia\n",
      "Con su balanceo, camino del mar\n",
      "Camino del mar\n",
      "Camino del mar\n",
      "Te quiero\n",
      "Aunque ahora no viene a cuento\n",
      "Aunque no te lo demuestro\n",
      "Te quiero\n",
      "\n",
      "Te quiero\n",
      "Aunque parezca que me olvide\n",
      "Aunque creas que no es cierto\n",
      "Eso es lo que siento\n",
      "\n",
      "Me gusta\n",
      "Pensar que me gustas\n",
      "Saber que te quiero\n",
      "Qué bueno, qué bueno\n",
      "\n",
      "Me gusta\n",
      "Ser el dueño de tus celos\n",
      "Despertarme y darme cuenta\n",
      "De lo mucho que te quiero\n",
      "\n",
      "Quererte\n",
      "Quererte no es bastante\n",
      "Quererte es no entenderte\n",
      "Y que te siga queriendo\n",
      "\n",
      "Quererte\n",
      "Quererte es acordarme\n",
      "Quererte es merecerte\n",
      "Más de lo que te merezco\n",
      "\n",
      "Me gusta\n",
      "Pensar que me gustas\n",
      "Saber que te quiero\n",
      "Qué bueno, qué bueno\n",
      "\n",
      "Me gusta\n",
      "Ser el dueño de tus celos\n",
      "Despertarme y darme cuenta\n",
      "De lo mucho que te quiero\n",
      "\n",
      "Te tengo, te pierdo (Te tengo, te pierdo)\n",
      "Te agarro, te suelto (Te agarro, te suelto)\n",
      "Te vas y te espero (Te vas y te espero)\n",
      "Te busco, te encuentro\n",
      "\n",
      "Te acercas, me alejo (Te acercas, me alejo)\n",
      "Te escucho, te cuento (Te escucho, te cuento)\n",
      "Te compro y te vendo (Te compro y te vendo)\n",
      "Te odio, te quiero\n",
      "\n",
      "Te dejas, me dejo\n",
      "Me besas, te muerdo\n",
      "Te amo, te huelo\n",
      "Qué bueno, qué bueno\n",
      "\n",
      "Te pido, te ofrezco (te amo, te miento)\n",
      "Te abrazo, te aprieto\n",
      "Me duermo, te sueño\n",
      "Qué bueno, qué bueno\n",
      "\n",
      "Te quiero (que te quiero)\n",
      "Y lo que más echo de menos (lo que más echo de menos)\n",
      "Es que no te quiera más (más, mucho más)\n",
      "De lo mucho que te quiero\n",
      "\n",
      "Te echo de menos (a veces, de más)\n",
      "Tu retrato en la pared (tu retrato en la pared)\n",
      "Una cartita en el correo (una cartita de quién)\n",
      "Para decirte que te quiero\n",
      "\n",
      "Qué bueno, qué bueno\n",
      "Qué bueno, qué bueno\n",
      "Qué bueno, qué bueno\n",
      "Qué bueno, qué bueno\n",
      "\n",
      "Qué bueno, qué bueno\n",
      "Qué bueno, qué bueno\n",
      "Te di mi sangre\n",
      "Te di mi cielo\n",
      "Te abrí la puerta\n",
      "De mis secretos\n",
      "\n",
      "Te di mi alma\n",
      "Y tú, tus besos\n",
      "Y ese veneno\n",
      "De efecto lento\n",
      "\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "\n",
      "¿Dónde está el fuego?\n",
      "Llegó el invierno\n",
      "¿Dónde has escrito\n",
      "Nuestro último verso?\n",
      "\n",
      "¿Cómo está el río\n",
      "Tranquilo y seco?\n",
      "¿Cómo borrarte\n",
      "De mis recuerdos?\n",
      "\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "Te miro y tiemblo\n",
      "\n",
      "Te di mi sangre\n",
      "Y tú, tus besos\n",
      "¿Cómo negar que\n",
      "Aún te venero?\n",
      "Puede que hayas\n",
      "Nacido en la cara buena del mundo\n",
      "Yo nací en la cara mala\n",
      "Llevo la marca del lado oscuro\n",
      "\n",
      "Y no me sonrojo\n",
      "Si te digo que te quiero\n",
      "Y que me dejes o te deje\n",
      "Eso ya no me da miedo\n",
      "\n",
      "Habías sido\n",
      "Sin dudarlo, la más bella\n",
      "De entre todas las estrellas\n",
      "Que yo vi en el firmamento\n",
      "\n",
      "Cómo ganarse el cielo\n",
      "Cuando uno ama con toda el alma\n",
      "Y es que el cariño que te tengo\n",
      "No se paga con dinero\n",
      "Cómo decirse que, sin ti, muero\n",
      "\n",
      "Y no me sonrojo\n",
      "Si te digo que te quiero\n",
      "Y que me dejes o te deje\n",
      "Eso ya no me da miedo\n",
      "\n",
      "Habías sido\n",
      "Sin dudarlo, la más bella\n",
      "De entre todas las estrellas\n",
      "Que yo vi en el firmamento\n",
      "\n",
      "Puede que hayas\n",
      "Nacido en la cara buena del mundo\n",
      "Yo nací en la cara mala\n",
      "Llevo la marca del lado oscuro\n",
      "\n",
      "Y no me sonrojo\n",
      "Si te digo que te quiero\n",
      "Y que me dejes o te deje\n",
      "Eso ya no me da miedo\n",
      "\n",
      "Habías sido\n",
      "Sin dudarlo, la más bella\n",
      "De entre todas las estrellas\n",
      "Que yo vi en el firmamento\n",
      "\n",
      "No me sonrojo\n",
      "Si te digo que te quiero\n",
      "Si te digo que te quiero\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Si se quiere mostrar el texto que ha sido cargado\n",
    "print(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvaXlThfxzia"
   },
   "source": [
    "### Limpiar el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1637588161930,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "aeTMbhwMx16u",
    "outputId": "f6916a08-2ef3-4ca2-9c01-82116bfbf01d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el texto esta compuesto de estos :83 caracteres\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '¿', 'É', 'Ó', 'à', 'á', 'è', 'é', 'í', 'ñ', 'ó', 'ú', 'ü']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(texto))\n",
    "print('el texto esta compuesto de estos :{} caracteres'. format(len(vocab)))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVBMy_8J0hv4"
   },
   "source": [
    "### Pasar texto a Minisculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1637588163793,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "6VkD3_CX0mK3"
   },
   "outputs": [],
   "source": [
    "texto = texto.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7cTHZoXyX6F"
   },
   "source": [
    "#### Reemplazar caracteres por espacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1637588165959,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "swS4FIFOyjJR"
   },
   "outputs": [],
   "source": [
    "texto = texto.replace('á','a')\n",
    "texto = texto.replace('é','e')\n",
    "texto = texto.replace('í','i')\n",
    "texto = texto.replace('ó','o')\n",
    "texto = texto.replace('ú','u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1637588167537,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "KZaEe8qmzh2i"
   },
   "outputs": [],
   "source": [
    "texto = texto.replace('(','')\n",
    "texto = texto.replace(')','')\n",
    "texto = texto.replace('*','')\n",
    "texto = texto.replace('!','')\n",
    "texto = texto.replace('¡','')\n",
    "texto = texto.replace('\"','')\n",
    "texto = texto.replace('&','')\n",
    "texto = texto.replace(\"'\",\"\")\n",
    "texto = texto.replace(',','')\n",
    "texto = texto.replace('.','')\n",
    "texto = texto.replace('-','')\n",
    "texto = texto.replace('_','')\n",
    "texto = texto.replace(':','')\n",
    "texto = texto.replace('/','')\n",
    "texto = texto.replace('$','')\n",
    "texto = texto.replace('%','')\n",
    "texto = texto.replace('=','')\n",
    "texto = texto.replace(';','')\n",
    "texto = texto.replace('?','')\n",
    "texto = texto.replace('¿','')\n",
    "texto = texto.replace('[','')\n",
    "texto = texto.replace(']','')\n",
    "texto = texto.replace('«','')\n",
    "texto = texto.replace('º','')\n",
    "texto = texto.replace('»','')\n",
    "texto = texto.replace('“','')\n",
    "texto = texto.replace('”','')\n",
    "texto = texto.replace('…','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1637588169353,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "UE8JMORk1Yx4"
   },
   "outputs": [],
   "source": [
    "texto = texto.replace('—','')\n",
    "texto = texto.replace('ü','u')\n",
    "texto = texto.replace('ä','a')\n",
    "texto = texto.replace('\\n',' ')\n",
    "texto = texto.replace('à','a')\n",
    "texto = texto.replace('è','e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1637588170993,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "sttSTHg51zHZ"
   },
   "outputs": [],
   "source": [
    "texto = texto.replace('0','')\n",
    "texto = texto.replace('1','')\n",
    "texto = texto.replace('2','')\n",
    "texto = texto.replace('3','')\n",
    "texto = texto.replace('4','')\n",
    "texto = texto.replace('5','')\n",
    "texto = texto.replace('6','')\n",
    "texto = texto.replace('7','')\n",
    "texto = texto.replace('8','')\n",
    "texto = texto.replace('9','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1637588173028,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "wpzHsfQ92FxQ",
    "outputId": "23a0aed8-d718-4357-de42-e83196263270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el texto esta compuesto de estos :28 caracteres\n",
      "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ñ']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(texto))\n",
    "print('el texto esta compuesto de estos :{} caracteres'. format(len(vocab)))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEKtQoEJ27zI"
   },
   "source": [
    "## Entendiendo El Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1637588175809,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "-oWUa6cv3AqL",
    "outputId": "e0fc140c-78ea-4482-fb24-24939dca8784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el texto tiene longitud de:117027 caracteres\n",
      "el texto esta compuesto de estos :28 caracteres\n",
      "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ñ']\n"
     ]
    }
   ],
   "source": [
    "print('el texto tiene longitud de:{} caracteres'. format(len(texto)))\n",
    "vocab = sorted(set(texto))\n",
    "print('el texto esta compuesto de estos :{} caracteres'. format(len(vocab)))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "8Q7S6R5Fs-Uy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flaca no me claves tus puñales por la espalda tan profundo no me duelen no me hacen mal  lejos en el centro de la tierra las raices del amor donde estaban quedaran  entre el no me olvides me deje nuestros abriles olvidados en el fondo del placard del cuarto de invitados eran tiempos dorados un pasado mejor  aunque casi me equivoco y te digo poco a poco no me mientas no me digas la verdad no te quedes callada no levantes la voz ni me pidas perdon  aunque casi te confieso que tambien he sido un perro compañero un perro ideal que aprendio a ladrar y a volver al hogar para poder comer  flaca no me claves tus puñales por la espalda tan profundo no me duelen no me hacen mal  lejos en el centro de la tierra las raices del amor donde estaban quedaran ay ven y dime todas esas cosas invitame a sentarme junto a ti escuchare todos tus sueños en mi oido  y dejame estrechar tus manos y regalarte unas pocas de ilusiones ay ven y cuentame una historia que me haga sentir bien  yo te escuchare con todo el silencio del planeta y mirare tus ojos como si fueran los ultimos de este pais  ay dejame ver como es que floreces con cinco petalos te absorbere cinco sentidos que te roban solo un poco de tu ser  y seis veces para vivirte debajo de una misma luna y otras nueve pasaran para sentir que nuevas flores naceran  y que cada estrella fuese una flor y asi regalarte todo un racimo de estrellas  no dejes que amanezca no dejes que la noche caiga no dejes que el sol salga solo dejame estar junto a ti  ay larara larara ay lara ay larara cuando estoy en mis excesos contigo en grande emocion quisiera con embelesos arrancarte el corazon arrancarte el corazon y comermelo a besos  ay larara larara ay lara ay larara yo te juro y te prometo como siempre te he querido que si tu amor es completo cumpleme lo prometido yo no quiero que otro prieto quiera lo que yo he querido  ay larara larara ay lara ay larara ay larara larara ay lara ay larara  mariquita quita quita quitame dolor y pena debajo de tu rebozo se pasa una noche buena buena es la buena memoria memoria del que se acuerda  se acuerda de san francisco san francisco no es esteban esteban no es ningun santo santo es aquel que le reza rezan los padres maitines  los maitines no son completos completas seran las mañas las mañas de un hechicero hechicero es el que urde urde la mujer su tela  tela la del buen cedazo cedazo de harina y cuerda cuerda la de los cochinos los cochinos tragan hierba de la hierba nace el trigo el trigo es el que se siembra  se siembra porque es costumbre dijo un viejito al pasar y lo echaron al alumbre porque no supo trovar y lo echaron al alumbre porque no supo trovar me quieren agitar me incitan a gritar soy como una roca palabras no me tocan adentro hay un volcan que pronto va estallar yo quiero estar tranquilo  es mi situacion una desolacion soy como un lamento lamento boliviano que un dia empezo y no va a terminar ya nadie hace daño  uoh yo yo yo eh eh eh yo  y yo estoy aqui borracho y loco y mi corazon idiota siempre brillara siempre brillara  y yo te amare te amare por siempre nena no te peines en la cama que los viajantes se van a atrasar  uoh yo yo yo eh eh eh yo  y hoy estoy aqui borracho y loco y mi corazon idiota siempre brillara siempre brillara  y yo te amare te amare por siempre nena no te peines en la cama que los viajantes se van a atrasar  y yo estoy aqui borracho y loco y mi corazon idiota siempre brillara siempre brillara  y yo te amare te amare por siempre nena no te peines en la cama que los viajantes se van a atrasar te puedes vender cualquier oferta es buena si quieres poder uy que facil es abrir tanto la boca para opinar y si te piensas echar atras ya tienes muchas huellas que borrar  uh dejame que yo no tengo la culpa de verte caer si yo no tengo la culpa de verte caer  pierdes la fe cualquier esperanza es vana y no se que creer pepepepero olvidame que nadie te ha llamado y ya estas otra vez  uh dejame que yo no tengo la culpa de verte caer si yo no tengo la culpa  entre dos tierras estas y no dejas aire que respirar entre dos tierras estas y no dejas aire que respirar  dejalo ya no seas membrillo y permite pasar y si no piensas echar atras ya tienes mucho barro que tragar  uh dejame que yo no tengo la culpa de verte caer si yo no tengo la culpa de verte  entre dos tierras estas y no dejas aire que respirar entre dos tierras estas y no dejas aire que respirar  dejame que yo no tengo la culpa de verte caer si yo no tengo la culpa de verte  entre dos tierras estas y no dejas aire que respirar entre dos tierras estas y no dejas aire que respirar soy un chico de la calle camino la ciudad con mi guitarra sin molestar a nadie voy cortando cadenas estoy creciendo contra la miseria y alguna que otra pena pero pierdo el control llego a casa y escucho su voz siempre la misma cancion  nene nenene que vas a ser cuando seas grande nene nenene que vas a ser cuando seas grande estrella de rock and roll presidente de la nacion nene nenene que vas a ser cuando alguien aprete el boton  estoy casi condenado a tener exito para no ser un perro fracasado asi asi asi asi yo fui enseñado generaciones tras generaciones marchan a mi lado solo quiero jugar soy el sueño de mama y papa yo no les puedo fallar  nene nenene que vas a ser cuando seas grande nene nenene que vas a ser cuando seas grande estrella de rock and roll presidente de la nacion nene nenene que vas a ser cuando alguien aprete el boton nene nenene que vas a ser cuando seas grande  cuando seas grande nene nenene que vas a ser cuando seas grande cuando seas grande nene nenene que vas a ser cuando seas grande cuando seas grande nene nenene que vas a ser cuando seas grande cae la noche y amanece en paris en el dia en que todo ocurrio como un sueño de loco sin fin la fortuna se ha reido de ti ja ja  sorprendido espiando el lobo escapo aullando es mordido por el mago del siam  la luna llena sobre paris ha transformado en hombre a denisse  rueda por los bares del boulevard se ha alojado en un sucio hostal  mientras esta cenando junto a el se ha sentado una joven con la que ira a contemplar la luna llena sobre paris  algunos francos cobra denisse auuu lobo hombre en paris auuu su nombre es denisse  el hombre lobo esta en paris su nombre denisse la luna llena sobre paris ha transformado en hombre a denisse  mientras esta cenando junto a el se ha sentado una joven con la que ira a contemplar la luna llena sobre paris  ha transformado en hombre a denisse lobo hombre en paris no sabes como te deseo no sabes como te he soñado si tu supieras que me muero por tu amor y por tus labios  si tu supieras que soy sincero yo soy derecho y no te fallo si tu supieras lo que te quiero podria darte todo hasta mis ojos  pero tu ya tienes otro un tipo frio y aburrido un tonto que es un reprimido eso no te queda a ti no te va  oye mi amor no me digas que no y vamos juntando las almas oye mi amor no me digas que no y vamos juntando los cuerpos  conmigo tu alucinarias como no conmigo tu hasta el fin del mundo contigo yo me perderia contigo yo quiero todo y nada a medias  pero tu ya tienes otro tipo frio y aburrido un tonto que es un reprimido eso no te queda a ti no te va  oye mi amor no me digas que no y vamos juntando las almas oye mi amor no me digas que no y vamos juntando los cuerpos en la vida conoci mujer igual a la flaca coral negro de la habana tremendisima mulata cien libras de piel y hueso cuarenta kilos de salsa y en la cara dos soles que sin palabras hablan que sin palabras hablan  la flaca duerme de dia dice que asi el hambre engaña y cuando cae la noche baja a bailar a la tasca y bailar y bailar y tomar y tomar una cerveza tras otra pero ella nunca engorda pero ella nunca engorda  por un beso de la flaca daria lo que fuera por un beso de ella aunque solo uno fuera por un beso de la flaca daria lo que fuera por un beso de ella aunque solo uno fuera aunque solo uno fuera  moje mis sabanas blancas como dice la cancion recordando las caricias que me brindo el primer dia y enloquezco de ganas de dormir a su ladito porque dios que esta flaca a mi me tiene loquito ooh a mi me tiene loquito  por un beso de la flaca yo daria lo que fuera por un beso de ella aunque solo uno fuera por un beso de la flaca yo daria lo que fuera por un beso de ella aunque solo uno fuera  aunque solo uno fuera aunque solo uno fuera aunque solo uno fuera aunque solo uno fuera  aunque solo uno fuera  aunque solo uno fuera  aunque solo uno fuera aunque solo uno fuera aunque solo uno fuera aunque solo uno fuera  aunque solo uno fuera  aunque solo uno fuera  aunque solo uno fuera  aunque solo uno fuera aunque solo uno fuera aunque solo uno fuera se llama lola y tiene historia aunque mas que historia sea un poema su vida entera paso buscando noches de gloria como alma en pena detras de su manto de fria dama tenia escondidas tremendas armas para las batallas del cara a cara que con ventaja muy bien libraba le fue muy mal de mano en mano de boca en boca de cama en cama como una muñeca que se desgasta se queda vieja y la pena arrastra  oyeme mi lola mi tierna lola tu triste vida es tu triste historia pero que manera de caminar mira que soberbia en su mirar oyeme mi lola mi tierna lola tu triste vida es tu triste historia pero que manera de caminar mira que soberbia en su mirar oyeme mi lola mi tierna lola tu triste vida es tu triste historia  fue mujer serena hasta el instante de entregarse presta a sus amantes es tiempo de llanto es tiempo de duda de nostalgia y de su locura tienes el consuelo de saberte llena de cariño limpio y amor sincero por que nadie supo robar de tus besos eso que hoy te sobra y que nadie añora  es el tiempo de la arruga que no perdona es el tiempo de la fruta y la pintura acompaño a mi sombra por la avenida mis pasos se pierden entre tanta gente busco una puerta una salida donde convivan pasado y presente de pronto me paro alguien me observa levanto la vista me encuentro con ella y ahi esta ahi esta ahi esta ahi esta viendo pasar el tiempo la puerta de alcala  una mañana fria llego carlos iii con aire insigne se quito el sombrero muy lentamente bajo de su caballo con voz profunda le dijo a su lacayo ahi esta la puerta de alcala ahi esta ahi esta viendo pasar el tiempo la puerta de alcala lanceros con casaca monarcas de otras tierras fanfarrones que llegan inventando la guerra milicias que resisten bajo el no pasaran y el sueño eterno como viene se va y ahi esta ahi esta la puerta de alcala ahi esta ahi esta viendo pasar el tiempo la puerta de alcala  todos los tiranos se abrazan como hermanos exhibiendo a las gentes sus calvas indecente mandadas de mangante doscientos estudiantes inician la revuelta son los años sesenta y ahi esta ahi esta la puerta de alcala ahi esta ahi esta viendo pasar el tiempo la puerta de alcala  un travesti perdido un guardia pendenciero pelos colorados chinchetas en los cueros rockeros insurgentes modernos complacientes poetas y colgados aires de libertad y ahi esta la puerta de alcala ahi esta ahi esta viendo pasar el tiempo la puerta de alcala  miro de frente me pierdo en sus ojos sus arcos me vigilan su sombra me acompaña no intento esconderme nadie la engaña toda la vida pasa por su mirada mirala mirala mirala mirala mirala la puerta de alcala mirala mirala mirala mirala ella existio solo en un sueño el es un poema que el poeta nunca escribio en la eternidad los dos unieron sus almas para darle vida a esta triste cancion de amor a esta triste cancion de amor a esta triste cancion de amor  el es como el mar ella es como la luna y en las noches de luna llena hacen el amor y en la inmensidad los dos unieron sus almas para darle vida a esta triste cancion de amor a esta triste cancion de amor a esta triste cancion de amor  el es como un dios ella es como una virgen y los dioses les enseñaron a pecar y en la eternidad los dos unieron sus almas para darle vida a esta triste cancion de amor a esta triste cancion de amor a esta triste cancion de amor siento el calor de toda tu piel en mi cuerpo otra vez estrella fugaz enciende mi sed misteriosa mujer  con tu amor sensual cuanto me das haz que mi sueño sea una verdad dame tu alma hoy haz el ritual llevame al mundo donde pueda soñar  uhh debo saber si en verdad en algun lado estas voy a buscar una señal una cancion uhh debo saber si en verdad en algun lado estas solo el amor que tu me das me ayudara  al amanecer tu imagen se va misteriosa mujer dejaste en mi lujuria total hermosa y sensual  corazon sin dios dame un lugar en ese mundo tibio casi irreal debere buscar una señal en aquel camino por el que vas  uhh debo saber si en verdad en algun lado estas voy a buscar una señal una cancion uhh debo saber si en verdad en algun lado estas solo el amor que tu me das me ayudara  tu presencia marco en mi vida el amor lo se es dificil pensar en vivir ya sin vos corazon sin dios dame un lugar en ese mundo tibio casi irreal  uhh debo saber si en verdad en algun lado estas voy a buscar una señal una cancion uhh debo saber si en verdad en algun lado estas solo el amor que tu me das me ayudara estoy llorando en mi habitacion todo se nubla a mi alrededor ella se fue con un niño pijo tiene un ford fiesta blanco y un jersey amarillo  por el parque les veo pasar cuando se besan lo paso fatal voy a vengarme de ese marica voy a llenarle el cuello con polvos pica pica  sufre mamon devuelveme a mi chica o te retorceras entre polvos pica pica sufre mamon devuelveme a mi chica o te retorceras entre polvos pica pica  le he quemado su jersey y se ha comprado cinco o seis voy a destrozarle el coche lo tengo preparado voy esta noche  no te reiras nunca mas de mi lo siento nene vas a morir tu me quitaste lo que mas queria y volvera conmigo volvera algun dia  sufre mamon devuelveme a mi chica o te retorceras entre polvos pica pica sufre mamon devuelveme a mi chica o te retorceras entre polvos pica pica  sufre mamon sufre mamon devuelveme a mi chica o te retorceras entre polvos pica pica sufre mamon sufre mamon devuelveme a mi chica o te retorceras entre polvos pica pica tantas cosas en la mente me aterran el pensar en todo y nada de una vez el estar dormido el soñar con frio el permanecer perdido buscandote  tras los muros de mi casa tan fria que puedo pensar en algo para hacer calor el moverme me hace titubear y dudar pero esa imagen no se ira jamas  y el pensar en ti me hace recordar el encanto que provoca tu fragilidad quedarme sentado aqui me puede congelar el hablar de ti me puede delatar  podria gritar que me dejes beber de tu sangre  y el pensar en ti me hace recordar el encanto que provoca tu fragilidad quedarme sentado aqui me puede congelar el hablar de ti me puede delatar  podria gritar que me dejes beber de tu sangre  podria gritar que me dejes beber de tu sangre  podria gritar los analisis dan alcohol dicen que ha bebido nuestro conductor  debido a su mal estado al final hemos chocado despues de tanto ruido hemos salido como hemos podido el coche destrozado no entiendo nada estoy tan atontado  no ha habido graves heridos de esta hemos salido vivos  y es que siempre estamos viviendo de noche siempre tomando copas viajando en coche siempre acompañando a la madrugada que a veces nos enseña su mala cara  el disco esta cerrado y como un loco el se lo ha pasado en las curvas siempre derrapando continuamente se la esta jugando  unas luces vienen deslumbrando cierro los ojos y ya estoy rodando y un coche que pasa al lado se para a ver la que se ha armado  no ha habido graves heridos de esta hemos salido vivos  y es que siempre estamos viviendo de noche siempre tomando copas viajando en coche siempre acompañando a la madrugada que a veces nos enseña su mala cara quisiera que me dijeras una y otra ves te quiero baby te quiero y siempre te querre con esa lengua extranjera que me ablanda las piernas  que tienes boca de azucar eso ya lo se que besas con quemaduras de veneno y miel que me has cambiado no hay duda lo se tambien y me gusta  por eso voy a ser por ti por ti por ti eternamente bella bella con un hechizo de gitana sere la princesa encantada que te amara por siempre desesperadamente desesperadamente  eternamente bella bella y en plena noche de la iguana hago un hechizo de gitana para que sigas siempre desesperadamente enamorado de mi  dispara y ya estas dispuesto a morir por mi por que ten vendes tan caro dime ya que si tras esos lentes tan negros que demonios piensas  asi es la ruleta rusa echale valor de que te sirven las dudas has igual que yo si encuentro algo que gusta lo tomo y no me lo pienso  desde hoy prometo ser por ti por ti por ti luz roja es la luz luz de neon que anuncia el lugar baile kumbala bar y adentro la noche es musica y pasion  sol no entiendes lo que pasa aqui esto es la noche y de la noche son las cosas del amor el corazon a media luz siempre se entregara  mar todo el ambiente huele a mar mucho calor sudores en la piel sudor sabor a sal y en la pista una pareja se vuelve a enamorar  una brisa una caricia y en la pista una pareja se vuelve a enamorar un sabroso y buen danzon a media luz el corazon y en el kumbala todo es musica y pasion yo sere el viento que va navegare por tu oscuridad tu rocio beso frio que me quemara yo sere tormento y amor tu la marea que arrastra a los dos  yo y tu tu y yo no diras que no no diras que no no diras que no sere tu amante bandido bandido corazon corazon malherido sere tu amante cautivo cautivo sere  pasion privada dorado enemigo huracan huracan abatido me perdere en un momento contigo por siempre yo sere un hombre por ti renunciare a ser lo que fui yo y tu tu y yo sin misterio sin misterio sin misterio  sere tu amante bandido bandido corazon corazon malherido sere tu amante cautivo cautivo sere  pasion privada dorado enemigo huracan huracan abatido me perdere en un momento contigo por siempre sere tu heroe de amor sere el amante que muere rendido corazon corazon malherido  sere tu amante bandido bandido sere y en un oasis prohibido prohibido por amor por amor concebido me perdere en un momento contigo por siempre sere tu heroe de amor no tengo ganas de hablar no tengo mas que decir que puedo ya declarar sobre lo de berlin no voy a hablar de vietnam no se pelear ni mentir solo me gusta mirar debajo de tu piel no es solo una escusa  te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto  aunque el cielo se ponga rojo de tanto lucir quiero contar hasta diez quiero cantar para mi vas a ayudarme a volar vas a dejarme subir solo te pido mirar solo te pido mirar debajo de tu piel es lo que me gusta  te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto  y bombardearan una noche el aire traera otro olor no comprenderan que es lo que paso el cielo sera solo esta vez solo vos y yo solo vos y yo solo vos y yo no es solo una escusa  te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto  te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto te quiero tanto uo te quiero tanto es por amor que al mudo yo le hago frente y por amor si caigo me levanto siempre y al costado del camino veo angeles caidos  es por amor que nunca voy a abandonarte y por amor espero lo que vas a darme y al costado del camino veo angeles caidos  hay una fiesta y es esta noche baila conmigo asi te pido dame uh uh uh mirame uh uh uh  es por amor que uno hace lo que siente y por amor yo sigo y sigo aunque me cueste y al costado del camino veo angeles caidos  hay una fiesta y es esta noche baila conmigo asi te pido dame uh uh uh mirame uh uh uh si yo fuera mujer tendria que empezar por abrir del todo  el telon del fondo del mito virginal y del hombre macho  si yo fuera mujer podria publicar miles de razones del secreto de don juan las carcajadas nos harian llorar  si yo fuera mujer a mi no me tocaba un tonto con coche musica de fondo y pose de john wayne me daria el gusto de violarle a el  y asi nada de igualdad muerte al violador premio a la infidelidad desearia tomar eso que ellos llaman nuestra libertad si yo fuera mujer si yo fuera mujer yo me tendria que querer  si yo fuera mujer no me casaria nada de sosten nada de pastillas que las tome el y ahora que lo sabes ahora tomame  y asi nada de igualdad muerte al violador premio a la infidelidad desearia tomar eso que ellos llaman nuestra libertad si yo fuera mujer si yo fuera mujer yo me tendria que querer  y asi nada de igualdad muerte al violador premio a la infidelidad desearia tomar eso que ellos llaman nuestra libertad si yo fuera mujer si fuera mujer yo me tendria que querer  si yo fuera mujer tendria que empezar por abrir del todo el telon del fondo del mito virginal y del hombre macho  si yo fuera mujer si yo fuera mujer si yo fuera mujer la policia te esta extorsionando dinero pero ellos viven de lo que tu estas pagando y si te tratan como a un delincuente ladron no es tu culpa dale gracias al regente  hay que arrancar el problema de raiz y cambiar al gobierno de nuestro pais a la gente que esta en la burocracia a esa gente que le gustan las migajas  yo por eso me quejo y me quejo porque aqui es donde vivo y yo ya no soy un pendejo  que no wachas los puestos del gobierno hay personas que se estan enriqueciendo gente que vive en la pobreza nadie hace nada porque a nadie le interesa  es la gente de arriba te detesta hay mas gente que quiere que caigan sus cabezas si le das mas poder al poder mas duro te van a venir a coger  porque fuimos potencia mundial somos pobres nos manejan mal  dame dame dame dame todo el power para que te demos en la madre gimme gimme gimme gimme todo el poder so i can come around to joder dame dame dame dame todo el power para que te demos en la madre gimme gimme gimme gimme todo el poder so i can come around to joder damele damele damele damele todo el poder damele damele damele damele todo el power  asi es puto fuck you puto baboso  porque no nacimos donde no hay que comer no hay porque preguntarnos como le vamos a hacer si nos pintan como unos huevones no lo somos viva mexico cabrones  que se sienta el power mexicano que se sienta todos juntos como hermanos porque somos mas jalamos mas parejo por que estar siguiendo a una bola de pendejos que nos llevan por donde les conviene y es nuestro sudor lo que los mantiene los mantiene comiendo pan caliente ese pan es el pan de nuestra gente  dame dame dame dame todo el power para que te demos en la madre gimme gimme gimme gimme todo el poder so i can come around to joder dame dame dame dame todo el power para que te demos en la madre gimme gimme gimme gimme todo el poder so i can come around to joder dame dame dame dame el poder como dame dame dame dame todo el power dame dame dame dame el poder como dame dame dame dame todo el power  el pueblo unido jamas sera vencido el tito y el huidos jamas seran vencidos  dame dame dame dame el poder dame dame dame dame todo el power tengo roto el corazon desarmada la razon podras tener mil romances nunca con sinceridad  tengo tanto para amar es como una enfermedad no tengas miedo a enamorarte no huyas no huyas de mi dolor de amor quiero contagiarte no huyas no huyas de mi soy un cometa que vuela a marte esta noche  puedo hacerte sentir bien tres seis cinco junto a mi hay quienes te prometen oro yo te ofrezco el corazon  tengo tanto para amar es como una enfermedad no tengas miedo a enamorarte no huyas no huyas de mi dolor de amor quiero contagiarte no huyas no huyas de mi soy un cometa que vuela a marte  girando volando de amor girando volando de amor  no no huyas de mi no no no huyas de mi  girando volando por ti girando volando de amor girando volando a marte  no tengas miedo a enamorarte no huyas no huyas de mi dolor de amor quiero contagiarte no huyas no huyas de mi solos solo tu y yo soy un cometa que vuela a marte soy un cometa que vuela a marte esta noche hoy todo esta fuera de sector tal vez no estuvo nunca mejor nadie regula mi decision nadie transforma mi satisfaccion  la mente se adelanta el cuerpo quiere ceder aunque no rien ni lloran todo puede suceder si tu quieres otra vez  hoy todo esta fuera de sector tu mente esta fuera de control tu cuerpo esta fuera de control hoy todo esta fuera de sector  afuera es noche y brilla la ciudad hay gente demente que siempre busca mas aunque ya no queda nada en que gastar con demasiada paz y tanta soledad  la mente se adelanta el cuerpo quiere ceder aunque no rien ni lloran todo puede suceder como la primera vez  hoy todo esta fuera de sector tu mente esta fuera de control tu cuerpo esta fuera de control hoy todo esta fuera de sector  hoy todo esta fuera de sector tal vez no estuvo nunca mejor nadie regula mi decision nadie transforma mi satisfaccion  fuera de sector fuera de sector tu imaginacion me programa en vivo llego volando y me arrojo sobre ti salto en la musica entro en tu cuerpo cometa halley copula y ensueño  tuyo tuyo luna de miel luna de miel  tu madre no podra interceptarme perfecto hermoso veloz luminoso  caramelos de miel entre tus manos te prometo una cita ideal adorando la vitalidad  tuyo tuyo luna de miel luna de miel  tu imaginacion me programa en vivo llego volando y me arrojo sobre ti salto en la musica entro en tu cuerpo cometa halley copula y ensueño  tuyo tuyo luna de miel luna de miel  caramelos de miel entre tus manos te prometo una cita ideal adorando la vitalidad  gozo tuyo luna de miel luna de miel te salgo a buscar y no te puedo encontrar ya tus amigas me han dicho por que  llegando a la fiesta te veo besandote con otro yo no lo quiero hoy te tengo que olvidar  decias que me querias que no era facil poderme olvidar regresame el retrato se acabo  lo siento es tarde comprende este es el final regresame el retrato se acabo  llegando a la fiesta te veo besandote con otro yo no lo quiero hoy te tengo que olvidar  decias que me querias que no era facil poderme olvidar regresame el retrato se acabo  es el final de nuestro amor no voy en tren voy en avion no necesito a nadie a nadie alrededor no voy en tren voy en avion no necesito a nadie a nadie alrededor  porque no hay nadie que mi piel resista porque no hay nadie que yo quiera ver no veo television ni las revistas no veo ya nada que no pueda ser  por eso yo no voy en tren voy en avion no necesito a nadie a nadie alrededor no voy en tren voy en avion no necesito a nadie a nadie alrededor  cuando era niño nunca fui muy listo tocaba el piano como un animal yo se que algunos piensan que soy mixto pero yo tengo personalidad  yo soy de la cruz del sur soy el que cierra y el que apaga la luz yo soy de la cruz del sur aqui y en everywhere  no voy en tren voy en avion en algun lugar de un gran pais olvidaron construir un hogar donde no queme el sol y al nacer no haya que morir y en las sombras mueren genios sin saber de su magia concedida sin pedirlo mucho tiempo antes de nacer  no hay camino que llegue hasta aqui y luego pretenda salir con el fuego de el atardecer arde la hierba  en algun lugar de un gran pais olvidaron construir un hogar donde no queme el sol y al nacer no haya que morir un silbido cruza el pueblo y se ve un jinete que se marcha con el viento mientras grita que no va a volver  y la tierra aqui es de otro color el polvo lo debe saber los hombres ya no saben si lo son pero lo quieren creer las madres que ya no saben llorar ven a sus hijos partir la tristeza aqui no tiene lugar cuando lo triste es vivir me veras volar por la ciudad de la furia donde nadie sabe de mi y yo soy parte de todos nada cambiara con un aviso de curva en sus caras veo el temor ya no hay fabulas en la ciudad de la furia  me veras caer como un ave de presa me veras caer sobre terrazas desiertas te desnudare por las calles azules me refugiare antes que todos despierten me dejaras dormir al amanecer entre tus piernas entre tus piernas sabras ocultarme bien y desaparecer entre la niebla entre la niebla un hombre alado extraña la tierra me veras volar por la ciudad de la furia donde nadie sabe de mi y yo soy parte de todos con la luz del sol se derriten mis alas solo encuentro en la oscuridad lo que me une con la ciudad de la furia  me veras caer como una flecha salvaje me veras caer entre vuelos fugaces buenos aires se ve tan susceptible es el destino de furia es lo que en sus caras persiste me dejaras dormir al amanecer entre tus piernas entre tus piernas sabras ocultarme bien y desaparecer entre la niebla entre la niebla un hombre alado prefiere la noche  me veras volver me veras volver te estan buscando matador  me dicen el matador naci en barracas si hablamos de matar mis palabras matan no hace mucho tiempo que cayo el leon santillan y ahora se que en cualquier momento me la van a dar mah matador mah matador donde estas matador mah matador mah matador  me dicen el matador me estan buscando en una fria pension los estoy esperando agazapado en lo mas oscuro de mi habitacion fuzil en mano espero mi final mah matador mah matador mah matador mah matador la cana te busca matador la cana te prende matador  hey hey hey hey  matador matador donde estas matador matador matador no te vayas matador matadooooooor oh yeah matadormatador  viento de libertad sangre combativa en los bolsillos del pueblo la vieja herida de pronto el dia se me hace de noche murmullos corridas y el golpe en la puerta llego la fuerza policial  mah matador mah matador mira hermano en que terminaste por pelear por un mundo mejor que suenan son balas me alcanzan me atrapan resiste victor jara no calla matador matador matador te esta buscando matador matador matador te estan matando matador oh yeah matador matador valiente matador  me dicen el matador de los  barrios porteños no tengo por que tener miedo mis palabras son balas balas de paz balas de justicia soy la voz de los que hicieron callar sin razon por el solo hecho de pensar distinto ay dios santa maria de los buenos aires si todo estuviera mejor matador matador si todo estuviera mejor matador matador a donde vas matador matador oh yeah matador matador voy a tomar por vos pasa un trago para olvidar que el miedo te comio los pies y que ahora sos un tipo mas y que poco a poco te fuiste yendo y que poco a poco te fuiste yendo de nuestro lugar  te sienta bien el sol te sienta bien ser cool te sienta bien el mal te sienta bien ser dios te sienta bien mentir y decir que te fuiste yendo de nuestro lugar  que es lo que ha pasado con tu corazon ya no marca el paso que marcaba ayer nunca fuiste libre y esa es la razon siempre hay un idiota para convencer hablas toda la noche como un boy scout hablas sobre mi vida como tu papa  los cadillacs tocando para vos los cadillacs tocando para vos los cadillacs tocando para vos los cadillacs tocando para vos mama compro y se le rompio el forro del que naci yo la plata no pudo juntar y el embarazo cancelar  ella invirtio en mi educacion pero con una condicion porque le tuve que jurar que de vieja no la iba a internar  dificil de creer dificil de explicar  dijo un troyano ojo con un griego que trae regalos  sea con dinero o no siempre se paga un favor y si veo que algo es facil yo dudo enseguida  pague antes o despues la cuenta va a aparecer  y esta claro de que nada es gratis en la vida  papa pago una mina en un bar cuando me llevo a debutar y por curarme se endeudo de la peste que me contagio  si si ya se esperma done pero pobrecito el destinatario yo tengo alzheimer hereditario  y como el jefe comento despues que mi sueldo aumento  si la limosna es de cuatia hasta el santo desconfia  sea con dinero o no siempre se paga un favor y si veo que algo es facil yo dudo enseguida  pague antes o despues la cuenta va a aparecer  y esta claro de que nada es gratis en la vida si sera asi que lo jodi al diablo cuando le vendi mi alma que no vale un billete se la canjee por un clarete  ni honorario ni voluntario soy un sicario y cobro salario y no pidan solidaridad que yo no hago caridad  no es gratis mi salud ni gratis sera mi ataud  si es que no pide su tajada es que no vale nada  sea con dinero o no siempre se paga un favor y si veo que algo es facil yo dudo enseguida  pague antes o despues la cuenta va a aparecer  y esta claro de que nada es gratis en la vida   nada es gratis en la vida  nada es gratis en la vida  nada es gratis en la vida  nada es gratis en la vida hoy estoy raro y no entiendo por que si nada extraño me tuvo a maltraer hoy estoy raro no se lo que hacer  sera que hoy me puse a recordar los dias de mi infancia cuando siempre estaba mal hijo unico de la casualidad mi padre era hippie y mi madre era punk  ah capazfue por esa niñera que para que no llorara ponia en mi mamadera valium y saliun dia con sus amigos y volvio con esa manga de drogados y acelerados en un rito satanico despues de torturar a mi hamster cocinaron fue un infierno me lo hicieron probar y no era tierno  depende ahi yo era un jopende como dijo mi tio que es un tipo que me entiende el que no sufre no aprende y ahi me bajo un diente de una patada y me robo la plata que el raton dejo bajo mi almohada todos se reian cuando arrastraba la erre mi abuela me pedia que si moria no la entierre y que subiera mas quizas quizas quizas  hoy estoy raro y no entiendo por que si nada extraño me tuvo a maltraer hoy estoy raro no se lo que hacer sentarme a esperar que se me pase y chau  y ta capaz fue que quede marcado por ser hijo de padres divorciados que tarado no lo habia pensado pero si fuera asi todos seriamos traumados  y yo a media luz ponia un blues y la abuela a jesus le pedia que gardel no fuera de toulousse yo pinchaba con su cruz los granos de pus por mi alergia al mousse  achus sera que fui a cenar con la novia de mi padre que me invito pero me hizo lavar las cacerolas y al ver que mi hermana desfilaba medio en bolas me dijo mira las modelos son todas trolas  y se enfurece justo ella que cuando toma se emputece me tuve que rajar cuando despues del cuarto vino me empezo a toquetear y se rio y le vinohipo  y me conto como anticipo que va a dejar al viejo por el tipo que le pago la lipo sera por eso que estoy sensible la vida es impredecible  hoy estoy raro y no entiendo por que si nada extraño me tuvo a maltraer hoy estoy raro no se lo que hacer sentarme a esperar que se me pase y chau  capaz que no le hizo gracia al de la farmacia cuando dije que yo defiendo a muerte a la eutanasia decia que si todos se morian se fundia y me tiro con un frasco de homeopatia  o en una de esas como decia el peyote estoy mal de la cabeza pero no el doctor que me curo me juro que la herida del frascazo en la nuca ya cicatrizo  sera ese copetin que tome en el cafetin picando un salamin escuchando led zepellin o fue esa moza con pinta de viciosa que de babosa echo en mi vaso alguna cosa  que pedazo de guaso si rompio el vaso cuando mi faso le quemo el brazo y por mi torpeza dejo el barril gigante de cerveza mal cerrado y el bar quedo inundado que acertado pensar que yo me quise levantar a la nami hablando del tsunami y baldeando me dijo viste volve por donde viniste el cielo no existe  hoy estoy raro y no entiendo por que si nada extraño me tuvo a maltraer hoy estoy raro no se lo que hacer sentarme a esperar que se me pase y chau no tengo penas ni tengo amores y asi no sufro de sinsabores con todo el mundo estoy a mano como no juego ni pierdo ni gano  no tengo mucho ni tengo poco como no opino no me equivoco y como metas yo no me trazo nunca supe lo que es un fracaso  alegria y tristeza es lo mismo para mi que no me interesa sentir porque en el angulo de la vida yo he decidido ser la bisectriz  ooohh asi soy yo ooohh asi soy yo ooohh asi soy yo ooohh asi soy yo  no me involucro en la pareja y asi no sufro cuando me dejan a nadie quise jamas en serio y entonces nunca lloro en los entierros  no pasa nada si no me muevo por eso todo me chupa un huevo y no me mata la indecision si should i stay or should i go  ojos que no ven corazon que no siente dijo un ciego cornudo una vez y no soy como hamlet perez no me importa nada si ser o no ser  ooohh asi soy yo ooohh asi soy yo ooohh asi soy yo ooohh asi soy yo  diran algunos ay que insensible otros diran que vacio y simple y esas palabras las lleva el viento como no escucho no me caliento  no estoy ni arriba ni abajo ya ni mejoro ni voy a empeorar y como nunca empiezo nada no me pone ansioso poder terminar  ooohh asi soy yo ooohh asi soy yo ooohh asi soy yo ooohh asi soy yo yendo un weekend a lo de damian tenia urgencia de hablar con el man camine porque pinche mi van vi una mina de la que soy fan  una que sale por el canal sony en una serie que esta con un pony y en mi casa del barrio marconi siempre la veo tomandome un johnny  la salude pero me hecho flit porque el programa era en mtv hacia un spot de care free y un jingle de los jeans lee  le dije a mi me gusta el rock pero quedo en estado de shock cuando escribi en una hoja de block que era mas fea que el señor spock  y que se rellena el sutien con corn beef y chow mien y a pesar de que usa channel toma un coctel con nafta de shell  el security se puso heavy era malo pero usaba levis y me tiro desde la limousine en el ojo un vaso con gin  ahh ahh yendo a la casa de damian ahh ahh camino por el boulevard ahh ahh yendo a la casa de damian no se si es que ya no veo que ya no entiendo porque me cuesta tanto llegar  cruzando la calle quede de flash cuando vi dos niñas fumando hash escuchaban trash y the clash jugando quien tomaba mas splash  y como una vez en un vernisagge me dio un ataque de surmenage cuando dijeron por diez pesos cash hacemos juntos los tres un menash  de los nervios me vino un tic en el fondo siempre fui un freak le di fuego con yesquero bic pero me parecio poco chic  que pasaran por una crush con un nerd de media de plush que le pinto los labios con rouge yo le escupi su tshirt de bush  con mi gargajo en la cara de george se subio con las chicas a un porsche  se pensaba que era un tipo vip masticando una papa chip cuando empezo a hacer un strip y quedaba solo en slip le clavo en el ojo un clip y con tu tumba va a decir rip  ahh ahh yendo a la casa de damian ahh ahh camino por el boulevard ahh ahh yendo a la casa de damian no se si es que ya no veo que ya no entiendo porque me cuesta tanto llegar  era happy hour en el cabaret era fashion y tenia moquete como un pub cool y con pool el dueño es de liverpool  y despues de un breve impasse entre a ver un show con freepass de un master que tocaba jazz a pesar de tener un bypass  vino a hablarme uno medio gay yo ponia stop y el ponia play  le gustaba el big mac y tupac vendia crack y tomaba prozac y grito escupiendo un snack el master hace playback lo destriparon como hacia jack sin poder terminar su cognac  pero cayeron desde un penthouse en mi ojo un teclado y un mouse  ciego y perdido por el stress peor que en un secuestro express yo que en ingles solo se decir yes pense en el libro de herman hess  soy un loser como boy scout y de la vida me declare out  ahh ahh yendo a la casa de damian ahh ahh camino por el boulevard ahh ahh yendo a la casa de damian no se si es que ya no veo  ahh ahh ahh ahh ahh ahh no se si es que ya no veo que ya no entiendo porque me cuesta tanto llegar papito tiene que ir a trabajar no quiere papa no quiere ir pero tiene que ir igual papito dice el ocio es lo que papi adora papito no nacio para las  horas  papa no quiere trabajar pero lo obligan papito prefiere quedarse panza arriba papito quiere una vida mas relajada papa quiere quedarse en casa y no hacer nada  pobre papa pobre papa pobre papa pobre papa a el no le gusta trabajar pobre papito pobre papito pobrecito papa pobre papa nunca lo dejan descansar  papito no quiere trabajar tan seguido papa preferiria ser un mantenido papa piensa que un dia manda todo al carajo pero no encara eso porque es mucho trabajo  pobre papa pobre papa pobre papa pobre papa a el no le gusta trabajar pobre papito pobre papito pobrecito papa pobre papa nunca lo dejan descansar  siempre pense que trabajar no era moderno si el trabajo es salud que trabajen los enfermos si el trabajo es salud que trabajen los enfermos ya tuve que ir obligado a misa ya toque en el piano para elisa ya aprendi a falsear mi sonrisa ya camine por la cornisa ya cambie de lugar mi cama ya hice comedia ya hice drama fui concreto y me fui por las ramas ya me hice el bueno y tuve mala fama  ya fui etico y fui erratico ya fui esceptico y fui fanatico ya fui abulico fui metodico ya fui impudico y fui caotico  ya lei arthur conan doyle ya me pase de nafta a gasoil ya lei a breton y a moliere ya dormi en colchon y en sommier ya me cambie el pelo de color ya estuve en contra y estuve a favor lo que me daba placer ahora me da dolor ya estuve al otro lado del mostrador  y oigo una voz que dice sin razon vos siempre cambiando ya no cambias mas y yo estoy cada vez mas igual ya no se que hacer conmigo  ya me ahogue en un vaso de agua ya plante cafe en nicaragua ya me fui a probar suerte a usa ya jugue a la ruleta rusa ya crei en los marcianos ya fui ovolactovegetariano sano fui quieto y fui gitano ya estuve tranqui y estuve hasta las manos  hice el curso de mitologia pero de mi los dioses se reian orfebreria lo salve raspando y ritmologia aqui la estoy aplicando ya probe ya fume ya tome ya deje ya firme ya viaje ya pegue ya sufri ya eludi ya hui ya asumi ya me fui ya volvi ya fingi ya menti y entre tantas falsedades muchas de mis mentiras ya son verdades hice facil las adversidades y me complique en las nimiedades  y oigo una voz que dice con razon vos siempre cambiando ya no cambias mas y yo estoy cada vez mas igual ya no se que hacer conmigo  adentro  ya me hice un lifting me puse un piercing fui a ver al dream team y no hubo feeling me tatue al che en una nalga arriba de mami para que no se salga ya me rei y me importo un bledo de cosas y gente que ahora me dan miedo ayune por causas al pedo ya me empache con pollo al spiedo  ya fui al psicologo fui al teologo fui al astrologo fui al enologo ya fui alcoholico y fui lambeta ya fui anonimo y ya hice dieta ya lance piedras y escupitajos al lugar donde ahora trabajo y mi legajo cuenta a destajo que me porte bien y que arme relajo  y oigo una voz que dice sin razon vos siempre cambiando ya no cambias mas y yo estoy cada vez mas igual ya no se que hacer conmigo  y oigo una voz que dice con razon vos siempre cambiando ya no cambias mas y yo estoy cada vez mas igual ya no se que hacer conmigo para poder dormir tengo que estar sedado para ir a estudiar tengo que estar tomado  en la navidad tengo que estar dopado para no pensar tengo que estar boleado  al trabajo tengo que ir sedado a la provision tengo que ir tomado  a lo de mi madre tengo que ir dopado si salgo de casa tengo que ir boleado  y no me puedo quejar despues de todo no me va tan mal llevando una vida asi tan natural  para funcionar tengo que estar sedado si quiero agradar tengo que estar tomado  para no enloquecer tengo que estar dopado para sentir placer tengo que estar boleado  a mi cumpleaños tengo que ir sedado cualquier decision la tomo dopado  a pagar impuestos tengo que ir dopado si tengo un velorio tengo que ir boleado  y no me puedo quejar despues de todo no me va tan mal llevando una vida asi tan natural llevando una vida asi tan natural  ahhhh  para no llorar tengo que estar sedado para no arrugar tengo que estar tomado  para olvidar tengo que estar dopado para recordar tengo que estar boleado  y no me puedo quejar despues de todo no me va tan mal llevando una vida asi tan natural llevando una vida asi tan natural llevando una vida asi tan natural  ahhhh  tengo que estar sedado tengo que estar tomado tengo que estar dopado tengo que estar boleado  tengo que estar sedado tengo que estar tomado tengo que estar dopado para poder vivir tengo que estar boleado un invierno que dolia el frio mi cuerpo ya no era el mio iba en el omnibus resfriado mirando por el vidrio empañado  era linda aunque con mal aliento pero le cedi la mitad de mi asiento lo lamento me dijo con acento al lado de un degenerado no me siento  ah rubia te hizo mal la lluvia o tenes la mente turbia soñas que te sigue un paparazzi con lentes negros de noche pareces un nazi no te acompaño el sentimiento vas a morir de un ataque de pensamientos y le grite en la cara congelada otra rubia tarada  uh oh oh oh oh alguien que de calor uh oh oh oh oh le pido por favor uh oh oh oh oh maldito invierno del   me note el ganglio inflamado y un auto no freno porque estaba mojado atropello a un niño sin piedad lo que mata es la humedad como hermano menor habia heredado solo este buzo agujereado y sabia que al tipo de al lado le sobraba un acolchado  cuando lo vi caminando por la acera de enfrente lo fui llamando primero hizo como pilar miro despues como robinson cruzo pero me dijo señorito que en el acolchado dormia su conejito que sabra lo que es un ghetto otro ecologista cheto  uh oh oh oh oh alguien que de calor uh oh oh oh oh le pido por favor uh oh oh oh oh maldito invierno del   iba en la niebla con mi dilema en el pulmon me salio un edema y con mi aspecto de calavera fui a que me viera una enfermera  parecia que yo deliraba decia que era porque de fiebre volaba volar dije mirando un termo el sueño de los hombres y los pajaros enfermos  esa curandera rea que en una asamblea de la oea el higado me dejo como pate porque me contagio con hepatitis b le descubri a esa rastrera un muñeco vudu mio en la heladera le llene de flema la caldera otra perra traicionera  uh oh oh oh oh alguien que de calor uh oh oh oh oh le pido por favor uh oh oh oh oh maldito invierno del   va a ser una larga espera hasta que llegue la primavera aunque de frio voy tiritando yo me sigo calentando  uh oh oh oh oh alguien que de calor uh oh oh oh oh le pido por favor uh oh oh oh oh maldito invierno del  el profesor pidio a su alumna que le repita aquella oscura elegia densa e ignota voy a hacer un playback de rey y los de ricota en el karaoke de mi noviecita  y mientras ella el curioso poema recita le va falsificando el pasaje aereo voy a hacer un playback de soda stereo en el karaoke de mi noviecita  en el karaoke de mi noviecita ella me descifra y despues se complica en el karaoke de mi wachecita playback de mi vida cancion problemita  el profesor pidio silencio a su favorita para tener un solo minuto de vida tranqui voy a hacer un playback de atahualpa yupanqui en el karaoke de noviecita  en el karaoke de mi noviecita ella me descifra y despues se complica en el karaoke de mi wachecita playback de mi vida cancion problemita  esa noche me tome hasta el agua bendita mi penultima curva y para siempre me perdi voy a hacer un playback de giuseppe verdi en el karaoke de noviecita  en el karaoke de mi noviecita ella me descifra y despues se complica en el karaoke de mi wachecita playback de mi vida cancion problemita todo lo que me gusta es pecado o hace mal todo lo que me gusta es muy caro o ilegal me mete en problemas que no tienen solucion se me vuelve peligroso o trae una complicacion entonces no se nunca que tengo que hacer me pregunto y no me puedo responder  porque si me hace bien porque si me hace bien porque si me hace bien me hace mal  todo lo que me da placer es raro o inmoral todo lo que me da placer no se puede contar y ando haciendo cosas que no puedo impedir y a veces al despertarme me tuve que arrepentir entonces no se nunca que tengo que hacer me pregunto y no me puedo responder  porque si me hace bien porque si me hace bien porque si me hace bien me hace mal  porque lo prohibido para mi es mejor pero despues me hace sentir peor entonces no se nunca que tengo que hacer me pregunto y no me puedo responder  porque si me hace bien porque si me hace bien porque si me hace bien me hace mal  y como veo que ya es tarde para decidir me tomo el ultimo trago y me acuesto a dormir me tomo el ultimo trago y me acuesto a dormir yo vivo en un pueblo podrido en donde todo esta podrido y voy de noche siempre a oscuras caminando entre la basura  no voy a llegar muy lejos en un omnibus lleno de viejos porque me asaltan con un caño delincuentes de doce años  asi quiero estar  los zapatos se me mojan pisando las baldosas flojas y la calle no me da tregua esquivando bosta de yegua  y a los chorros tanto les da si es facil comprar la autoridad y cuando en casa busco abrigo tengo que entrar pateando mendigos  asi quiero estar  aca ya no hay nada que hacer el que se quedo es porque no se fue y en la esquina hay feo olor si no hace frio hace calor  lunes de noche no hay donde ir igual mejor para que salir si me pegan los vecinos si no les doy plata para el vino  y si me pregunta algun podrido por que no te vas de este pueblo podrido le digo no me hagas poner violento y escucha lo que estoy diciendo  asi quiero estar las manos apoyadas en la mesa las rotulas temblando en el calor y en el tercer impulso se enderezan la van llevando  las casa tiene puertas muy pesadas y el cuarto esta lejos del comedor por el pasillo se van sosteniendo la van llevando  con mucho esfuerzo se abre la ventana el polvo iluminado por el sol se van acomodando en os sillones la van llevando  los arboles tapan el paisaje y el mar esta en las chapas de un galpon y mientras van mirando lo que pueden se van quedando  y vendran autos nuevos y colchones blandos y vendran a buscarnos y a sacarnos a pasear  el personal muy tarde fue alertado inutil la carrera en el calor se van distribuyendo en la vvereda y van buscando  el dia transcurre sin novedades y vuelven derrrotados por el corredor inventan una excusa para el mundo y la van llevando  y vendran autos nuevos y colchones blandos y vendran a buscarnos y a sacarnos a pasear vengan vengan siganme vamos todos juntos todos a la vez siempre hacia adelante no importa para que cero compromiso cero estres  salgan del agujero y recorramos el camino arrasando a nuestro paso devorando sin respiro una marabunta sin discurso ni sentido aca el que piensa pierde el que piensa esta perdido  ya no hay mañana ni ayer solo es lo que pase hoy y sin logica y razon aca todos queremos lo mismo  y ellos nos ven deambular sintiendo el miedo en la piel porque nunca van a saber de donde venimos  somos su imagen mas real lo que nunca esperaron ver su reflejo mas aterrador que los habra de convencer que hay poco por hacer en este apocalipsis zombi  ah este simulacro virtual copiar y pegar usar y tirar seguimos la jauria la horda desalmada exigiendo mas de todo pero sin pensar en nada  ellos nos crearon pero ahora nos tienen miedo porque no pueden manipular lo que queremos solo por instinto es que vamos al extremo y nos multiplicamos por contagio y sin deseo  y no pueden tolerar que nos resbale el poder y con su falsa moral nunca podran someternos  porque este virus letal les roba su identidad igual eso era normal antes de aparecernos  somos su imagen mas real lo que nunca esperaron ver su reflejo mas aterrador que los habra de convencer que hay poco por hacer en este apocalipsis  zombi filmando su propia sombra zombi aplaudiendo al zombi de moda zombi automata zombi mediatico zombi viral zombi superstar zombi que mira a otro zombi sin alma que le dice desde la pantalla  no seas asi dejate morder  somos su imagen mas real lo que nunca esperaron ver su reflejo mas aterrador que los habra de convencer que hay poco por hacer en este apocalipsis zombi  no seas asi dejate morder no seas asi dejate morder  agregar a la playlist tamaño a a cifrado imprimir corregir nada por aqui nada por alla nada que decir nada que explicar hoy no me va a ver ni el sol nada que mostrar nada que fingir nada que juzgar nada que eludir hoy nadie va a oir mi voz  tantas luces tantas miradas que tienen tanto para mirar tanta oscuridad tanta oscuridad  porque es cierto que me siento invisible las veces que prefiero que me puedan ver y en el fondo solo busco que me encuentren las veces que prefiero desaparecer  siento el poder de ver sin ser visto cuando nadie se fija en mi es cuando se que existo no soy mefisto eh ni el anticristo ah  no me oculto por placer sino por necesidad como houdini impredecible sin magia ni hechizo me vuelvo invisible y cavo impasible la trinchera de mi guerra suplicando tragame tierra  puedo ser real puedo ser ficcion solo material o solo ilusion pero tengo el control  y aunque se que nunca lo voy a ver se que hay alguien mas que debe tener la misma intencion que yo  lo esencial no lo ven los ojos por eso hay dias que elijo no estar  y esa es mi verdad y esa es mi verdad  porque es cierto que me siento invisible las veces que prefiero que me puedan ver y en el fondo solo busco que me encuentren las veces que prefiero desaparecer  me he acostumbrado a ser transparente entre la multitud que no me ve aunque este presente  y que me siento ausente solo cuando me esfumo envuelto en mi bomba de humo me describio wells me pinto dali pero nadie entiende porque soy asi si preguntan como hago nadie contesta no todo tiene respuesta  porque es cierto que me siento invisible las veces que prefiero que me puedan ver y en el fondo solo busco que me encuentren las veces que prefiero desaparecer las veces que prefiero desaparecer las veces que prefiero desaparecer no lo nombren no  toquen madera y quemen benjui miren quien se acerca miren quien viene ahi es el el yeta el que agita avisperos el que todos dicen que es un pajaro de mal aguero  su presencia arruina cualquier celebracion y siempre al invocarlo una desgracia sucedio dicen que es asi que asi fue y sera y que atrae desastres como si fuera un iman  que no nos vea ni que no nos toque que a nadie se le ocurra saludar no vayan a gritar su nombre porque llama a la fatalidad  no lo nombren no  todo lo que toca lo echa a perder igual que el rey midas pero al reves fue el lo acusan cuando pasa algo grave pero lo cierto es que en verdad nadie sabe si el sabe  cuando su fama comenzo como el rumor se propago quien fue el primero que lo estigmatizo porque una vez marcado siempre lo señalaran quien se hace piedra piedra morira  toda la vida cargara ese peso y ese peso acabara con el y un poco en broma un poco en serio sera el blanco de una risa cruel  no lo nombren no  no tiene explicacion y es antiracional como en la inquisicion cazando brujas por cazar y quien dice que noque uno no sera tambien sin justificacion otro innombrable a quien temer  escondemos en un saco roto la cobardia de no aceptar cargandole la culpa a otros de las cosas que nos salen mal  no lo nombren no tranquilo ya se que estas en un lio y que todo es hastio sombrio vacio y el frio te parte vine para ayudarte y le traje un masaje a tu alma un vendaje a tu orgullo un arrullo que aquiete tu alto voltaje  aqui estoy para apaciguarte y tratar de que mi voz y mi presencia te impulsen la paciencia tiene la raiz amarga pero da frutos dulces  calma vladimir son cosas que pasan respira bien hondo y mantene la calma calma vladimir no pierdas el tino para razonar hay que estar tranquilo  es feo creeme que te creo ese olor a nada el deseo en cero y sentis que es un placebo lo que ves y ois por ahi y decis que nadie te quiere asistir que nadie te puede entender que es facil hablar con cordura sin estar en tu piel  vine para darle a tu espiritu un mensaje que lo relaje y lo tranquilice uno es dueño de lo que calla pero esclavo de lo que dice  calma vladimir son cosas que pasan respira bien hondo y mantene la calma calma vladimir no pierdas el tino para razonar hay que estar tranquilo  para de gritar para de correr no dramatices pone tu infierno en el freezer para que tu ira exorcice tan solo eso quise pero no me dejas me estas poniendo nervioso me estas haciendo enojar no entendiste nada lo que te quise explicar  la serenidad es lo unico para aceptar lo que ya no puede cambiarse y si se pierde en el camino habra que gritar para salvarse  calma  calma vladimir son cosas que pasan respira bien hondo y mantene la calma calma vladimir no pierdas el tino para razonar hay que estar tranquilo  calma vladimir este gaucho no se agacha con la frente en alto marcha y ante cualquier situacion no se rinde facil no  en la adversidad se agranda y aunque no es de presumir sabe que lleva el coraje en sus andas ah si si si  y abraza su libertad porque la supo perder y la tierra que mas ama es la tierra que lo vio nacer cuando le toca sufrir su valor lo hace crecer contagia ese poder  todo el mundo sabe tengo el gaucho power con el vivo y lucho y lo llevo donde voy  cuando no hay escape uso el gaucho power no te acerques mucho si te toco te lo doy  cuando siente que hay desprecio en la mirada de algun necio el no le presta interes porque el sabe bien quien es  la tradicion enciende el fuego y no la ceniza gris y asi su llama flamea en el tiempo asi si si si  no le importa disimular su rudeza y su altivez cuando se arrodilla firme ante el amor de una mujer y si alguien toca su honor su garra habla por el contagia ese poder  todo el mundo sabe tengo el gaucho power con el vivo y lucho y lo llevo donde voy  cuando no hay escape uso el gaucho power no te acerques mucho si te toco te lo doy y en la noche me guia la cruz del sur soy toro en mi rodeo y torazo en ruedo ajeno no me encandila la luz mala contagia ese poder  todo el mundo sabe tengo el gaucho power con el vivo y lucho y lo llevo donde voy  cuando no hay escape uso el gaucho power no te acerques mucho si te toco te lo doy ojos vinilicos deseos elasticos alma de acrilico sonrisa de plastico labios de melamina besos virtuales palabras de licra y caricias de latex  y con su voz de celofan dice que es su forma de poder enfrentar sin armas autenticas sin armas autenticas a esta realidad sintetica  tan real tan comun en su juego tan artificial que no parece extraño y asi va con sus brazos de velcro corazon de teflon y mirada de nylon  risa de carmica lagrimas cinicas pose de camara emociones quimicas planes de silicona nervios de pvc amores de neopreno y amigosjpg  y con su andar de maniqui dice que es su forma de poder existir sin gestos autenticos sin gestos autenticos en un entorno sintetico  tan real tan comun en su juego tan artificial que no parece extraño y asi va con sus brazos de velcro corazon de teflon y mirada de nylon  cuidado que el fuego derrite ese plastico oh oh oh por que la pasion no se enciende con fosforos no no no no  tan real tan comun en su juego tan artificial que no parece extraño y asi va con sus brazos de velcro corazon de tefron y mirada de nylon  cuidado que el fuego derrite ese plastico oh oh oh hay unas verdades que mejor no demostrar lo que le preste a la vida la vida me pagara y todo lo que di para bien o para mal de la misma manera me lo devolvera  mi madre me decia que no hay peor dolor que cuando el amor se vuelve odio y el odio temor y que quien hizo mal ira de mal en peor y que es mas feliz el que mas amo  y es que todo vuelve como un eco sin ruido ni voz yo camino siguiendo a mi corazon  ah sembrando un beso ah guardando el arma ah adios destino ah hola karma  nadie escapa de si mismo adonde vaya ahi estare cada accion me condiciona aunque no lo quiera ver libre de elegir libre de escoger con cada decision decido quien quiero ser  abrazo mis valores cuando me toca cambiar es con el universo mi forma de negociar y dice la ley que aunque no se mire atras al que sembro viento le espera una tempestad  y es que todo vuelve como un eco sin ruido ni voz yo camino siguiendo a mi corazon  ah sembrando un beso ah guardando el arma ah adios destino ah hola karma  cada paso cada huella que dejamos atras son como una cuerda vibrando en la eternidad sin miedo a perderme ni a cambiar de direccion yo camino siguiendo a mi corazon  ah sembrando un beso ah guardando el arma ah adios destino ah hola karma hay alguien ahi hay alguien ahi  aca estoy otra vez viendome cambiar de piel diciendo cosas que no siento haciendo cosas sin querer  alguien deberia atarme alguien deberia callarme y llevarme a otro lugar antes de que sea demasiado tarde  se que ya volvere a la tranquilidad y que me espera un dia de calma y paz pero tambien se que nunca estare libre del animal preso en mi ser porque cualquier frase o gesto hostil logran poner fuera de si a la bestia que hay en mi  la bestia que hay en mi hay alguien ahi  y aunque no me crezcan garras ni colmillos me aparezcan y que no me cubra la bruma ni este aullandole a la luna  alguien deberia frenarme alguien deberia encerrarme porque puedo lastimar y ser peligroso aunque no corra sangre  se que ya volvere a la tranquilidad y que me espera un dia de calma y paz pero tambien se que nunca estare libre del animal preso en mi ser porque cualquier frase o gesto hostil logran poner fuera de si a la bestia que hay en mi  bestia bestia alguien que me ayude a volver a ser yo bestia alguien que me ayude a volver a ser yo bestia alguien que me ayude a volver a ser yo  se que ya volvere a la tranquilidad y que me espera un dia de calma y paz pero tambien se que nunca estare libre del animal preso en mi ser porque cualquier frase o gesto hostil logran poner fuera de si a la bestia que hay en mi  alguien que me ayude a volver a ser yo alguien que me ayude a volver a ser yo alguien que me ayude a volver a ser yo alguien que me ayude a volver a ser yo alguien que me ayude a volver a ser yo bestia alguien que me ayude a volver a ser yo bestia alguien que me ayude a volver a ser yo bestia alguien que me ayude a volver a ser yo bestia  hay alguien ahi le puse un nombre a mi inseguridad le di una cara ojos y una voz  cuando la invoco siempre acude a mi llamado y asi puedo hablarle y sentirme acompañado cuando quedo frente a una decision a veces pienso mucho  esto me pasa cuando pienso demasiado esto me pasa cuando pienso de mas a veces pienso mucho ohuhohuh esto me pasa cuando pienso demasiado esto me pasa cuando pienso de mas a veces pienso mucho ohuhohuh  le puse un nombre a mi soledad a la nostalgia al miedo y al dolor  y asi cuando aparecen como sombras en mi espalda puedo enfrentarlos solo sin escudo y sin espada porque tambien le puse nombre a mi valor a veces pienso mucho hah  esto me pasa cuando pienso demasiado esto me pasa cuando pienso de mas a veces pienso mucho ohuhohuh esto me pasa cuando pienso demasiado esto me pasa cuando pienso de mas  y asi mis temores reconoci los enfrente y pude dormir los puedo nombrar y los puedo ver les puedo hablar y los puedo oir  y asi deje de huir y ser su rehen y los bautice con los nombres que yo mismo les elegi para que fueran como un talisman  que me protegieran del mal que dificil es a veces comprender quien es quien  esto me pasa cuando pienso demasiado esto me pasa cuando pienso de mas a veces pienso mucho ohuhohuh esto me pasa cuando pienso demasiado esto me pasa cuando pienso de mas a veces pienso mucho ohuhohuh parece que por fin el cielo esta aclarando parece que el camino al fin se enderezo siento a la fortuna andando a mi lado jugando a mi favor  y las piedras con que tropece hoy solo arena son y la lluvia que me cegaba ya paro y se convirtio en luz  asi que hoy me quiero sentir libre de celebrar por si mañana no tengo de nuevo al rey y al as pero esta partida sin fin cuanto puede durar solo la luna sabe cuanto cuanto cuanto mas  la suerte nunca apunta pero da en el blanco y el blanco es el que menos la espero y muchas veces puede hacernos pagar caro lo que creemos que nos regalo  por eso cuando cambia la pisada no me pongo a cuestionar porque antes de cambiar de nuevo nunca me lo va a avisar  asi que hoy me quiero sentir libre de celebrar por si mañana no tengo de nuevo al rey y al as pero esta partida sin fin cuanto puede durar solo la luna sabe cuanto cuanto cuanto mas cuanto mas cuanto mas cuanto mas  dicen que lo que ha de suceder entonces sucedera pero es dueño de su destino quien nada espera del azar y aunque me cueste creer que todo tiene una razon la suerte es un desenlace pero no una explicacion  asi que hoy me quiero sentir libre de celebrar por si mañana no tengo de nuevo al rey y al as pero esta partida sin fin cuanto puede durar solo la luna sabe cuanto cuanto cuanto mas cuanto mas cuanto mas cuanto mas con ella estoy adicto a su sexy amor para mi en su velar me hace alucinar soy un convicto de tu amor y es que te beso en la cocina te hago el amor en la oficina no logro evitar voy a penetrar ese arcoiris me fascina  suben mis labios quieren subir hasta tus caderas mis labios quieren bajar hasta tu pecera mami soy un adicto de tu amor no lo puedo negar eres mi pasion eres mi obsesion eres tu mi adiccion eres tu mi sol soy adicto de tu amor no lo puedo negar soy adicto de tu amor  eres mi pasion eres mi obsesion eres tu mi adiccion eres tu mi sol addict no lo puedo negar addict que manera hermosa como muerdes hay algo de sexy en tu mirar soy como un volcan y tu falda cae estamos empapados en amor  suben mis labios quieren subir hasta tus caderas mis labios quieren bajar hasta tu pecera mami soy un adicto de tu amor no lo puedo negar eres mi pasion eres mi obsesion eres tu mi adiccion eres tu mi sol soy adicto de tu amor no lo puedo negar soy adicto de tu amor  eres mi pasion eres mi obsesion eres tu mi adiccion eres tu mi sol addict no lo puedo negar te amaria noche y dia te amaria de por vida es una adiccion no lo puedo negar no lo puedo negar  eres mi pasion eres mi obsesion eres tu mi adiccion eres tu mi sol no lo puedo negar no lo puedo negar adiccion obsesion adiccion pierdo pierdo la razon se que soy adicto adicto de tu amor no lo puedo negar incendiado estoy pretty baby desolado estoy incendiado its connection y seducir sabes incendiar eres una adivina en la conexion its connection y se que besa rico alla con otro chico i saw you con otro wey no and thats not right no no no thats no right  me tienes me tienes me tienes la cama incendiada en el fuego de tu amor y sin dormir estoy alucinado mi amor y no puedo mas mas mas no importan tus engaños te extraño y no puedo sin ti la cama incendiada sin ti  mi gatita mi pasion mi respiracion regresame en los labios de tu conexion its connection labios labios que tienes tienes tu labios labios que tienes en el sur labios al sur del ombligo en el sur  y se que besa rico alla con otro chico i saw you con otro wey no and thats not right no no no thats not right me tienes me tienes me tienes la cama incendiada en el fuego de tu amor y sin dormir estoy alucinado mi amor y no puedo mas mas mas no importan tus engaños te extraño y no puedo sin ti la cama incendiada sin ti  la cama la cama la cama incendiada y yo alucinado angustiado estoy amor y sin dormir estoy desesperado mi amor extrañandote a murir no no no no no importan tus engaños te extraño y no puedo sin ti la cama incendiada sin ti la cama incendiada sin ti sin ti yo no puedo vivir no no  its connection its connection its connection no regreso a tu carcel no regreso a tu prision a la opresion que por miedo a perderte el silencio me invadio y mi vida encarcelo quiero ahogarme en otros labios en otro sol liberacion voy a liberarme voy a rescatarme no regreso a tu prision  no no no mi amor no no no regreso a tu carcel oh no no mi amor no no no regreso a tu carcel no regreso corazon a la prision no volvere voy a liberarme hoy uoh uoh yeah  fui cayendo en la demencia con la urgencia de escapar para no volver jamas ya no aguanto las paredes ni las redes ni el control no soporto tu prision quiero ahogarme en otro labios en otro sol liberacion voy a liberarme voy a rescatarme no regreso a tu prision  no no no mi amor no no no regreso a tu carcel no no no mi amor no no no regreso a tu carcel no regreso corazon a la prision no volvere voy a liberarme hoy uoh uoh yeah  no mi amor jamas regreso a tu carcel no no regreso corazon a la prision no volvere a tu carcel no voy a liberarme hoy uoh uoh yeah  no regreso a tu prision oh no no regreso a tu prision no regreso a las paredes a las redes al control no mi amor que ironia de la vida el amor que duele noche y dia que te alegra en abundancia o te quiebra del dolor ahora que no vas a andar conmigo ahora que solo sere tu amigo ilumina la distancia iluminame el dolor como olvidar como regresar que ironia del amor  que ironia si es la vida inundada de dolor el amor glorifico el amor nos arranco tantas risas tanto llanto que le lloro que le canto que nos va a matar que ironia que manera de llorar por un amor y en mis tristes manos guardo el vacio de tu olor y tan solo espero ya mi amor amanecer  como el cielo y el infierno tu amor que hiere y que es muy tierno estoy tan lleno de tu vida y vacio de tu amor y es que es absurdo estando enamorados que triste amor estar asi de separados y perdona la insistencia pero muero del dolor como olvidar como regresar que ironia del amor ehhh  que ironia si es la vida inundada de amor el amor glorifico el amor nos condeno uno ama pa estar vivo y uno muere en el vacio en las guerras del amor que ironia que manera de quebrarse amor y en mis tristes manos guardo el vacio de tu olor y solo espero ya mi amor  amanecer guardas el secreto del amor sigo yo abrazando la esperanza abrazando la demencia que ironia de la vida amanecer cual es el secreto del amor sigo en la esperanza o sera pura demencia que le voy a hacer cual es el secreto del amor hay mentiras en los labios hay mentiras en la piel que dolor  hay mentiras hay amantes que por instantes de placer ponen su vida a temblar  hay mentiras compasivas hay mentiras por piedad que no quieren lastimar  hay mentiras que nos hieren de verdad ay ay ay  y hay engaños que por años ocultaron la verdad haciendo mucho daño  ay yo me voy a refugiar a la tierra de tu amor mi verdad  tu eres mi amor mi alegria la verdad de mi vida mi bebe que me salta a los brazos de prisa tu eres mi refugio y mi verdad  oh yeah  tu eres mi amor mi alegria la verdad de mi vida mi bebe que me calma el alma con risas tu eres mi refugio y mi verdad  hay mentira en la mirada hay mentiras en la piel dibujadas  hay mentiras hay amantes que por instantes de placer ponen su vida a temblar  hay doctrinas y oradores dictadores sin piedad que gobiernan sin verdad  y hay mentiras en los diarios en las redes y en el bar ay ay ay  hay engaños que por años ocultaron la verdad hiriendo de dolor  ay yo me voy a refugiar al oasis de tu amor  tu eres mi amor mi alegria la verdad de mi vida mi bebe que me salta a los brazos de prisa tu eres mi refugio y mi verdad  oh yeah  tu eres mi amor mi alegria la verdad de mi vida mi bebe que me calma el alma con risas tu eres mi refugio y mi verdad  ay dios santo  en un mundo tan irreal no se en que creer se oh y amor se que tu eres mi verdad eres mi verdad  tu eres la luz de mi vida tu eres la voz que me calma tu eres la lluvia de mi alma y eres toda mi verdad  tu eres la luz de mi vida tu eres la voz que me calma tu eres la lluvia de mi alma y eres toda mi verdad  y eres toda mi verdad solo quiero vivir en tus playas tu mar tratame con mucho amor yo no quiero sufrir y solo quiero hundirme en tu agua de mar hundirme en tu placer piel canela piel de mar mueve tu cuerpo te va a gustar mueve tu cuerpo te va a gustar habre tu cuerpo que te voy a dar amor  ay amor que delicia amanecer con tu sonrisa hoy te amo tanto piel canela dame suavecito amor mi amorcito si curas y sanas tanto dolor del corazon te lo pido te lo digo suavecito suavecito suavecito solo quiero un beso de bajo del mar y bailame suave amor suavecito en el mar yo solo quiero mojarme de tu humeda mojarme de tu placer piel canela piel de mar  mueve tu cuerpo te va a gustar mueve tu cuerpo te va a gustar habre tu cuerpo que te voy a dar amor  ay amor que delicia amanecer con por tu sonrisa hoy te amo tanto piel canela dame suavecito amor mi amorcito si curas y sanas tanto dolor del corazon te lo pido te lo digo suavecito por ahi por alla como baila la morena esa reina no paren el ritmo que baila super rico esa reina por ahi por alla como baila la morena esa reina no paren el ritmo que baila super rico esa reina  en puerto rico por ahi por alla habre tu cuerpo que te voy a dar amor dame suave tus labios de mar y dame suave todo mi morena dame suave otro besito y de a poquito borrar las penas estaba hundido estaba en el olvido y hoy bañado de tu amor de corazon te lo pido suavecito suavecito suavecito  te mueves suavecito te mueves suavecito te mueves suavecito te mueves suavecito por que lloras mi amor que te fluye en la piel te despiertas en el llanto con espantos de dolor  son los monstruos del ayer son tus miedos corazon sabes bien que yo te amo y te pido que tengas fe  no sufras mas por mi bebe eres la mariposa que vuela hacia el huracan cuentame de tu pesar suelta todo tu dolor dimelo  aaaaaaaaaa amor un huracan y una mariposa llegan se dan la cara en medio de la mar  lluvia de esperanza lluvia al corazon siempre ahi estare no te fallare desde el cielo lluvia al corazon sol que lanza la esperanza la esperanza y la luz no importa lo que pase no importa jamas no no lluvia al corazon  fluye la desilusion muda desesperacion pero todo tiene alivio menos el decir adios  y si te vas asi yo morire y te amarras a tu piano y te vas al altamar y te quieres escapar y te quieres diluir no mi amor  aaaaaaaaaa amor un huracan y una mariposa llegan se dan la cara en medio de la mar  lluvia de esperanza lluvia al corazon siempre ahi estare no te fallare desde el cielo lluvia al corazon sol que lanza la esperanza la esperanza y la luz no importa lo que pase no importa jamas no no lluvia al corazon  la esperanza al corazon la esperanza al corazon que te sane que te alivie el dolor no importa lo que pase no importa jamas no no lluvia al corazon eres inevitable amor casi como respirar casi como respirar  llegue a tus playas impuntual pero no me rendire soy tu amor clandestino soy el viento sin destino que se cuela en tu faldas mi amor un soñador un clandestino que se juega hasta la vida mi amor clandestino amada amada amor  no no no no  mi amor clandestino en el silencio el dolor se nos cae todo el cielo de esperar inevitable casi como respirar se nos cae todo el cielo de tanto esperar clandestino  el universo conspiro inevitable corazon clandestino eterno amor  pero me duele no gritar tu nombre en toda libertad bajo sospecha hay que callar  y te sueño piel con piel ahogado en besos y tus risas amor y me hundo en el calor que hay en tus muslos en tu mar llorando en silencio temblando tu ausencia rogandole al cielo y finjiendo estar muy bien  no no no no  mi amor clandestino en el silencio el dolor se nos cae todo el cielo de tanto esperar inevitable caasi como respirar se nos cae todo el cielo de tanto esperar clandestino  no te engañes mas ya no te mientas si aire ya paso ya paso y verdad ya no tengas miedo solo tu mantienes mi respiracion  hace tanto que yo esperaba al viento amor cae el llanto del cielo de esperar hace tanto que yo espere tu luz amor ay amor ay amor ay amor  se nos cae todo el cielo se nos cae todo el cielo de tanto esperar mi amor ya no te engañes no te mientas corazon se nos cae todo el cielo entiendelo amor vas por el mundo destrozando corazones podras tener mas de mil hombres a tus pies pero mi amor ya lo veras no lo repones oyeme nena tu mi reina te me vas a volar  cuando me vaya empezaras a valorarme amor del bueno nunca es facil encontrar de ti mi vida ya no vuelvo a enamorarme vete al infierno y te me pintas a volar  prefiero solo que atado mi reina del dolor prefiero solo que engañado que tengas suerte amor te digo adios bye bye mi reina del dolor  hoy me pregunto por que quieres humillarme nunca me amaste por favor dejame en paz y aunque me pidas de rodillas voy a amarte hoy me di cuenta de mi triste realidad hoy me di cuenta de mi error lo se mi reina del dolor  prefiero solo que atado mi reina del dolor prefiero solo que engañado que tengas suerte amor te digo adios bye bye mi reina del dolor  no me hieras mas no mi amor mi sirena del dolor hoy me doy cuenta del vacio quedas ya en el olvido prefiero solo que engañado mi reina del amor  y aunque me implores y me llores jamas yo volvere y aunque me pidas de rodillas jamas yo volvere te digo adios bye bye mi reina del dolor  no me hieras mas no mi amor mi sirena del dolor  prefiero solo que engañado mi reina del dolor mi reina del dolor con duda yo pensaba si lo haria si era vida ahi de regreso el espejo seductor en su reflejo lo tenia que cruzar lo toco con la punta mi miedo que se hunde en el mercurio del cristal lo cruzo y lo dejo a mis espaldas no hay regreso es tan fatal  quede atrapado en un espejo azul que voy a hacer dios mio estoy perdiendo la razon quede atrapado quede fundido en otro tiempo en otra dimension  voy caminando por el hall del monasterio medieval el padre aurelio me instruyo bienvenido pase ya todo lo que vea es de usted se lo voy a regalar me dijo el cura sin piedad usted pudo llegar hasta aqui y jamas podra escapar uooohhh uooohh por pecar y blasfemar uooohhh uooohh con la vida pagaran  quede atrapado en un espejo azul que voy a hacer dios mio estoy perdiendo la razon quede atrapado quede fundido en otro tiempo en otra dimension  cayendo huyendo estan equivocados maligno mezquino me grita un fraile bizantino y en el rio la jauria de los frailes me seguia me atraparon me golpearon de regreso a la abadia y en el patio del convento exorcistas me gritaban no hay remedio a la hoguera no lo hagan no  no me maten por piedad nooo no me maten por piedad nooo no me maten por favor nooo no por piedad nooo quede atrapado detras del muro en un convento hay un sueño en la piel sor maria se disfraza como el viento sueña y vuela va con el  sor maria encerrada le prohibieron libertad las hermanas le advirtieron con espanto es pecado enamorarse es virtud la castidad  se lo dijo el padre aurelio sor maria pliega el vuelo hija mia ponte en paz ella dijo ya no puedo padre aurelio si la luz entra en el agua se le olvida el cielo  una mujer enamorada decidida pasma el aire el universo y la razon si la luz entra en el agua olvida el cielo va con un sueño en la piel  hablando sola con su sombra inventando estar con el suelta un beso en el aire y lo nombra labios llenos de su miel  sor maria enamorada sin remedio trae ardiendo el corazon esta inundada de sus sueños de sus ganas ignorarlo es contra natura por piedad no me juzguen revento  una mujer enamorada decidida pasma el aire el universo y la razon si la luz entra en el agua olvida el cielo va con un sueño en la piel  en huida el padre aurelio y sor maria fatal los sorprendieron en pecado capital los fusilaron a los dos mano con mano hasta el final como los arboles que mueren de pie  y se soñaba con la luz de la mañana en la bañera que le besa el vientre y los labios y los pies se sonroja y se le encienden las mejillas se murio con un sueño en la piel con un sueño en la piel te fuiste a un viaje a las estrellas te fuieste al cielo mi amor te hiciste luz bella de estrella y yo aqui me quede con dolor  tu eres mi angel de la guarda que me cuida que me aguarda que esta dentro de mi  tu eres el arbol en el rio y las flores de naranjo el ave que esta aqui  no te olvido paloma me haces falta mi vida algun dia yo te vere ya no lloro paloma ya no lloro mi vida gracias por tanto amor  gracias a la vida por tenerte guerrero de la luz del amor tu cuerpo ya no pudo sostenerte yo te voy a encontrar en el cielo mi amor  vuela vuela libre mi paloma vuela vuela libre mi amor tu luz y bendicion no me abandonan si volviera a nacer seria contigo amor  no lloro mi paloma ya no lloro no lloro pajarito mi amor voy con la fe y con la esperanza porque te amo mi amor y yo te voy a encontrar  quisiera estar contigo en la playa y bailando despacito tu mirada entrando en mi te fuiste y llego la primavera que le digo a tus rosales que le digo al colibri  no te olvido paloma me haces fallta mi vida algun dia yo te vere tengo el corazon inundado corazon inundado gracias por tanto amor  tu eres mi faro en la tormenta que ilumina mis espacios de luz tu eres angel vida y en el cielo mi amor yo te voy a encontrar  vuela vuela libre mi paloma vuela vuela libre mi amor tu luz y bendicion no me abandonan si volviera a nacer seria contigo amor  no lloro mi paloma ya no lloro no lloro pajarito amor mio voy con la fe y con la esperanza porque te amo mi amor yo te voy a encontrar va a amanecer va a sanar no te me rindas mi vida duerme esperando otro dia que saldra el sol no te rindas amor resistir al dolor yo que te quiero a morir   voy a sembrar en tu herida una flor yo tratare de curar todo ese dolor tenme fe corazon esperanza y valor yo que te quiero a morir   va a amanecer va a sanar te voy a curar extrañas tanto tanto pero aguanta corazon tu soledad se va te voy a curar   no te rindas mi vida siembra unas flores de amor en tu herida ay corazon siempre habra un nuevo amanecer te amo a morir no te rajes mi vida siempre la suerte nos cambia nos gira ay corazon siempre habra un nuevo amanecer sale el sol   no te me rajes mi vida mi amor eres un roble valiente con la cara al sol vamos a resistir como el arbol de pie ponte de pie hasta morir   va a amanecer yo se que te pega el dolor tu sabes te amamos lo sabes corazon tu soledad se va se va se va   no te rindas mi vida siembra unas flores de amor en tu herida ay corazon siempre habra un nuevo amanecer te amo a morir   no te rajes mi vida niempre la suerte nos cambia nos gira ay corazon siempre habra un nuevo amanecer sale el sol   no te rindas mi amor es la vida un milagro de dios ve cantando las penas y suelta el dolor va a amanecer pronto llega el sol con la esperanza de amanecer de renacer no te rindas amor alerta esto es un llamado es valiosa su atencion estan discriminando latinos no me parece que tienen razon  somos gente que nunca se raja ante cualquier situacion vamos a mostrar quienes somos con coraje y valor  no vamos no vamos a quejarnos jamas  latino tu latino yo la misma sangre y corazon esto es mi latinoamerica hay que luchar latinoamerica  y si nos quieren marginar nunca nos vamos a dejar solo existe una america hay que soñar latinoamerica  si no aprendemos de nuestra historia no habra forma de progresar cometeremos los mismos errores atrasados nos vamos a quedar  ahora es nuestro momento de brillar como el sol tenemos todo para hacerlo con cojones dignidad y valor  no vamos no vamos a quejarnos jamas  latino tu latino yo la misma sangre y corazon esto es mi latinoamerica hay que luchar latinoamerica  y si nos quieren marginar nunca nos vamos a dejar solo existe una america hay que soñar latinoamerica  jamas se te olviden tus raices jamas se te olviden tus raices jamas se te olviden tus raices jamas se te olviden tus raices  latino tu latino yo la misma sangre y corazon esto es mi latinoamerica hay que luchar latinoamerica  y si nos quieren marginar nunca nos vamos a dejar solo existe una america hay que soñar latinoamerica  hey hey hey  jamas se te olviden tus raices se te olviden tus raices jamas jamas nunca mas jamas se te olviden tus raices se te olviden tus raices vamos mi gente no nos vamos a rajar jamas se te olviden tus raices se te olviden tus raices no te rindas latinoamerica jamas se te olviden tus raices se te olviden tus raices hay que echar palante  hay que luchar latinoamerica hay que soñar latinoamerica hay que pensar latinoamerica hay que lograr latinoamerica yeah yeah yeah yeah vas mi vida perdiendo el suelo te vas sin despedida te vas hiriendo el cielo te di mi vida te amaba tanto dragones en el viento que rompieron nuestro encanto no podia y no leia las lineas tan heridas tatuadas en tu alma te vas fugaz a la eternidad  dragon parece un dragon tus recuerdos quedaron salpicando fuego dragon parece un dragon va salpicando el fuego va hiriendo el cielo dragon parece un dragon tus recuerdos quedaron salpicando fuego dragon parece un dragon hiriendo la eternidad  veneno y penas fluyen por tus venas ficticio paraiso y yo sin darme cuenta dolor por dentro dragones en el viento clavaron sus colmillos la adiccion y el sufrimiento te vas fugaz a la eternidad  dragon parece un dragon tus recuerdos quedaron salpicando fuego dragon parece un dragon va salpicando el fuego va hiriendo el cielo dragon parece un dragon tus recuerdos quedaron salpicando fuego dragon parece un dragon hiriendo la eternidad  te vas fugaz a la eternidad  dragon parece un dragon la adiccion clava sus colmillos en el cuello dragon parece un dragon va salpicando el fuego va hiriendo el cielo dragon parece un dragon tus recuerdos quedaron salpicando fuego dragon parece un dragon hiriendo la eternidad tienes todos los espacios inundados de tu ausencia inundados de silencio no hay palabras no hay perdon  tu me tienes olvidado no respondes al llamado no eches tierra a la palabra me condenas a la nada no me entierres sin perdon  mira corazon que es el engaño se revierte y hace daño se revienta en el aire como pompas de jabon como pude haberte yo herido engañarte y ofendido alma gemela no te olvido aunque me arranque el corazon  ay el rencor que nos envenena nos hace daño aunque no regreses corazon haz de perdonarme  el verdadero amor perdona no abandona no se quiebra no aprisiona no revienta como pompas de jabon  un error es algo humano no justifico la traicion los amantes verdaderos se comprenden se aman y se olvidan del rencor  la noche empieza a amotinarse de sueños rotos y el dolor y me revuelco en la cama aferrandome a la nada implorando tu perdon  mira corazon cuanto te extraño pasan dias pasan años y mi vida se revienta como pompas de jabon como pude haberte yo herido engañarte y ofendido alma gemela no te olvido aunque me arranque el corazon  ay el rencor que nos envenena nos hace daño aunque no regreses corazon haz de perdonarme  el verdadero amor perdona no abandona no se quiebra no aprisiona no revienta como pompas de jabon  un verdadero amor perdona un verdadero amor perdona si el amor es verdadero no se quiebra no abandona si el amor es verdadero no se quiebra no abandona me he vuelto adicto a tu veneno me he vuelto adicto a tu tersa piel esta trenzada mi sed mi locura a tu cintura amor soy un preso irremediable del deseo que me aferra a ti  ella me tiene envenenado ella me tiene intoxicado oyeme nena envenename  erizada mi piel de sensaciones quisiera liberar mis emociones hoy y nos bebimos cada beso cada vena los suspiros tu veneno amor ella me tiene envenenado de tentaciones y de amor  ella me tiene envenenado ella me tiene intoxicado oyeme nena envenename  ella me tiene envenenado ella me tiene intoxicado oyeme nena envenename  adiccion a tus labios tengo adiccion intoxicame de tu amor envenename  adiccion no te puedo evitar amor a tus labios tu risa tus muslos tus pechos envenename  ella me tiene envenenado ella me tiene intoxicado oyeme nena envenename  ella me tiene envenenado ella me tiene intoxicado oyeme nena envenename va a amanecer va a sanar no te me rindas mi vida duerme esperando otro dia que saldra el sol no te rindas amor resistir al dolor yo que te quiero a morir   voy a sembrar en tu herida una flor yo tratare de curar todo ese dolor tenme fe corazon esperanza y valor yo que te quiero a morir   va a amanecer va a sanar te voy a curar extrañas tanto tanto pero aguanta corazon tu soledad se va te voy a curar   no te rindas mi vida siembra unas flores de amor en tu herida ay corazon siempre habra un nuevo amanecer te amo a morir no te rajes mi vida siempre la suerte nos cambia nos gira ay corazon siempre habra un nuevo amanecer sale el sol   no te me rajes mi vida mi amor eres un roble valiente con la cara al sol vamos a resistir como el arbol de pie ponte de pie hasta morir   va a amanecer yo se que te pega el dolor tu sabes te amamos lo sabes corazon tu soledad se va se va se va   no te rindas mi vida siembra unas flores de amor en tu herida ay corazon siempre habra un nuevo amanecer te amo a morir   no te rajes mi vida niempre la suerte nos cambia nos gira ay corazon siempre habra un nuevo amanecer sale el sol   no te rindas mi amor es la vida un milagro de dios ve cantando las penas y suelta el dolor va a amanecer pronto llega el sol con la esperanza de amanecer de renacer no te rindas amor ella uso mi cabeza como un revolver e incendio mi conciencia con sus demonios me vi llegando tarde tarde a todo  despues de un baño cerebral estaba listo para ser amado  pasa el tiempo y ahora creo que el vacio es un lugar normal ella uso mi cabeza como un revolver  no creerias las cosas que he hecho por ella cobardemente fueron sin verguenza era una piedra en el agua seca por dentro  asi se siente cuando la verdad es la palabra sometida  fui tan docil como un guante y tan sincero como pude ella uso mi cabeza como un revolver  no creerias las cosas que he hecho por ella me sali fuera de contexto practicar no te hace perfecto poner un disco eterno y moverme tornasol un espiritu a veces seguro otras veces incierto quiero descubrir por que este deseo crece  entre los dos pasa un meridiano latitud de vida paralelas abrir el sueño stereo crear la dimension sin disimular me voy desnudando con cada sonido alta fidelidad cuando este deseo crece  un espiritu a veces seguro otras veces incierto vengo a descubrir por que este deseo crece quiero un zoom anatomico quiero el fin del secreto entre tus labios de plata y mi acero inolvidable quiero un loop protagonico  pruebame y veras que todos somos adictos a estos fuegos de artificio voy a hacerte un macro porno intenso lo que seduce nunca suele estar donde se piensa  zoom  por aqui ya estuve te largas a reir tus comisuras dame un zoom  luz camara y accion calente la cama y te di de comer mi principe no se da por vencido sobrevolando el ojo de la tormenta mi ser siempre encuentras la calma para ver va girando a tu alrededor como la tierra la tierra es el mundo el mundo es la bola la bola es tu juego  ahora cierra los ojos mi ser este fue un dia agitado ya lo se no hay nada nada a lo que debas temer  regrese a mi pieza y encendi la tv en esta hiperhistoria todos quieren un flash y pocos algo para ver en el ojo de la tormenta mi ser el centro del centro es la ausencia y tu poder es mas  mas de lo que puedes creer oye la frecuencia decaer cada vez que me dejas te perseguiria hasta el sol pero hoy es solo inercia  y un milenio pasa  oye el arco suena a lagrimas cada vez que lo tensas y oye las sirenas en el mar si es que aun no lo entiendes  es el efecto doppler cuando te alejas de mi  es el efecto doppler cuando te alejas de mi vuelve vuelve  sostenido por una ilusion cae la frecuencia de tu amor mañana es mejor  que ahora es hora de colgar estoy perdido en la linea son las dos y te llame desespero pero es mejor decir adios e incrementar mañana  ahora es hora de volver este noche soy un robocop todo el tiempo me encontre dando culpas es extraña esta ciudad o yo estoy fuera de escala  que ahora es hora y no fue ayer mis amigos he cambiado pero aun mi corazon permanece intacto tan intacto como ayer solo para decir  hasta mañana suena el mar prefiero seguir tus pasos suena el mar prefiero seguirte  tengo mal de alturas y aqui vuelan pajaros de oro si me maree es por devocion yo prefiero seguir tus pasos  es igual a un laser la pasion actua por reflejo de  a  de  a  yo prefiero seguir tus pasos  suena el mar suena el mar y yo prefiero seguir tus pasos ahi va la tempestad ya parece un paisaje habitual un arbol color sodio y la caida de un angel electrico  hoy tengo estatica y no querria lastimarte de nuevo volvi solo y cansado por la caida de otro angel electrico  enredado en cables estoy al filo de la resignacion debe ser el habito de esperar que algo quiebre el unisono  un nuevo acorde te hace mirarme a los ojos aun tengo al sol para besar tu sombra hoy cai al dejarte sola ya pague por quebrar la calma lo que irradia esta noche es especial sobre el lago resplandece esperaba una tenue aparicion nebulosa como siempre  e imagine su rostro vivido cuando esta oscuro todo empieza a verse mas claro en mi constelacion  recorde su gustos conversacion astral las canciones que oiamos su cuerpo lunar refugio celestial  y el ph de su saliva y me perdi en la inmensa quietud una crema de estrellas parece cubrirlo todo en mi constelacion  recorde su gustos conversacion astral las canciones que oiamos y subi y subi sabia savia por mi cuerpo como oro de acapulco voy preparandome no se que me pasa ya no puedo volver al oir al oir  tanto irme por las ramas ahora recorro las heridas no fue suficiente fe una vez por semana ya no puedo volver al oir al oir  mi voz vegetal necesito hoy tener amarrados los pies en el aire se que soy nada mas que menos de lo que podria ser me resisto a empujarte a otro juego de azar en el aire reverbera el ansiar de mi voz mi voz vegetal vegetal amor vegetal me siento tan laxo me siento moire pastillas de zen instantaneo calman mi sed el dolor clandestino se desvanece hay cuarto menguante suaviza mi voz suaviza mi voz  cerra la escotilla nena que no hay gravedad afuera oigo truenos lejanos y el mundo al reves odios vs te amo oh dios te amo como quieres ser mi amiga si por ti daria la vida si confundo tu sonrisa por camelo si me miras  razon y piel dificil mezcla agua y sed serio problema  como quieres ser mi amiga si por ti me perderia si confundo tus caricias por camelo si me mimas  pasion y ley dificil mezcla agua y sed serio problema  cuando uno tiene sed pero el agua no esta cerca cuando uno quiere beber pero el agua no esta cerca  que hacer tu lo sabes conservar la distancia  renunciar a lo natural y dejar que el agua corra  como vas a ser mi amiga cuando esta carta recibas un mensaje hay entre lineas como quieres ser mi amiga  cuando uno tiene sed pero el agua no esta cerca cuando uno quiere beber pero el agua no esta cerca ahora que empiezo de cero que el tiempo es humo que el tiempo es incierto ahora que ya no me creo que la vida sera un sueño  ahora que solo el ahora es lo unico que tengo ahora que solo me queda esperar a que llegue la hora  ahora que cada suspiro es un soplo de vida robada a la muerte ahora que solo respiro porque asi podre volver a verte  ahora que ya no me importa que la vida se vista de negro porque a nada le tengo miedo porque a nada le tengo fe  a nada le tengo fe ni miedo ni fe a nada le tengo fe  ahora que ya no me quiero que no me conozco que me abandono abrazame mi amor te lo ruego abrazame fuerte por ultima vez  ahora que ya nada espero ni siento ni anhelo ni nada me se abrazame fuerte amor te lo ruego por si esta fuera la ultima vez  ahora que solo el ahora es lo unico que tengo ahora que solo me queda esperar a que llegue la hora  ahora que ya no me importa que la vida se vista de negro porque a nada le tengo miedo porque a nada le tengo fe  a nada le tengo fe ni miedo ni fe a nada le tengo fe  ahora que empiezo de cero que el tiempo es humo que el tiempo es incierto abrazame fuerte amor te lo ruego por si esta fuera la ultima vez bonito todo me parece bonito bonita mañana bonito lugar bonita la cama que bien se ve el mar  bonito es el dia que acaba de empezar bonita la vida respira respira respira  el telefono suena mi pana se queja la cosa va mal la vida le pesa que vivir asi ya no le interesa que seguir asi no vale la pena  se perdio el amor se acabo la fiesta ya no anda el motor que empuja la tierra la vida es un chiste con triste final el futuro no existe pero yo le digo  bonito todo me parece bonito bonito todo me parece bonito  bonita la paz bonita la vida bonito volver a nacer cada dia bonita la verdad cuando no suena a mentira bonita la amistad bonita la risa  bonita la gente cuando hay calidad bonita la gente que no se arrepiente que gana y que pierde que habla y no miente bonita la gente por eso yo digo  bonito todo me parece bonito bonito todo me parece bonito  que bonito que te va cuando te va bonito que bonito que te va  que bonito que te va cuando te va bonito que bonito que te va  bonito todo me parece bonito la mar la mañana la casa la samba la tierra la paz y la vida que pasa  bonito todo me parece bonito tu calma tu salsa la mancha en la espalda tu cara tus ganas el fin de semana  bonita la gente que viene y que va bonita la gente que no se detiene bonita la gente que no tiene edad que escucha que entiende que tiene y que da  bonito portet bonito peret bonita la rumba bonito jose bonita la brisa que no tiene prisa bonito este dia respira respira  bonita la gente cuando es de verdad bonita la gente que es diferente que tiembla que siente que vive el presente bonita la gente que estuvo y no esta  bonito todo me parece bonito todo me parece bonito  que bonito que te va cuando te va bonito que bonito que te va  que bonito que se esta cuando se esta bonito que bonito que se esta  que bonito que te va cuando te va bonito que bonito que te va  que bonito que se esta cuando se esta bonito que bonito que se esta eso que tu me das es mucho mas de lo que pido todo lo que me das es lo que ahora necesito  eso que tu me das no creo lo tenga merecido por todo lo que me das te estare siempre agradecido  asi que gracias por estar por tu amistad y tu compañia eres lo lo mejor que me ha dado la vida  por todo lo que recibi estar aqui vale la pena gracias a ti segui remando contra la marea  por todo lo que recibi ahora se que no estoy solo ahora te tengo a ti amigo mio mi tesoro  asi que gracias por estar por tu amistad y tu compañia eres lo lo mejor que me ha dado la vida  todo te lo voy a dar por tu calidad por tu alegria me ayudaste a remontar a superarme dia a dia  todo te lo voy a dar fuiste mi mejor medicina todo te lo dare sea lo que sea lo que pidas  y eso que tu me das es mucho mas es mucho mas de lo que nunca te he pedido  todo lo que me das es mucho mas es mucho mas de lo que nunca he merecido  eso que tu me das eso que tu me das hace dias que te observo y he contado con los dedos cuantas veces te has reido ni una mano me ha valido  hace dias que me fijo no se que guardas ahi dentro y a juzgar por lo que veo nada bueno nada bueno  de que tienes miedo a reir y a llorar luego a romper el hielo que recubre tu silencio  sueltate ya y cuentame que aqui estamos para eso pa lo bueno y pa lo malo llora ahora y rie luego  si salgo corriendo tu me agarras por el cuello y si no te escucho grita  te tiendo la mano tu agarras todo el brazo y si quieres mas pues grita  hace tiempo alguien me dijo cual era el mejor remedio cuando sin motivo alguno se te iba el mundo al suelo  y si quieres yo te explico en que consiste el misterio que no hay cielo mar ni tierra que la vida es un sueño  si salgo corriendo tu me agarras por el cuello y si no te escucho grita  te tiendo la mano tu agarras todo el brazo y si quieres mas pues grita  grita grita grita  si salgo corriendo tu me agarras por el cuello y si no te escucho grita  te tiendo la mano tu agarras todo el brazo y si quieres mas pues grita como una barca de papel que cuando se moja se hunde como una manzana que al morder la cabeza me confunde como una veleta que se mueve y que al viento no obedece me gusta como eres  como la balanza que mide el tiempo la soledad y el silencio como un agujero en el cielo por donde se van los sueños como esa cesta que tanto cuesta llenar y que se vacia al momento me gusta como eres  como una herida en el corazon que no me duele tu me gusta como eres como una ventana que al cerrar deja correr el aire una niña una madre una mujer en mi vida  como una nube cargada de agua que moja la tierra seca como la manta que me protege cuando el invierno llega como la vela que se prende y me rescata de la oscuridad me gusta como eres  como la calle que siempre me lleva a ese sitio al que quiero llegar como ese bar en la carretera en el que me paro a descansar como esa peninsula sin bandera en la que me siento libre me gusta como eres  como una herida en el corazon que no me duele tu me gusta como eres como una ventana que al cerrar deja correr el aire una niña una madre una mujer en mi vida  como una herida en el corazon que no me duele tu me gusta como eres como una ventana que al cerrar deja correr el aire una niña una madre una mujer en mi vida  como una barca de papel que cuando se moja se hunde como una manzana que al morder la cabeza me confunde como una veleta que se mueve y que al viento no obedece que el blanco sea blanco que el negro sea negro que uno y uno sean dos como exactos son los numeros depende  que aqui estamos de prestao que el cielo esta nublao que uno nace y luego muere y este cuento se ha acabao depende  depende de que depende de segun como se mire todo depende  depende de que depende de segun como se mire todo depende  que bonito es el amor mas que nunca en primavera que mañana sale el sol porque estamos en agosto depende  que con el paso del tiempo el vino se hace bueno que to lo que sube baja de abajo a arriba y de arriba a abajo depende  depende de que depende de segun como se mire todo depende  depende de que depende de segun como se mire todo depende  que no has conocido a nadie que te bese como yo que no hay otro hombre en tu vida que de ti se beneficie depende  y si quieres decir si cada vez que abres la boca que te hace muy feliz que sea el dia de tu boda depende  depende de que depende de segun como se mire todo depende  depende de que depende de segun como se mire todo depende  depende de que depende de segun como se mire todo depende  depende de que depende de segun como se mire todo depende  depende de que depende de segun como se mire todo depende  depende de que depende de segun como se mire todo depende y yo que hasta ayer solo fui un holgazan y hoy soy el guardian de sus sueños de amor la quiero a morir  podeis destrozar todo aquello que veis porque ella de un soplo lo vuelve a crear como si nada como si nada la quiero a morir  ella borra las horas de cada reloj y me enseña a pintar transparente el dolor con su sonrisa  levanta una torre desde el cielo hasta aqui y me cose unas alas y me ayuda a subir a toda prisa a toda prisa la quiero a morir  conoce bien cada guerra cada herida cada ser conoce bien cada guerra de la vida y del amor tambien  me dibuja un paisaje y me lo hace vivir en un bosque de lapiz se apodera de mi la quiero a morir  y me atrapa en un lazo que no aprieta jamas como un hilo de seda que no puedo soltar no puedo soltar no quiero soltar la quiero a morir  cuando trepo a sus ojos me enfrento al mar dos espejos de agua encerrada en cristal la quiero a morir  solo puedo sentarme solo puedo charlar solo puedo enredarme solo puedo aceptar ser solo suyo tan solo suyo la quiero a morir  conoce bien cada guerra cada herida cada ser conoce bien cada guerra de la vida y del amor tambien  conoce bien cada guerra cada herida cada ser conoce bien cada guerra de la vida y del amor tambien  conoce bien cada guerra cada herida cada ser conoce bien cada guerra de la vida y del amor tambien  y yo que hasta ayer solo fui un holgazan y hoy soy el guardian de sus sueños de amor la quiero a morir  podeis destrozar todo aquello que veis porque ella de un soplo lo vuelve a crear como si nada como si nada la quiero a morir hay dos dias en la vida para los que no naci dos momentos en la vida que no existen para mi ciertas cosas en la vida no se hicieron para mi hay dos dias en la vida para los que no naci  el primero de esos dias fue cuando te conoci me atraparon tus mentiras y me enamore de ti del camelo de tus risas de tus ganas de vivir de la crueldad de tus caricias por las que crei morir  hay dos dias en la vida para los que no naci dos momentos en la vida que no existen para mi ciertas cosas en la vida no se hicieron para mi hay dos dias en la vida para los que no naci  el segundo de esos dias fue justo el que te perdi se fue tu cara bonita y mis ganas de vivir se acabaron las mentiras y de todo aprendi que hay dos dias en la vida para los que no naci  hay dos dias en la vida para los que no naci dos momentos en la vida que no existen para mi ciertas cosas en la vida no se hicieron para mi hay dos dias en la vida para los que no naci  me trague todo el veneno el que llevaban tus besos me empape del sufrimiento que escondia tu sonrisa descubri que con el tiempo me perdi todo el respeto compraste mis sentimientos con tus labios de carmin  y hay dos dias en la vida para los que no naci dos momentos en la vida que no existen para mi ciertas cosas en la vida no se hicieron para mi hay dos dias en la vida para los que no naci  y hay dos dias en la vida dos momentos en mi vida y hay dos dias en la vida dos momentos en mi vida y hay dos dias dias en la vida dos momentos en mi vida y hay dos dias en la vida dos momentos en mi vida y hay dos dias en la vida dos momentos en mi vida y hay dos dias en la vida hoy el mundo da otra vuelta pero nadie me ha avisao hoy el tiempo me ha pillao con un lio en la cabeza  tirao en la cama con ganas de nada hoy el tiempo se ha parao en la hora que no era  hoy el mundo da una vuelta pero no me ha preguntao hoy estoy desafinao hoy estoy de calavera  y el alma partida la pena encendida en la acera me he sentao a esperar la primavera  primavera que no llega primavera que no llega primavera que no llega primavera que no llega  primavera que no llega primavera que no llega primavera que no llega primavera que no llega  hoy el mundo da otra vuelta pero no me ha despertao hoy me levante girao hoy me levante de vuelta  de capa caida peleo con la vida hoy no estoy pa nadie hoy estoy de vuelta  de vuelta de todo de vuelta de nada de vuelta y vuelta tan joven y de vuelta  de vuelta de todo de vuelta de nada de vuelta y vuelta tan joven y de vuelta  primavera que no llega primavera que no llega primavera que no llega primavera que no llega  primavera que no llega primavera que no llega primavera que no llega primavera que no llega oh oh ohohohooh oh oh ohohohooh  a donde vas con tu vestido nuevo a donde vas con ese balanceo a donde vas me gusta lo que veo tu a donde vas  tu de que vas animal con ese desespero no tengas prisa chaval seduceme primero  lo estas haciendo muy mal guardate tu dinero no quiero un chico formal yo busco un marinero  oh oh ohohohooh alguien que me sepa conquistar oh oh ohohohooh alguien que me vuelva a enamorar oh oh ohohohooh alguien que me quiera de verdad oh oh ohohohooh  a donde vas vamos a hablar primero a donde vas voy a serte sincero a donde vas quiero invitarte y luego tu a donde vas  te voy a dar otra oportunidad de nuevo mejor sera chico que me trates con esmero  ya no me preguntes mas ya me contaste el cuento ve con cuidado chaval yo busco marinero  oh oh ohohohooh alguien que me quiera acariciar oh oh ohohohooh alguien que me vuelva a interesar oh oh ohohohooh alguien que me quiera de verdad oh oh ohohohooh  oh oh ohohohooh alguien que me sepa convencer oh oh ohohohooh alguien que tendra algo que ofrecer oh oh ohohohooh alguien que me haga enloquecer oh oh ohohohooh  a donde vas voy a serte sincero lo estas haciendo muy mal seduceme primero  a donde vas me gustas sin remedio no tengas prisa chaval yo busco marinero  oh oh ohohohooh alguien que me sepa conquistar oh oh ohohohooh alguien que me vuelva a enamorar oh oh ohohohooh alguien que me quiera de verdad oh oh ohohohooh  oh oh ohohohooh alguien que me quiera acariciar oh oh ohohohooh alguien que me vuelva a interesar oh oh ohohohooh alguien que me quiera de verdad dejame vivir libre como las palomas que anidan en mi ventana mi compañia cada vez que tu te vas cada vez que tu te vas  dejame vivir libre libre como el aire me enseñaste a volar y ahora me cortas las alas  y volver a ser yo mismo y que tu vuelvas a ser tu libre libre como el aire  dejame vivir libre pero a mi manera y volver a respirar de ese aire que me vuelve a la vida pero a mi manera pero a mi manera  y volver a ser yo mismo y que tu vuelvas a ser tu libre pero a tu manera  y volver a ser yo mismo y que tu vuelvas a ser tu libre libre libre como el aire  pero a mi manera pero a mi manera dejame vivir pero a mi manera pero a mi manera pero a mi manera sosososomos lo que somos sosososomos lo que somos  mira hermano aqui somos los que estamos y aunque hacemos lo que podemos no aprendemos no avanzamos el mundo se hace pequeño sososo y la vida nos sigue pesando somos lo que somos  la tierra enferma y tu con ella bro mira el hombre arrasa con todo lo que le dio digo paz verdad justicia libertad digo amor respeto conciencia dignidad  mira somos lo que somos no lo que queremos patrones esclavos humanos imperfectos somos raza cultura humanidad sosososomos lo que somos  saca la mentira pa fuera de tu vida el amor es el camino que cambie tu destino que cambie la direccion que abra tu corazon esta calle si tiene salida liberate y respira  somos monos inteligentes animales racionales con carnet de identidad seres humanos indiferentes victimas supervivientes de la propia raza humana  yo somos lo que somos no lo que queremos individuos vigilados con derechos controlados we are what we are no what we wanna be sosososomos lo que somos  somos monos somos locos somos raros somos cocos somos rotos somos chotos somos nacos somos jotos  somos monos somos locos somos raros somos cocos somos rotos somos chotos somos nacos somos jotos somos homos somos rotos somos falsos somos bobos sosososomos lo que somos  calma tu tienes la palabra la fuerza de la vida reside en la esperanza reside en la energia que brota de tu alma en tu mente positiva no tengas miedo avanza liberate y respira  lo que si te digo amigo es que ya estoy preparado no me gusta lo que veo voy a empezar a hacer algo  voy a empezar a quererte sin que importe lo que haya pasado voy a empezar a ser libre estrechandote la mano  en la vida algo me he propuesto yo seguir adelante sin miedo flow vivir y avanzar compartiendo con la gente a la que yo quiero  a pesar de nuestros defectos algunas virtudes tenemos de pana somos angeles somos buenos mira sosososomos lo que somos  saca la mentira pa fuera de tu vida el amor es el camino que cambie tu destino que cambie la direccion que abra tu corazon esta calle si tiene salida sosososomos lo que somos  somos tierra somos paz somos fuego destino y verdad somos sangre hermanos amigos y en el tiempo andamos perdidos sosososomos lo que somos  a pesar de nuestros defectos algunas virtudes tenemos somos angeles somos buenos sosososomos lo que somos  monos locos raros cocos sosososomos lo que somos rotos chotos nacos jotos sosososomos lo que somos fotos cortos chapos votos sosososomos lo que somos homos rostros falsos bobos sosososomos lo que somos yin yang menos es mas polos opuestos que nunca se juntan yin yang vienen y van lineas paralelas que nunca se cruzan  bien mal madera o metal puntos de vista que no se preguntan tal cual azucar o sal dos que se oyen pero no se escuchan  yin yang eva y adan desequilibrio por una manzana yin yang bastos o espadas palos opuestos en una baraja  yin yang salir o entrar de un laberinto lleno de puertas yin yang delante o detras dos que se buscan pero no se encuentran  como vas como lo ves si tu veleta y la mia señalan rumbos distintos como vas como lo ves si tu maleta y la mia viajan en vuelos distintos  yin yang menos es mas polos opuestos que nunca se juntan yin yang vienen y van lineas paralelas que nunca se cruzan  bien mal madera o metal puntos de vista que no se preguntan tal cual azucar o sal dos que se oyen pero no se escuchan  yin yang eva y adan desequilibrio por una manzana yin yang bastos o espadas palos opuestos en una baraja  yin yang salir o entrar de un laberinto lleno de puertas yin yang delante o detras dos que se buscan pero no se encuentran  como vas como lo ves si tu veleta y la mia señalan rumbos distintos como vas como lo ves si tu maleta y la mia viajan en vuelos distintos  como vas como lo ves si tu receta y la mia tienen sabores distintos como vas como lo ves si tu cabeza y la mia viven paisajes distintos soy un completo incompleto incompleto por amor la costilla que me falta cuelga de tu corazon  un seguro inseguro media persona en el mundo un amante incompleto cada vez que te deseo  soy un completo incompleto si me giro y no te veo como una persona a medias sabes a que me refiero  soy un acorde incompleto menor y desafinado que va persiguiendo notas sin lograr una cancion  un rosal sin hojas secas un perfume sin olor una pelicula de cine sin final en el guion  soy un completo incompleto si me giro y no te veo como una persona a medias sabes a que me refiero  soy un completo incompleto si me giro y no te veo como una persona a medias sabes a que me refiero  sin ti en mi corazon  soy un completo incompleto se me para el corazon si me giro y no te veo sabes a que me refiero  un seguro inseguro media persona en el mundo un amante incompleto sin ti en mi corazon mira que cosa mas linda mas llena de gracia es esa muchacha que viene y que pasa con su balanceo camino del mar  niña de cuerpo dorado del sol de ipanema con su balanceo es todo un poema la chica mas linda que he visto pasar  ay por que estoy tan solo ay por que me siento triste ay la belleza que existe belleza que no es solo mia que ahora pasea solita  oh vida mia se supieras que cuando tu pasas el mundo entero se llena de gracia con tu balanceo camino del mar  mira que cosa mas linda mas llena de gracia es esa muchacha que viene y que pasa con su balanceo camino del mar  niña de cuerpo dorado del sol de ipanema con su balanceo es todo un poema la chica mas linda que he visto pasar  ay por que estoy tan solo ay por que me siento triste ay la belleza que existe belleza que no es solo mia que ahora pasea solita  oh vida mia se supieras que cuando tu pasas el mundo entero se llena de gracia con tu balanceo camino del mar  ay por que estoy tan solo ay por que me siento triste ay la belleza que existe belleza que no es solo mia que ahora pasea solita  mira que cosa mas linda mas llena de gracia con su balanceo camino del mar camino del mar camino del mar te quiero aunque ahora no viene a cuento aunque no te lo demuestro te quiero  te quiero aunque parezca que me olvide aunque creas que no es cierto eso es lo que siento  me gusta pensar que me gustas saber que te quiero que bueno que bueno  me gusta ser el dueño de tus celos despertarme y darme cuenta de lo mucho que te quiero  quererte quererte no es bastante quererte es no entenderte y que te siga queriendo  quererte quererte es acordarme quererte es merecerte mas de lo que te merezco  me gusta pensar que me gustas saber que te quiero que bueno que bueno  me gusta ser el dueño de tus celos despertarme y darme cuenta de lo mucho que te quiero  te tengo te pierdo te tengo te pierdo te agarro te suelto te agarro te suelto te vas y te espero te vas y te espero te busco te encuentro  te acercas me alejo te acercas me alejo te escucho te cuento te escucho te cuento te compro y te vendo te compro y te vendo te odio te quiero  te dejas me dejo me besas te muerdo te amo te huelo que bueno que bueno  te pido te ofrezco te amo te miento te abrazo te aprieto me duermo te sueño que bueno que bueno  te quiero que te quiero y lo que mas echo de menos lo que mas echo de menos es que no te quiera mas mas mucho mas de lo mucho que te quiero  te echo de menos a veces de mas tu retrato en la pared tu retrato en la pared una cartita en el correo una cartita de quien para decirte que te quiero  que bueno que bueno que bueno que bueno que bueno que bueno que bueno que bueno  que bueno que bueno que bueno que bueno te di mi sangre te di mi cielo te abri la puerta de mis secretos  te di mi alma y tu tus besos y ese veneno de efecto lento  te miro y tiemblo te miro y tiemblo te miro y tiemblo te miro y tiemblo te miro y tiemblo  donde esta el fuego llego el invierno donde has escrito nuestro ultimo verso  como esta el rio tranquilo y seco como borrarte de mis recuerdos  te miro y tiemblo te miro y tiemblo te miro y tiemblo te miro y tiemblo te miro y tiemblo  te miro y tiemblo te miro y tiemblo te miro y tiemblo te miro y tiemblo te miro y tiemblo  te di mi sangre y tu tus besos como negar que aun te venero puede que hayas nacido en la cara buena del mundo yo naci en la cara mala llevo la marca del lado oscuro  y no me sonrojo si te digo que te quiero y que me dejes o te deje eso ya no me da miedo  habias sido sin dudarlo la mas bella de entre todas las estrellas que yo vi en el firmamento  como ganarse el cielo cuando uno ama con toda el alma y es que el cariño que te tengo no se paga con dinero como decirse que sin ti muero  y no me sonrojo si te digo que te quiero y que me dejes o te deje eso ya no me da miedo  habias sido sin dudarlo la mas bella de entre todas las estrellas que yo vi en el firmamento  puede que hayas nacido en la cara buena del mundo yo naci en la cara mala llevo la marca del lado oscuro  y no me sonrojo si te digo que te quiero y que me dejes o te deje eso ya no me da miedo  habias sido sin dudarlo la mas bella de entre todas las estrellas que yo vi en el firmamento  no me sonrojo si te digo que te quiero si te digo que te quiero  \n"
     ]
    }
   ],
   "source": [
    "print(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5q-kn_cMorW"
   },
   "source": [
    "## Pasar el texto a numeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxbtiv_IwhgX"
   },
   "source": [
    "Las redes neuronales solo procesan valores numéricos, no letras, por tanto tenemos que traducir los caracteres a representación numérica. Para ello crearemos dos “tablas de traducción”: una de caracteres a números y otra de números a caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "h_SJ5R6IMuyo"
   },
   "outputs": [],
   "source": [
    "# ordena los caracteres presentes en el texto de forma alfabetica como en una lista\n",
    "# a cada uno de los caracteres listados asigname un numero ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1637588209379,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "woK_B4BaMvfD",
    "outputId": "ee670f95-6429-4156-db9a-756b61c126b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texto: 'flaca no me claves tus puñales por la espalda tan profundo no me duelen no me hacen mal  lejos en el'\n",
      "array([ 6, 12,  1,  3,  1,  0, 14, 15,  0, 13,  5,  0,  3, 12,  1, 22,  5,\n",
      "       19,  0, 20, 21, 19,  0, 16, 21, 27,  1, 12,  5, 19,  0, 16, 15, 18,\n",
      "        0, 12,  1,  0,  5, 19, 16,  1, 12,  4,  1,  0, 20,  1, 14,  0, 16,\n",
      "       18, 15,  6, 21, 14,  4, 15,  0, 14, 15,  0, 13,  5,  0,  4, 21,  5,\n",
      "       12,  5, 14,  0, 14, 15,  0, 13,  5,  0,  8,  1,  3,  5, 14,  0, 13,\n",
      "        1, 12,  0,  0, 12,  5, 10, 15, 19,  0,  5, 14,  0,  5, 12])\n"
     ]
    }
   ],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)} # asignamos un número a cada vocablo\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "#pasamos todo el texto a números\n",
    "texto_como_entero= np.array([char2idx[c] for c in texto])\n",
    "print('texto: {}'.format(repr(texto[:100])))\n",
    "print('{}'.format(repr(texto_como_entero[:100])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "sJJQSzcX3PJC"
   },
   "outputs": [],
   "source": [
    "#-----------revisando las conversiones\n",
    "#for char,_ in zip(char2idx, range(len(vocab))):\n",
    "#    print(' {:4s}: {:3d},'.format(repr(char),char2idx[char]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSb9uD_xMDP3"
   },
   "source": [
    "## Preparar los datos para ser usados en la RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1637588228857,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "8xZPqZO9MxEt",
    "outputId": "26638e20-168b-4075-b11c-fb2d12d7b372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'flaca no me claves tus puñales por la espalda tan profundo no me duelen no me hacen mal  lejos en el centro de la tierra las raices del amor donde estaban quedaran  entre el no me olvides me deje nuestros abriles olvidados en el fondo del placard del cuarto de invitados eran tiempos dorados un pasado mejor  aunque casi me equivoco y te digo poco a p'\n",
      "'oco no me mientas no me digas la verdad no te quedes callada no levantes la voz ni me pidas perdon  aunque casi te confieso que tambien he sido un perro compañero un perro ideal que aprendio a ladrar y a volver al hogar para poder comer  flaca no me claves tus puñales por la espalda tan profundo no me duelen no me hacen mal  lejos en el centro de la'\n",
      "' tierra las raices del amor donde estaban quedaran ay ven y dime todas esas cosas invitame a sentarme junto a ti escuchare todos tus sueños en mi oido  y dejame estrechar tus manos y regalarte unas pocas de ilusiones ay ven y cuentame una historia que me haga sentir bien  yo te escuchare con todo el silencio del planeta y mirare tus ojos como si fue'\n",
      "'ran los ultimos de este pais  ay dejame ver como es que floreces con cinco petalos te absorbere cinco sentidos que te roban solo un poco de tu ser  y seis veces para vivirte debajo de una misma luna y otras nueve pasaran para sentir que nuevas flores naceran  y que cada estrella fuese una flor y asi regalarte todo un racimo de estrellas  no dejes qu'\n",
      "'e amanezca no dejes que la noche caiga no dejes que el sol salga solo dejame estar junto a ti  ay larara larara ay lara ay larara cuando estoy en mis excesos contigo en grande emocion quisiera con embelesos arrancarte el corazon arrancarte el corazon y comermelo a besos  ay larara larara ay lara ay larara yo te juro y te prometo como siempre te he q'\n",
      "'uerido que si tu amor es completo cumpleme lo prometido yo no quiero que otro prieto quiera lo que yo he querido  ay larara larara ay lara ay larara ay larara larara ay lara ay larara  mariquita quita quita quitame dolor y pena debajo de tu rebozo se pasa una noche buena buena es la buena memoria memoria del que se acuerda  se acuerda de san francis'\n",
      "'co san francisco no es esteban esteban no es ningun santo santo es aquel que le reza rezan los padres maitines  los maitines no son completos completas seran las mañas las mañas de un hechicero hechicero es el que urde urde la mujer su tela  tela la del buen cedazo cedazo de harina y cuerda cuerda la de los cochinos los cochinos tragan hierba de la '\n",
      "'hierba nace el trigo el trigo es el que se siembra  se siembra porque es costumbre dijo un viejito al pasar y lo echaron al alumbre porque no supo trovar y lo echaron al alumbre porque no supo trovar me quieren agitar me incitan a gritar soy como una roca palabras no me tocan adentro hay un volcan que pronto va estallar yo quiero estar tranquilo  es'\n",
      "' mi situacion una desolacion soy como un lamento lamento boliviano que un dia empezo y no va a terminar ya nadie hace daño  uoh yo yo yo eh eh eh yo  y yo estoy aqui borracho y loco y mi corazon idiota siempre brillara siempre brillara  y yo te amare te amare por siempre nena no te peines en la cama que los viajantes se van a atrasar  uoh yo yo yo e'\n",
      "'h eh eh yo  y hoy estoy aqui borracho y loco y mi corazon idiota siempre brillara siempre brillara  y yo te amare te amare por siempre nena no te peines en la cama que los viajantes se van a atrasar  y yo estoy aqui borracho y loco y mi corazon idiota siempre brillara siempre brillara  y yo te amare te amare por siempre nena no te peines en la cama '\n"
     ]
    }
   ],
   "source": [
    "char_dataset= tf.data.Dataset.from_tensor_slices(texto_como_entero)\n",
    "#cantidad de secuencia de caracteres\n",
    "secu_length=350\n",
    "#creamos secuencias de maximo 100 caractereres\n",
    "secuencias= char_dataset.batch(secu_length+1, drop_remainder=True)\n",
    "for item in secuencias.take(10):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1636982594628,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "NcndwtCIM-Fs",
    "outputId": "96691d37-c961-42eb-d7a5-40f031bc2d51"
   },
   "source": [
    "### Separar los datos en agrupamientos (batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1637588252335,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "mksd_T8Swhga",
    "outputId": "bb06e3b6-8ff2-4fe5-af4d-c77d71a302f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data:  'flaca no me claves tus puñales por la espalda tan profundo no me duelen no me hacen mal  lejos en el centro de la tierra las raices del amor donde estaban quedaran  entre el no me olvides me deje nuestros abriles olvidados en el fondo del placard del cuarto de invitados eran tiempos dorados un pasado mejor  aunque casi me equivoco y te digo poco a '\n",
      "Target data:  'laca no me claves tus puñales por la espalda tan profundo no me duelen no me hacen mal  lejos en el centro de la tierra las raices del amor donde estaban quedaran  entre el no me olvides me deje nuestros abriles olvidados en el fondo del placard del cuarto de invitados eran tiempos dorados un pasado mejor  aunque casi me equivoco y te digo poco a p'\n"
     ]
    }
   ],
   "source": [
    "#funcion para obtener el conjunto de datos de trainning\n",
    "def split_input_target(chunk):\n",
    "  input_text = chunk[:-1]\n",
    "  target_text= chunk[1:]\n",
    "  return input_text, target_text\n",
    "\n",
    "dataset  = secuencias.map(split_input_target)\n",
    "\n",
    "for input_example, target_example in dataset.take(1):\n",
    "  print('input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "u4TECYFI33aY"
   },
   "outputs": [],
   "source": [
    "#el dataset contiene un conjunto de parejas de secuencia de texto\n",
    "#(con la representación numérica de los caracteres), donde el \n",
    "#primer componente de la pareja contiene un paquete con una secuencia \n",
    "#de 100 caracteres del texto original y la segunda su correspondiente salida, \n",
    "#también de 100 caracteres. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1637587377021,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "lg5_OSKi4PMX",
    "outputId": "8bba63b6-e937-4f1d-a6d0-031eae850cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((350,), (350,)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "#imprimimos el tensor del dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1637588271720,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "ZkunMWeq4PPZ"
   },
   "outputs": [],
   "source": [
    "#Hyper-Parametros para entrenamiento  de una rede neuronal \n",
    "#   -los datos se agrupan en batch\n",
    "BATCH_SIZE= 128\n",
    "#    -Tamaño de memoria disponible \n",
    "BUFFER_SIZE=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1637588273192,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "k38SFjFk4PSA",
    "outputId": "c99d2dc1-95d9-4437-ffd4-66860d4622a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((128, 350), (128, 350)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "dataset= dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "ZwkuwfDkwhgb"
   },
   "outputs": [],
   "source": [
    "#En el tensor dataset disponemos los datos de entrenamiento\n",
    "#con agrupamienttos (batches) compuestos de 64 parejas de secuencias \n",
    "#de 100 integers de 64 bits que representan el carácter correspondiente \n",
    "#en el vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH8XNyuhwhgb"
   },
   "source": [
    "## Construcción del modelo RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfPNCXvFwhgc"
   },
   "source": [
    "Para construir el modelo usaremos tf.keras.Sequential. Usaremos una versión mínima de RNN, que contenga solo una capa LSTM y 3 capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1637588292710,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "8IXjYsnu43Uo",
    "outputId": "4cfd5c3c-061a-4dc9-ad7f-522b6f065fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (128, None, 1024)         28672     \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (128, None, 1024)         8392704   \n",
      "                                                                 \n",
      " dense_14 (Dense)            (128, None, 28)           28700     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,450,076\n",
      "Trainable params: 8,450,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#como es un problema de clasificación estándar \n",
    "#para el que debemos definir la función de Lossy el optimizador.\n",
    "def lossy(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "def create_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  #creando el modelo\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                         return_sequences=True,\n",
    "                         stateful=True,\n",
    "                         recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)                               \n",
    "  ])\n",
    "  #En cuanto al optimizador usaremos tf.keras.optimizers.Adam \n",
    "  #con los argumentos por defecto del optimizador Adam. \n",
    "  model.compile(optimizer='adam',\n",
    "              loss=lossy,\n",
    "              metrics=['accuracy'])\n",
    "  return model\n",
    "vocab_size= len(vocab)\n",
    "#dimensiones de los vectores que tendrá la capa.\n",
    "embedding_dim= 1024\n",
    "#cantidad de neuronas\n",
    "rnn_units=1024\n",
    "#creamos nuestra red neuronal RNN\n",
    "model=create_model(vocab_size   =vocab_size,\n",
    "                  embedding_dim =embedding_dim,\n",
    "                  rnn_units     =rnn_units,\n",
    "                  batch_size    =BATCH_SIZE)\n",
    "#summary()para visualizar la estructura del modelo\n",
    "model.summary()\n",
    "#resultados=  -La capa LSTM consta más de 5 millones de parametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fK4Q3f6whge"
   },
   "source": [
    "## Creando chekpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lC4Y98ibwhge"
   },
   "source": [
    "Una técnica de tolerancia de fallos para procesos cuyo tiempo de ejecución es muy largo. La idea es guardar una instantánea del estado del sistema periódicamente para recuperar desde ese punto la ejecución en caso de fallo del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/derma/Documents/Checkpoints Deep/\n"
     ]
    }
   ],
   "source": [
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1637588303381,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "9abTuOLl1GRG"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir=root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzjdnPZ6D5RZ"
   },
   "source": [
    "Se utiliza un checkpoint_dir en un espacio en DRIVE para mejorar la situacion del entranimiento. Google Colab ofrece un espacio en disco limitado para guardar variables, cada checkpoint en este proceso en concreto puede llegar a pesar 60 a 70MB, con un entrenamiento relativamente basico de 1000 Epochs, tendriamos un espacio de 70000MB o 70Gb en disco de los cuales requerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1637588325322,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "SIeCOJ975Xzp"
   },
   "outputs": [],
   "source": [
    "checkpoint_prefix= os.path.join(checkpoint_dir,\"cp_{epoch:04d}.ckpt\")\n",
    "\n",
    "\n",
    "cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                               monitor='loss',\n",
    "                                               verbose=1,\n",
    "                                               save_weights_only=True,\n",
    "                                               save_best_only=True,\n",
    "                                               mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8clgrqkwhgd"
   },
   "source": [
    "## Entrenando la RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2zs2LtNC1Ql"
   },
   "source": [
    "### Entrenamiento desde Checkpoint 0\n",
    "\n",
    "Se recomienda investigar los siguientes enlaces de informacion:\n",
    "\n",
    "1. https://keras.io/api/callbacks/model_checkpoint/\n",
    "2. https://towardsdatascience.com/checkpointing-deep-learning-models-in-keras-a652570b8de6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1637588329511,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "UaIIJwEgLq4w",
    "outputId": "944af155-b1d7-4326-aabb-8ee1f8a2e866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Thu_Nov_18_09:52:33_Pacific_Standard_Time_2021\n",
      "Cuda compilation tools, release 11.5, V11.5.119\n",
      "Build cuda_11.5.r11.5/compiler.30672275_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "executionInfo": {
     "elapsed": 5397,
     "status": "error",
     "timestamp": 1637588354399,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "wbvK7H9rC9pP",
    "outputId": "df3cd2fe-28f0-46d7-83b4-be4f690caab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.2739 - accuracy: 0.1147\n",
      "Epoch 00001: loss improved from inf to 3.27394, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0001.ckpt\n",
      "2/2 [==============================] - 4s 1s/step - loss: 3.2739 - accuracy: 0.1147\n",
      "Epoch 2/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.4086 - accuracy: 0.1568\n",
      "Epoch 00002: loss did not improve from 3.27394\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.4086 - accuracy: 0.1568\n",
      "Epoch 3/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.0767 - accuracy: 0.1156\n",
      "Epoch 00003: loss improved from 3.27394 to 3.07674, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0003.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.0767 - accuracy: 0.1156\n",
      "Epoch 4/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.8551 - accuracy: 0.1406\n",
      "Epoch 00004: loss improved from 3.07674 to 2.85508, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0004.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.8551 - accuracy: 0.1406\n",
      "Epoch 5/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.7361 - accuracy: 0.2048\n",
      "Epoch 00005: loss improved from 2.85508 to 2.73609, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0005.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.7361 - accuracy: 0.2048\n",
      "Epoch 6/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.7076 - accuracy: 0.2541\n",
      "Epoch 00006: loss improved from 2.73609 to 2.70762, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0006.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.7076 - accuracy: 0.2541\n",
      "Epoch 7/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.6706 - accuracy: 0.2073\n",
      "Epoch 00007: loss improved from 2.70762 to 2.67061, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0007.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.6706 - accuracy: 0.2073\n",
      "Epoch 8/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.6453 - accuracy: 0.2264\n",
      "Epoch 00008: loss improved from 2.67061 to 2.64529, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0008.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.6453 - accuracy: 0.2264\n",
      "Epoch 9/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.6192 - accuracy: 0.2621\n",
      "Epoch 00009: loss improved from 2.64529 to 2.61915, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0009.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.6192 - accuracy: 0.2621\n",
      "Epoch 10/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.5843 - accuracy: 0.2592\n",
      "Epoch 00010: loss improved from 2.61915 to 2.58434, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0010.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.5843 - accuracy: 0.2592\n",
      "Epoch 11/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.5530 - accuracy: 0.2603\n",
      "Epoch 00011: loss improved from 2.58434 to 2.55304, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0011.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.5530 - accuracy: 0.2603\n",
      "Epoch 12/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.5155 - accuracy: 0.2775\n",
      "Epoch 00012: loss improved from 2.55304 to 2.51548, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0012.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.5155 - accuracy: 0.2775\n",
      "Epoch 13/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.4811 - accuracy: 0.2869\n",
      "Epoch 00013: loss improved from 2.51548 to 2.48107, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0013.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.4811 - accuracy: 0.2869\n",
      "Epoch 14/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.4357 - accuracy: 0.3008\n",
      "Epoch 00014: loss improved from 2.48107 to 2.43568, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0014.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.4357 - accuracy: 0.3008\n",
      "Epoch 15/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.3950 - accuracy: 0.3130\n",
      "Epoch 00015: loss improved from 2.43568 to 2.39498, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0015.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.3950 - accuracy: 0.3130\n",
      "Epoch 16/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.3505 - accuracy: 0.3140\n",
      "Epoch 00016: loss improved from 2.39498 to 2.35045, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0016.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.3505 - accuracy: 0.3140\n",
      "Epoch 17/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.3097 - accuracy: 0.3163\n",
      "Epoch 00017: loss improved from 2.35045 to 2.30969, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0017.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.3097 - accuracy: 0.3163\n",
      "Epoch 18/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.2736 - accuracy: 0.3177\n",
      "Epoch 00018: loss improved from 2.30969 to 2.27365, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0018.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.2736 - accuracy: 0.3177\n",
      "Epoch 19/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.2383 - accuracy: 0.3248\n",
      "Epoch 00019: loss improved from 2.27365 to 2.23825, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0019.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.2383 - accuracy: 0.3248\n",
      "Epoch 20/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.2075 - accuracy: 0.3256\n",
      "Epoch 00020: loss improved from 2.23825 to 2.20749, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0020.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.2075 - accuracy: 0.3256\n",
      "Epoch 21/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1837 - accuracy: 0.3293\n",
      "Epoch 00021: loss improved from 2.20749 to 2.18374, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0021.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.1837 - accuracy: 0.3293\n",
      "Epoch 22/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1687 - accuracy: 0.3283\n",
      "Epoch 00022: loss improved from 2.18374 to 2.16871, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0022.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.1687 - accuracy: 0.3283\n",
      "Epoch 23/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1625 - accuracy: 0.3259\n",
      "Epoch 00023: loss improved from 2.16871 to 2.16250, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0023.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.1625 - accuracy: 0.3259\n",
      "Epoch 24/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1402 - accuracy: 0.3320\n",
      "Epoch 00024: loss improved from 2.16250 to 2.14019, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0024.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.1402 - accuracy: 0.3320\n",
      "Epoch 25/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1341 - accuracy: 0.3314\n",
      "Epoch 00025: loss improved from 2.14019 to 2.13412, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0025.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.1341 - accuracy: 0.3314\n",
      "Epoch 26/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1250 - accuracy: 0.3351\n",
      "Epoch 00026: loss improved from 2.13412 to 2.12504, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0026.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.1250 - accuracy: 0.3351\n",
      "Epoch 27/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1120 - accuracy: 0.3400\n",
      "Epoch 00027: loss improved from 2.12504 to 2.11202, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0027.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.1120 - accuracy: 0.3400\n",
      "Epoch 28/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0988 - accuracy: 0.3385\n",
      "Epoch 00028: loss improved from 2.11202 to 2.09883, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0028.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 1s/step - loss: 2.0988 - accuracy: 0.3385\n",
      "Epoch 29/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0951 - accuracy: 0.3479\n",
      "Epoch 00029: loss improved from 2.09883 to 2.09512, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0029.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.0951 - accuracy: 0.3479\n",
      "Epoch 30/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0865 - accuracy: 0.3440\n",
      "Epoch 00030: loss improved from 2.09512 to 2.08653, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0030.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.0865 - accuracy: 0.3440\n",
      "Epoch 31/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0771 - accuracy: 0.3499\n",
      "Epoch 00031: loss improved from 2.08653 to 2.07712, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0031.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.0771 - accuracy: 0.3499\n",
      "Epoch 32/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0633 - accuracy: 0.3533\n",
      "Epoch 00032: loss improved from 2.07712 to 2.06329, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0032.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.0633 - accuracy: 0.3533\n",
      "Epoch 33/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0511 - accuracy: 0.3540\n",
      "Epoch 00033: loss improved from 2.06329 to 2.05111, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0033.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.0511 - accuracy: 0.3540\n",
      "Epoch 34/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0532 - accuracy: 0.3566\n",
      "Epoch 00034: loss did not improve from 2.05111\n",
      "2/2 [==============================] - 2s 989ms/step - loss: 2.0532 - accuracy: 0.3566\n",
      "Epoch 35/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0426 - accuracy: 0.3597\n",
      "Epoch 00035: loss improved from 2.05111 to 2.04255, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0035.ckpt\n",
      "2/2 [==============================] - 4s 3s/step - loss: 2.0426 - accuracy: 0.3597\n",
      "Epoch 36/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0337 - accuracy: 0.3628\n",
      "Epoch 00036: loss improved from 2.04255 to 2.03373, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0036.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 2.0337 - accuracy: 0.3628\n",
      "Epoch 37/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0256 - accuracy: 0.3620\n",
      "Epoch 00037: loss improved from 2.03373 to 2.02556, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0037.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.0256 - accuracy: 0.3620\n",
      "Epoch 38/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0208 - accuracy: 0.3639\n",
      "Epoch 00038: loss improved from 2.02556 to 2.02076, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0038.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.0208 - accuracy: 0.3639\n",
      "Epoch 39/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0243 - accuracy: 0.3608\n",
      "Epoch 00039: loss did not improve from 2.02076\n",
      "2/2 [==============================] - 2s 959ms/step - loss: 2.0243 - accuracy: 0.3608\n",
      "Epoch 40/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0097 - accuracy: 0.3641\n",
      "Epoch 00040: loss improved from 2.02076 to 2.00966, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0040.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.0097 - accuracy: 0.3641\n",
      "Epoch 41/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9969 - accuracy: 0.3696\n",
      "Epoch 00041: loss improved from 2.00966 to 1.99690, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0041.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9969 - accuracy: 0.3696\n",
      "Epoch 42/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9953 - accuracy: 0.3721\n",
      "Epoch 00042: loss improved from 1.99690 to 1.99528, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0042.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9953 - accuracy: 0.3721\n",
      "Epoch 43/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9799 - accuracy: 0.3755\n",
      "Epoch 00043: loss improved from 1.99528 to 1.97987, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0043.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9799 - accuracy: 0.3755\n",
      "Epoch 44/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9799 - accuracy: 0.3764\n",
      "Epoch 00044: loss improved from 1.97987 to 1.97986, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0044.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9799 - accuracy: 0.3764\n",
      "Epoch 45/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9660 - accuracy: 0.3819\n",
      "Epoch 00045: loss improved from 1.97986 to 1.96596, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0045.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9660 - accuracy: 0.3819\n",
      "Epoch 46/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9588 - accuracy: 0.3829\n",
      "Epoch 00046: loss improved from 1.96596 to 1.95877, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0046.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9588 - accuracy: 0.3829\n",
      "Epoch 47/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9591 - accuracy: 0.3830\n",
      "Epoch 00047: loss did not improve from 1.95877\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 1.9591 - accuracy: 0.3830\n",
      "Epoch 48/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9361 - accuracy: 0.3871\n",
      "Epoch 00048: loss improved from 1.95877 to 1.93613, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0048.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9361 - accuracy: 0.3871\n",
      "Epoch 49/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9400 - accuracy: 0.3872\n",
      "Epoch 00049: loss did not improve from 1.93613\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 1.9400 - accuracy: 0.3872\n",
      "Epoch 50/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9334 - accuracy: 0.3882\n",
      "Epoch 00050: loss improved from 1.93613 to 1.93337, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0050.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9334 - accuracy: 0.3882\n",
      "Epoch 51/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9219 - accuracy: 0.3928\n",
      "Epoch 00051: loss improved from 1.93337 to 1.92191, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0051.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9219 - accuracy: 0.3928\n",
      "Epoch 52/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9111 - accuracy: 0.3966\n",
      "Epoch 00052: loss improved from 1.92191 to 1.91109, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0052.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9111 - accuracy: 0.3966\n",
      "Epoch 53/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9035 - accuracy: 0.3974\n",
      "Epoch 00053: loss improved from 1.91109 to 1.90345, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0053.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9035 - accuracy: 0.3974\n",
      "Epoch 54/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8947 - accuracy: 0.4000\n",
      "Epoch 00054: loss improved from 1.90345 to 1.89473, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0054.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.8947 - accuracy: 0.4000\n",
      "Epoch 55/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8891 - accuracy: 0.4021\n",
      "Epoch 00055: loss improved from 1.89473 to 1.88914, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0055.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.8891 - accuracy: 0.4021\n",
      "Epoch 56/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8897 - accuracy: 0.4009\n",
      "Epoch 00056: loss did not improve from 1.88914\n",
      "2/2 [==============================] - 2s 957ms/step - loss: 1.8897 - accuracy: 0.4009\n",
      "Epoch 57/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.8852 - accuracy: 0.4021\n",
      "Epoch 00057: loss improved from 1.88914 to 1.88520, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0057.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.8852 - accuracy: 0.4021\n",
      "Epoch 58/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8610 - accuracy: 0.4090\n",
      "Epoch 00058: loss improved from 1.88520 to 1.86102, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0058.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.8610 - accuracy: 0.4090\n",
      "Epoch 59/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8549 - accuracy: 0.4125\n",
      "Epoch 00059: loss improved from 1.86102 to 1.85492, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0059.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.8549 - accuracy: 0.4125\n",
      "Epoch 60/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8561 - accuracy: 0.4144\n",
      "Epoch 00060: loss did not improve from 1.85492\n",
      "2/2 [==============================] - 2s 995ms/step - loss: 1.8561 - accuracy: 0.4144\n",
      "Epoch 61/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8325 - accuracy: 0.4222\n",
      "Epoch 00061: loss improved from 1.85492 to 1.83254, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0061.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.8325 - accuracy: 0.4222\n",
      "Epoch 62/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8269 - accuracy: 0.4226\n",
      "Epoch 00062: loss improved from 1.83254 to 1.82692, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0062.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.8269 - accuracy: 0.4226\n",
      "Epoch 63/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8118 - accuracy: 0.4295\n",
      "Epoch 00063: loss improved from 1.82692 to 1.81178, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0063.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.8118 - accuracy: 0.4295\n",
      "Epoch 64/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8132 - accuracy: 0.4268\n",
      "Epoch 00064: loss did not improve from 1.81178\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.8132 - accuracy: 0.4268\n",
      "Epoch 65/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8070 - accuracy: 0.4287\n",
      "Epoch 00065: loss improved from 1.81178 to 1.80703, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0065.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.8070 - accuracy: 0.4287\n",
      "Epoch 66/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7957 - accuracy: 0.4344\n",
      "Epoch 00066: loss improved from 1.80703 to 1.79574, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0066.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.7957 - accuracy: 0.4344\n",
      "Epoch 67/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7920 - accuracy: 0.4355\n",
      "Epoch 00067: loss improved from 1.79574 to 1.79200, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0067.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.7920 - accuracy: 0.4355\n",
      "Epoch 68/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7760 - accuracy: 0.4376\n",
      "Epoch 00068: loss improved from 1.79200 to 1.77597, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0068.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.7760 - accuracy: 0.4376\n",
      "Epoch 69/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7720 - accuracy: 0.4445\n",
      "Epoch 00069: loss improved from 1.77597 to 1.77202, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0069.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.7720 - accuracy: 0.4445\n",
      "Epoch 70/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7557 - accuracy: 0.4494\n",
      "Epoch 00070: loss improved from 1.77202 to 1.75572, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0070.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.7557 - accuracy: 0.4494\n",
      "Epoch 71/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7461 - accuracy: 0.4499\n",
      "Epoch 00071: loss improved from 1.75572 to 1.74610, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0071.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.7461 - accuracy: 0.4499\n",
      "Epoch 72/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7455 - accuracy: 0.4501\n",
      "Epoch 00072: loss improved from 1.74610 to 1.74551, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0072.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.7455 - accuracy: 0.4501\n",
      "Epoch 73/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7246 - accuracy: 0.4584\n",
      "Epoch 00073: loss improved from 1.74551 to 1.72458, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0073.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.7246 - accuracy: 0.4584\n",
      "Epoch 74/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7178 - accuracy: 0.4600\n",
      "Epoch 00074: loss improved from 1.72458 to 1.71779, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0074.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.7178 - accuracy: 0.4600\n",
      "Epoch 75/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7204 - accuracy: 0.4570\n",
      "Epoch 00075: loss did not improve from 1.71779\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.7204 - accuracy: 0.4570\n",
      "Epoch 76/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7004 - accuracy: 0.4690\n",
      "Epoch 00076: loss improved from 1.71779 to 1.70038, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0076.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.7004 - accuracy: 0.4690\n",
      "Epoch 77/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7109 - accuracy: 0.4647\n",
      "Epoch 00077: loss did not improve from 1.70038\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.7109 - accuracy: 0.4647\n",
      "Epoch 78/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6940 - accuracy: 0.4693\n",
      "Epoch 00078: loss improved from 1.70038 to 1.69398, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0078.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.6940 - accuracy: 0.4693\n",
      "Epoch 79/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6746 - accuracy: 0.4777\n",
      "Epoch 00079: loss improved from 1.69398 to 1.67461, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0079.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.6746 - accuracy: 0.4777\n",
      "Epoch 80/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6727 - accuracy: 0.4778\n",
      "Epoch 00080: loss improved from 1.67461 to 1.67268, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0080.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.6727 - accuracy: 0.4778\n",
      "Epoch 81/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6612 - accuracy: 0.4820\n",
      "Epoch 00081: loss improved from 1.67268 to 1.66120, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0081.ckpt\n",
      "2/2 [==============================] - 5s 4s/step - loss: 1.6612 - accuracy: 0.4820\n",
      "Epoch 82/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6545 - accuracy: 0.4850\n",
      "Epoch 00082: loss improved from 1.66120 to 1.65446, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0082.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.6545 - accuracy: 0.4850\n",
      "Epoch 83/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6486 - accuracy: 0.4858\n",
      "Epoch 00083: loss improved from 1.65446 to 1.64864, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0083.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.6486 - accuracy: 0.4858\n",
      "Epoch 84/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6318 - accuracy: 0.4942\n",
      "Epoch 00084: loss improved from 1.64864 to 1.63180, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0084.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.6318 - accuracy: 0.4942\n",
      "Epoch 85/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6254 - accuracy: 0.4951\n",
      "Epoch 00085: loss improved from 1.63180 to 1.62539, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0085.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.6254 - accuracy: 0.4951\n",
      "Epoch 86/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6138 - accuracy: 0.5013\n",
      "Epoch 00086: loss improved from 1.62539 to 1.61384, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0086.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.6138 - accuracy: 0.5013\n",
      "Epoch 87/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6103 - accuracy: 0.5016\n",
      "Epoch 00087: loss improved from 1.61384 to 1.61034, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0087.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6103 - accuracy: 0.5016\n",
      "Epoch 88/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6001 - accuracy: 0.5045\n",
      "Epoch 00088: loss improved from 1.61034 to 1.60010, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0088.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6001 - accuracy: 0.5045\n",
      "Epoch 89/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5882 - accuracy: 0.5082\n",
      "Epoch 00089: loss improved from 1.60010 to 1.58825, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0089.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5882 - accuracy: 0.5082\n",
      "Epoch 90/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5696 - accuracy: 0.5163\n",
      "Epoch 00090: loss improved from 1.58825 to 1.56961, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0090.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5696 - accuracy: 0.5163\n",
      "Epoch 91/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5745 - accuracy: 0.5155\n",
      "Epoch 00091: loss did not improve from 1.56961\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5745 - accuracy: 0.5155\n",
      "Epoch 92/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5573 - accuracy: 0.5195\n",
      "Epoch 00092: loss improved from 1.56961 to 1.55727, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0092.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5573 - accuracy: 0.5195\n",
      "Epoch 93/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5413 - accuracy: 0.5265\n",
      "Epoch 00093: loss improved from 1.55727 to 1.54135, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0093.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5413 - accuracy: 0.5265\n",
      "Epoch 94/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5274 - accuracy: 0.5304\n",
      "Epoch 00094: loss improved from 1.54135 to 1.52744, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0094.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5274 - accuracy: 0.5304\n",
      "Epoch 95/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5210 - accuracy: 0.5316\n",
      "Epoch 00095: loss improved from 1.52744 to 1.52103, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0095.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5210 - accuracy: 0.5316\n",
      "Epoch 96/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5427 - accuracy: 0.5238\n",
      "Epoch 00096: loss did not improve from 1.52103\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5427 - accuracy: 0.5238\n",
      "Epoch 97/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5406 - accuracy: 0.5241\n",
      "Epoch 00097: loss did not improve from 1.52103\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5406 - accuracy: 0.5241\n",
      "Epoch 98/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5135 - accuracy: 0.5342\n",
      "Epoch 00098: loss improved from 1.52103 to 1.51352, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0098.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.5135 - accuracy: 0.5342\n",
      "Epoch 99/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4931 - accuracy: 0.5435\n",
      "Epoch 00099: loss improved from 1.51352 to 1.49311, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0099.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.4931 - accuracy: 0.5435\n",
      "Epoch 100/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4815 - accuracy: 0.5470\n",
      "Epoch 00100: loss improved from 1.49311 to 1.48146, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0100.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.4815 - accuracy: 0.5470\n",
      "Epoch 101/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4706 - accuracy: 0.5510\n",
      "Epoch 00101: loss improved from 1.48146 to 1.47059, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0101.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.4706 - accuracy: 0.5510\n",
      "Epoch 102/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4666 - accuracy: 0.5507\n",
      "Epoch 00102: loss improved from 1.47059 to 1.46658, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0102.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.4666 - accuracy: 0.5507\n",
      "Epoch 103/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4440 - accuracy: 0.5626\n",
      "Epoch 00103: loss improved from 1.46658 to 1.44399, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0103.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.4440 - accuracy: 0.5626\n",
      "Epoch 104/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4373 - accuracy: 0.5638\n",
      "Epoch 00104: loss improved from 1.44399 to 1.43733, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0104.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.4373 - accuracy: 0.5638\n",
      "Epoch 105/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4283 - accuracy: 0.5673\n",
      "Epoch 00105: loss improved from 1.43733 to 1.42830, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0105.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.4283 - accuracy: 0.5673\n",
      "Epoch 106/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4228 - accuracy: 0.5705\n",
      "Epoch 00106: loss improved from 1.42830 to 1.42283, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0106.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.4228 - accuracy: 0.5705\n",
      "Epoch 107/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3957 - accuracy: 0.5782\n",
      "Epoch 00107: loss improved from 1.42283 to 1.39572, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0107.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.3957 - accuracy: 0.5782\n",
      "Epoch 108/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3860 - accuracy: 0.5806\n",
      "Epoch 00108: loss improved from 1.39572 to 1.38597, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0108.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.3860 - accuracy: 0.5806\n",
      "Epoch 109/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3844 - accuracy: 0.5807\n",
      "Epoch 00109: loss improved from 1.38597 to 1.38439, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0109.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.3844 - accuracy: 0.5807\n",
      "Epoch 110/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3798 - accuracy: 0.5825\n",
      "Epoch 00110: loss improved from 1.38439 to 1.37977, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0110.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.3798 - accuracy: 0.5825\n",
      "Epoch 111/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3596 - accuracy: 0.5900\n",
      "Epoch 00111: loss improved from 1.37977 to 1.35957, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0111.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.3596 - accuracy: 0.5900\n",
      "Epoch 112/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3547 - accuracy: 0.5916\n",
      "Epoch 00112: loss improved from 1.35957 to 1.35469, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0112.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.3547 - accuracy: 0.5916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3339 - accuracy: 0.6010\n",
      "Epoch 00113: loss improved from 1.35469 to 1.33394, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0113.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.3339 - accuracy: 0.6010\n",
      "Epoch 114/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3339 - accuracy: 0.5974\n",
      "Epoch 00114: loss improved from 1.33394 to 1.33390, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0114.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.3339 - accuracy: 0.5974\n",
      "Epoch 115/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3204 - accuracy: 0.6032\n",
      "Epoch 00115: loss improved from 1.33390 to 1.32042, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0115.ckpt\n",
      "2/2 [==============================] - 6s 5s/step - loss: 1.3204 - accuracy: 0.6032\n",
      "Epoch 116/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3134 - accuracy: 0.6071\n",
      "Epoch 00116: loss improved from 1.32042 to 1.31340, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0116.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 1.3134 - accuracy: 0.6071\n",
      "Epoch 117/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2950 - accuracy: 0.6123\n",
      "Epoch 00117: loss improved from 1.31340 to 1.29501, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0117.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.2950 - accuracy: 0.6123\n",
      "Epoch 118/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2859 - accuracy: 0.6149\n",
      "Epoch 00118: loss improved from 1.29501 to 1.28595, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0118.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.2859 - accuracy: 0.6149\n",
      "Epoch 119/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2729 - accuracy: 0.6199\n",
      "Epoch 00119: loss improved from 1.28595 to 1.27286, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0119.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.2729 - accuracy: 0.6199\n",
      "Epoch 120/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2582 - accuracy: 0.6243\n",
      "Epoch 00120: loss improved from 1.27286 to 1.25824, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0120.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.2582 - accuracy: 0.6243\n",
      "Epoch 121/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2372 - accuracy: 0.6324\n",
      "Epoch 00121: loss improved from 1.25824 to 1.23721, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0121.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.2372 - accuracy: 0.6324\n",
      "Epoch 122/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2355 - accuracy: 0.6346\n",
      "Epoch 00122: loss improved from 1.23721 to 1.23555, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0122.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.2355 - accuracy: 0.6346\n",
      "Epoch 123/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2195 - accuracy: 0.6387\n",
      "Epoch 00123: loss improved from 1.23555 to 1.21954, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0123.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.2195 - accuracy: 0.6387\n",
      "Epoch 124/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1963 - accuracy: 0.6488\n",
      "Epoch 00124: loss improved from 1.21954 to 1.19633, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0124.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.1963 - accuracy: 0.6488\n",
      "Epoch 125/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2031 - accuracy: 0.6474\n",
      "Epoch 00125: loss did not improve from 1.19633\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2031 - accuracy: 0.6474\n",
      "Epoch 126/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1749 - accuracy: 0.6540\n",
      "Epoch 00126: loss improved from 1.19633 to 1.17491, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0126.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1749 - accuracy: 0.6540\n",
      "Epoch 127/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1959 - accuracy: 0.6466\n",
      "Epoch 00127: loss did not improve from 1.17491\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1959 - accuracy: 0.6466\n",
      "Epoch 128/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1578 - accuracy: 0.6598\n",
      "Epoch 00128: loss improved from 1.17491 to 1.15784, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0128.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.1578 - accuracy: 0.6598\n",
      "Epoch 129/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1474 - accuracy: 0.6655\n",
      "Epoch 00129: loss improved from 1.15784 to 1.14741, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0129.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1474 - accuracy: 0.6655\n",
      "Epoch 130/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1259 - accuracy: 0.6725\n",
      "Epoch 00130: loss improved from 1.14741 to 1.12590, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0130.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.1259 - accuracy: 0.6725\n",
      "Epoch 131/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1177 - accuracy: 0.6763\n",
      "Epoch 00131: loss improved from 1.12590 to 1.11770, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0131.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.1177 - accuracy: 0.6763\n",
      "Epoch 132/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1331 - accuracy: 0.6668\n",
      "Epoch 00132: loss did not improve from 1.11770\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1331 - accuracy: 0.6668\n",
      "Epoch 133/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1068 - accuracy: 0.6757\n",
      "Epoch 00133: loss improved from 1.11770 to 1.10678, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0133.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1068 - accuracy: 0.6757\n",
      "Epoch 134/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1028 - accuracy: 0.6808\n",
      "Epoch 00134: loss improved from 1.10678 to 1.10284, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0134.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.1028 - accuracy: 0.6808\n",
      "Epoch 135/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0774 - accuracy: 0.6899\n",
      "Epoch 00135: loss improved from 1.10284 to 1.07739, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0135.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.0774 - accuracy: 0.6899\n",
      "Epoch 136/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0528 - accuracy: 0.6965\n",
      "Epoch 00136: loss improved from 1.07739 to 1.05283, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0136.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.0528 - accuracy: 0.6965\n",
      "Epoch 137/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0591 - accuracy: 0.6938\n",
      "Epoch 00137: loss did not improve from 1.05283\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0591 - accuracy: 0.6938\n",
      "Epoch 138/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0389 - accuracy: 0.7001\n",
      "Epoch 00138: loss improved from 1.05283 to 1.03890, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0138.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.0389 - accuracy: 0.7001\n",
      "Epoch 139/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0143 - accuracy: 0.7118\n",
      "Epoch 00139: loss improved from 1.03890 to 1.01431, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0139.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.0143 - accuracy: 0.7118\n",
      "Epoch 140/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0182 - accuracy: 0.7080\n",
      "Epoch 00140: loss did not improve from 1.01431\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0182 - accuracy: 0.7080\n",
      "Epoch 141/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.9952 - accuracy: 0.7171\n",
      "Epoch 00141: loss improved from 1.01431 to 0.99523, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0141.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.9952 - accuracy: 0.7171\n",
      "Epoch 142/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9888 - accuracy: 0.7214\n",
      "Epoch 00142: loss improved from 0.99523 to 0.98880, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0142.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.9888 - accuracy: 0.7214\n",
      "Epoch 143/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9595 - accuracy: 0.7302\n",
      "Epoch 00143: loss improved from 0.98880 to 0.95946, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0143.ckpt\n",
      "2/2 [==============================] - 4s 3s/step - loss: 0.9595 - accuracy: 0.7302\n",
      "Epoch 144/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9514 - accuracy: 0.7344\n",
      "Epoch 00144: loss improved from 0.95946 to 0.95139, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0144.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.9514 - accuracy: 0.7344\n",
      "Epoch 145/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9229 - accuracy: 0.7448\n",
      "Epoch 00145: loss improved from 0.95139 to 0.92289, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0145.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.9229 - accuracy: 0.7448\n",
      "Epoch 146/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8960 - accuracy: 0.7524\n",
      "Epoch 00146: loss improved from 0.92289 to 0.89598, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0146.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8960 - accuracy: 0.7524\n",
      "Epoch 147/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8873 - accuracy: 0.7580\n",
      "Epoch 00147: loss improved from 0.89598 to 0.88730, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0147.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8873 - accuracy: 0.7580\n",
      "Epoch 148/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9077 - accuracy: 0.7430\n",
      "Epoch 00148: loss did not improve from 0.88730\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9077 - accuracy: 0.7430\n",
      "Epoch 149/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9625 - accuracy: 0.7188\n",
      "Epoch 00149: loss did not improve from 0.88730\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9625 - accuracy: 0.7188\n",
      "Epoch 150/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9354 - accuracy: 0.7330\n",
      "Epoch 00150: loss did not improve from 0.88730\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9354 - accuracy: 0.7330\n",
      "Epoch 151/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9134 - accuracy: 0.7422\n",
      "Epoch 00151: loss did not improve from 0.88730\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9134 - accuracy: 0.7422\n",
      "Epoch 152/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8992 - accuracy: 0.7434\n",
      "Epoch 00152: loss did not improve from 0.88730\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8992 - accuracy: 0.7434\n",
      "Epoch 153/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8538 - accuracy: 0.7633\n",
      "Epoch 00153: loss improved from 0.88730 to 0.85383, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0153.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8538 - accuracy: 0.7633\n",
      "Epoch 154/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8441 - accuracy: 0.7678\n",
      "Epoch 00154: loss improved from 0.85383 to 0.84407, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0154.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8441 - accuracy: 0.7678\n",
      "Epoch 155/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8126 - accuracy: 0.7795\n",
      "Epoch 00155: loss improved from 0.84407 to 0.81259, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0155.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8126 - accuracy: 0.7795\n",
      "Epoch 156/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.7844\n",
      "Epoch 00156: loss improved from 0.81259 to 0.79628, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0156.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7963 - accuracy: 0.7844\n",
      "Epoch 157/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7752 - accuracy: 0.7933\n",
      "Epoch 00157: loss improved from 0.79628 to 0.77522, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0157.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7752 - accuracy: 0.7933\n",
      "Epoch 158/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7560 - accuracy: 0.7994\n",
      "Epoch 00158: loss improved from 0.77522 to 0.75605, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0158.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7560 - accuracy: 0.7994\n",
      "Epoch 159/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7336 - accuracy: 0.8090\n",
      "Epoch 00159: loss improved from 0.75605 to 0.73362, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0159.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7336 - accuracy: 0.8090\n",
      "Epoch 160/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.8147\n",
      "Epoch 00160: loss improved from 0.73362 to 0.71372, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0160.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7137 - accuracy: 0.8147\n",
      "Epoch 161/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7085 - accuracy: 0.8177\n",
      "Epoch 00161: loss improved from 0.71372 to 0.70849, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0161.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7085 - accuracy: 0.8177\n",
      "Epoch 162/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7235 - accuracy: 0.8065\n",
      "Epoch 00162: loss did not improve from 0.70849\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7235 - accuracy: 0.8065\n",
      "Epoch 163/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7346 - accuracy: 0.8042\n",
      "Epoch 00163: loss did not improve from 0.70849\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7346 - accuracy: 0.8042\n",
      "Epoch 164/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7236 - accuracy: 0.8065\n",
      "Epoch 00164: loss did not improve from 0.70849\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7236 - accuracy: 0.8065\n",
      "Epoch 165/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7193 - accuracy: 0.8070\n",
      "Epoch 00165: loss did not improve from 0.70849\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7193 - accuracy: 0.8070\n",
      "Epoch 166/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.8155\n",
      "Epoch 00166: loss improved from 0.70849 to 0.69572, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0166.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6957 - accuracy: 0.8155\n",
      "Epoch 167/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.8323\n",
      "Epoch 00167: loss improved from 0.69572 to 0.65825, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0167.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6583 - accuracy: 0.8323\n",
      "Epoch 168/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6426 - accuracy: 0.8369\n",
      "Epoch 00168: loss improved from 0.65825 to 0.64256, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0168.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6426 - accuracy: 0.8369\n",
      "Epoch 169/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6126 - accuracy: 0.8468\n",
      "Epoch 00169: loss improved from 0.64256 to 0.61265, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0169.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6126 - accuracy: 0.8468\n",
      "Epoch 170/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6157 - accuracy: 0.8467\n",
      "Epoch 00170: loss did not improve from 0.61265\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6157 - accuracy: 0.8467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5947 - accuracy: 0.8521\n",
      "Epoch 00171: loss improved from 0.61265 to 0.59468, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0171.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5947 - accuracy: 0.8521\n",
      "Epoch 172/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5796 - accuracy: 0.8593\n",
      "Epoch 00172: loss improved from 0.59468 to 0.57959, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0172.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5796 - accuracy: 0.8593\n",
      "Epoch 173/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.8629\n",
      "Epoch 00173: loss improved from 0.57959 to 0.56795, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0173.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5680 - accuracy: 0.8629\n",
      "Epoch 174/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.8670\n",
      "Epoch 00174: loss improved from 0.56795 to 0.55310, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0174.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5531 - accuracy: 0.8670\n",
      "Epoch 175/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.8702\n",
      "Epoch 00175: loss improved from 0.55310 to 0.54547, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0175.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5455 - accuracy: 0.8702\n",
      "Epoch 176/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.8762\n",
      "Epoch 00176: loss improved from 0.54547 to 0.52716, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0176.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5272 - accuracy: 0.8762\n",
      "Epoch 177/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5109 - accuracy: 0.8808\n",
      "Epoch 00177: loss improved from 0.52716 to 0.51093, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0177.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5109 - accuracy: 0.8808\n",
      "Epoch 178/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4939 - accuracy: 0.8888\n",
      "Epoch 00178: loss improved from 0.51093 to 0.49391, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0178.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4939 - accuracy: 0.8888\n",
      "Epoch 179/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.8892\n",
      "Epoch 00179: loss improved from 0.49391 to 0.49066, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0179.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4907 - accuracy: 0.8892\n",
      "Epoch 180/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.8818\n",
      "Epoch 00180: loss did not improve from 0.49066\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5065 - accuracy: 0.8818\n",
      "Epoch 181/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.8810\n",
      "Epoch 00181: loss did not improve from 0.49066\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5030 - accuracy: 0.8810\n",
      "Epoch 182/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.8884\n",
      "Epoch 00182: loss improved from 0.49066 to 0.48378, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0182.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4838 - accuracy: 0.8884\n",
      "Epoch 183/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.8991\n",
      "Epoch 00183: loss improved from 0.48378 to 0.46038, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0183.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4604 - accuracy: 0.8991\n",
      "Epoch 184/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4541 - accuracy: 0.8997\n",
      "Epoch 00184: loss improved from 0.46038 to 0.45412, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0184.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4541 - accuracy: 0.8997\n",
      "Epoch 185/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4433 - accuracy: 0.9026\n",
      "Epoch 00185: loss improved from 0.45412 to 0.44331, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0185.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.4433 - accuracy: 0.9026\n",
      "Epoch 186/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.9107\n",
      "Epoch 00186: loss improved from 0.44331 to 0.42828, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0186.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.4283 - accuracy: 0.9107\n",
      "Epoch 187/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4141 - accuracy: 0.9149\n",
      "Epoch 00187: loss improved from 0.42828 to 0.41409, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0187.ckpt\n",
      "2/2 [==============================] - 7s 5s/step - loss: 0.4141 - accuracy: 0.9149\n",
      "Epoch 188/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4000 - accuracy: 0.9194\n",
      "Epoch 00188: loss improved from 0.41409 to 0.39996, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0188.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.4000 - accuracy: 0.9194\n",
      "Epoch 189/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.9238\n",
      "Epoch 00189: loss improved from 0.39996 to 0.38685, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0189.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3868 - accuracy: 0.9238\n",
      "Epoch 190/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.9298\n",
      "Epoch 00190: loss improved from 0.38685 to 0.36774, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0190.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3677 - accuracy: 0.9298\n",
      "Epoch 191/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.9320\n",
      "Epoch 00191: loss improved from 0.36774 to 0.36112, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0191.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3611 - accuracy: 0.9320\n",
      "Epoch 192/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3546 - accuracy: 0.9349\n",
      "Epoch 00192: loss improved from 0.36112 to 0.35460, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0192.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3546 - accuracy: 0.9349\n",
      "Epoch 193/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3405 - accuracy: 0.9400\n",
      "Epoch 00193: loss improved from 0.35460 to 0.34046, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0193.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3405 - accuracy: 0.9400\n",
      "Epoch 194/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.9422\n",
      "Epoch 00194: loss improved from 0.34046 to 0.33011, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0194.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3301 - accuracy: 0.9422\n",
      "Epoch 195/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.9432\n",
      "Epoch 00195: loss did not improve from 0.33011\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3302 - accuracy: 0.9432\n",
      "Epoch 196/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.9388\n",
      "Epoch 00196: loss did not improve from 0.33011\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3364 - accuracy: 0.9388\n",
      "Epoch 197/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.9402\n",
      "Epoch 00197: loss improved from 0.33011 to 0.32880, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0197.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3288 - accuracy: 0.9402\n",
      "Epoch 198/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.9450\n",
      "Epoch 00198: loss improved from 0.32880 to 0.31717, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0198.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3172 - accuracy: 0.9450\n",
      "Epoch 199/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.9482\n",
      "Epoch 00199: loss improved from 0.31717 to 0.30664, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0199.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.3066 - accuracy: 0.9482\n",
      "Epoch 200/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2998 - accuracy: 0.9488\n",
      "Epoch 00200: loss improved from 0.30664 to 0.29975, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0200.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2998 - accuracy: 0.9488\n",
      "Epoch 201/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.9519\n",
      "Epoch 00201: loss improved from 0.29975 to 0.29326, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0201.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2933 - accuracy: 0.9519\n",
      "Epoch 202/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.9548\n",
      "Epoch 00202: loss improved from 0.29326 to 0.28237, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0202.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2824 - accuracy: 0.9548\n",
      "Epoch 203/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.9557\n",
      "Epoch 00203: loss improved from 0.28237 to 0.27834, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0203.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2783 - accuracy: 0.9557\n",
      "Epoch 204/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.9586\n",
      "Epoch 00204: loss improved from 0.27834 to 0.26937, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0204.ckpt\n",
      "2/2 [==============================] - 17s 16s/step - loss: 0.2694 - accuracy: 0.9586\n",
      "Epoch 205/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.9593\n",
      "Epoch 00205: loss improved from 0.26937 to 0.26614, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0205.ckpt\n",
      "2/2 [==============================] - 7s 5s/step - loss: 0.2661 - accuracy: 0.9593\n",
      "Epoch 206/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.9627\n",
      "Epoch 00206: loss improved from 0.26614 to 0.25132, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0206.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.2513 - accuracy: 0.9627\n",
      "Epoch 207/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.9621\n",
      "Epoch 00207: loss improved from 0.25132 to 0.24859, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0207.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2486 - accuracy: 0.9621\n",
      "Epoch 208/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.9635\n",
      "Epoch 00208: loss improved from 0.24859 to 0.24343, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0208.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2434 - accuracy: 0.9635\n",
      "Epoch 209/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.9645\n",
      "Epoch 00209: loss improved from 0.24343 to 0.23946, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0209.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2395 - accuracy: 0.9645\n",
      "Epoch 210/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.9651\n",
      "Epoch 00210: loss improved from 0.23946 to 0.23281, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0210.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2328 - accuracy: 0.9651\n",
      "Epoch 211/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.9674\n",
      "Epoch 00211: loss improved from 0.23281 to 0.22548, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0211.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2255 - accuracy: 0.9674\n",
      "Epoch 212/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.9680\n",
      "Epoch 00212: loss improved from 0.22548 to 0.22077, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0212.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2208 - accuracy: 0.9680\n",
      "Epoch 213/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.9685\n",
      "Epoch 00213: loss improved from 0.22077 to 0.21774, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0213.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2177 - accuracy: 0.9685\n",
      "Epoch 214/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.9695\n",
      "Epoch 00214: loss improved from 0.21774 to 0.21183, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0214.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2118 - accuracy: 0.9695\n",
      "Epoch 215/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9704\n",
      "Epoch 00215: loss improved from 0.21183 to 0.20778, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0215.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2078 - accuracy: 0.9704\n",
      "Epoch 216/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2052 - accuracy: 0.9700\n",
      "Epoch 00216: loss improved from 0.20778 to 0.20523, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0216.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2052 - accuracy: 0.9700\n",
      "Epoch 217/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2039 - accuracy: 0.9704\n",
      "Epoch 00217: loss improved from 0.20523 to 0.20388, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0217.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2039 - accuracy: 0.9704\n",
      "Epoch 218/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9712\n",
      "Epoch 00218: loss improved from 0.20388 to 0.20026, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0218.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.2003 - accuracy: 0.9712\n",
      "Epoch 219/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9723\n",
      "Epoch 00219: loss improved from 0.20026 to 0.19352, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0219.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1935 - accuracy: 0.9723\n",
      "Epoch 220/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9725\n",
      "Epoch 00220: loss improved from 0.19352 to 0.19350, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0220.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1935 - accuracy: 0.9725\n",
      "Epoch 221/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.9731\n",
      "Epoch 00221: loss improved from 0.19350 to 0.19124, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0221.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1912 - accuracy: 0.9731\n",
      "Epoch 222/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9728\n",
      "Epoch 00222: loss improved from 0.19124 to 0.18641, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0222.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1864 - accuracy: 0.9728\n",
      "Epoch 223/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9731\n",
      "Epoch 00223: loss did not improve from 0.18641\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1877 - accuracy: 0.9731\n",
      "Epoch 224/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9742\n",
      "Epoch 00224: loss improved from 0.18641 to 0.18211, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0224.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.1821 - accuracy: 0.9742\n",
      "Epoch 225/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9738\n",
      "Epoch 00225: loss improved from 0.18211 to 0.18030, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0225.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1803 - accuracy: 0.9738\n",
      "Epoch 226/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.9735\n",
      "Epoch 00226: loss improved from 0.18030 to 0.17997, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0226.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 2s/step - loss: 0.1800 - accuracy: 0.9735\n",
      "Epoch 227/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1746 - accuracy: 0.9742\n",
      "Epoch 00227: loss improved from 0.17997 to 0.17459, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0227.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1746 - accuracy: 0.9742\n",
      "Epoch 228/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.9746\n",
      "Epoch 00228: loss improved from 0.17459 to 0.17125, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0228.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1713 - accuracy: 0.9746\n",
      "Epoch 229/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.9748\n",
      "Epoch 00229: loss did not improve from 0.17125\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1713 - accuracy: 0.9748\n",
      "Epoch 230/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1702 - accuracy: 0.9751\n",
      "Epoch 00230: loss improved from 0.17125 to 0.17016, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0230.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1702 - accuracy: 0.9751\n",
      "Epoch 231/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.9759\n",
      "Epoch 00231: loss improved from 0.17016 to 0.16393, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0231.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1639 - accuracy: 0.9759\n",
      "Epoch 232/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9756\n",
      "Epoch 00232: loss did not improve from 0.16393\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1640 - accuracy: 0.9756\n",
      "Epoch 233/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9758\n",
      "Epoch 00233: loss did not improve from 0.16393\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1644 - accuracy: 0.9758\n",
      "Epoch 234/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1603 - accuracy: 0.9757\n",
      "Epoch 00234: loss improved from 0.16393 to 0.16027, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0234.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1603 - accuracy: 0.9757\n",
      "Epoch 235/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1579 - accuracy: 0.9763\n",
      "Epoch 00235: loss improved from 0.16027 to 0.15788, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0235.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1579 - accuracy: 0.9763\n",
      "Epoch 236/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.9769\n",
      "Epoch 00236: loss improved from 0.15788 to 0.15497, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0236.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1550 - accuracy: 0.9769\n",
      "Epoch 237/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1529 - accuracy: 0.9771\n",
      "Epoch 00237: loss improved from 0.15497 to 0.15286, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0237.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.1529 - accuracy: 0.9771\n",
      "Epoch 238/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9768\n",
      "Epoch 00238: loss improved from 0.15286 to 0.15187, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0238.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.1519 - accuracy: 0.9768\n",
      "Epoch 239/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9766\n",
      "Epoch 00239: loss improved from 0.15187 to 0.14975, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0239.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.1497 - accuracy: 0.9766\n",
      "Epoch 240/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9779\n",
      "Epoch 00240: loss did not improve from 0.14975\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1501 - accuracy: 0.9779\n",
      "Epoch 241/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.9776\n",
      "Epoch 00241: loss improved from 0.14975 to 0.14921, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0241.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.1492 - accuracy: 0.9776\n",
      "Epoch 242/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.9774\n",
      "Epoch 00242: loss did not improve from 0.14921\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1493 - accuracy: 0.9774\n",
      "Epoch 243/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.9779\n",
      "Epoch 00243: loss improved from 0.14921 to 0.14725, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0243.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1472 - accuracy: 0.9779\n",
      "Epoch 244/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.9785\n",
      "Epoch 00244: loss improved from 0.14725 to 0.14203, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0244.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1420 - accuracy: 0.9785\n",
      "Epoch 245/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9782\n",
      "Epoch 00245: loss did not improve from 0.14203\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1439 - accuracy: 0.9782\n",
      "Epoch 246/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.9783\n",
      "Epoch 00246: loss did not improve from 0.14203\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1426 - accuracy: 0.9783\n",
      "Epoch 247/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9784\n",
      "Epoch 00247: loss did not improve from 0.14203\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1421 - accuracy: 0.9784\n",
      "Epoch 248/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9780\n",
      "Epoch 00248: loss did not improve from 0.14203\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1429 - accuracy: 0.9780\n",
      "Epoch 249/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.9790\n",
      "Epoch 00249: loss improved from 0.14203 to 0.13765, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0249.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.1376 - accuracy: 0.9790\n",
      "Epoch 250/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9794\n",
      "Epoch 00250: loss improved from 0.13765 to 0.13508, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0250.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.1351 - accuracy: 0.9794\n",
      "Epoch 251/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9791\n",
      "Epoch 00251: loss improved from 0.13508 to 0.13467, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0251.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.1347 - accuracy: 0.9791\n",
      "Epoch 252/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9785\n",
      "Epoch 00252: loss did not improve from 0.13467\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1368 - accuracy: 0.9785\n",
      "Epoch 253/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9791\n",
      "Epoch 00253: loss improved from 0.13467 to 0.13326, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0253.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1333 - accuracy: 0.9791\n",
      "Epoch 254/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1313 - accuracy: 0.9792\n",
      "Epoch 00254: loss improved from 0.13326 to 0.13134, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0254.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1313 - accuracy: 0.9792\n",
      "Epoch 255/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.9795\n",
      "Epoch 00255: loss improved from 0.13134 to 0.12886, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0255.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1289 - accuracy: 0.9795\n",
      "Epoch 256/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9800\n",
      "Epoch 00256: loss improved from 0.12886 to 0.12812, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0256.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1281 - accuracy: 0.9800\n",
      "Epoch 257/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 0.9803\n",
      "Epoch 00257: loss improved from 0.12812 to 0.12662, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0257.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1266 - accuracy: 0.9803\n",
      "Epoch 258/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.9796\n",
      "Epoch 00258: loss did not improve from 0.12662\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1271 - accuracy: 0.9796\n",
      "Epoch 259/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9798\n",
      "Epoch 00259: loss did not improve from 0.12662\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1269 - accuracy: 0.9798\n",
      "Epoch 260/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.9803\n",
      "Epoch 00260: loss improved from 0.12662 to 0.12389, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0260.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1239 - accuracy: 0.9803\n",
      "Epoch 261/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.9800\n",
      "Epoch 00261: loss improved from 0.12389 to 0.12323, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0261.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1232 - accuracy: 0.9800\n",
      "Epoch 262/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9804\n",
      "Epoch 00262: loss improved from 0.12323 to 0.12232, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0262.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1223 - accuracy: 0.9804\n",
      "Epoch 263/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9801\n",
      "Epoch 00263: loss improved from 0.12232 to 0.12155, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0263.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1216 - accuracy: 0.9801\n",
      "Epoch 264/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.9803\n",
      "Epoch 00264: loss did not improve from 0.12155\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1228 - accuracy: 0.9803\n",
      "Epoch 265/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9804\n",
      "Epoch 00265: loss improved from 0.12155 to 0.12049, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0265.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1205 - accuracy: 0.9804\n",
      "Epoch 266/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9810\n",
      "Epoch 00266: loss improved from 0.12049 to 0.11777, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0266.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1178 - accuracy: 0.9810\n",
      "Epoch 267/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9810\n",
      "Epoch 00267: loss improved from 0.11777 to 0.11740, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0267.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1174 - accuracy: 0.9810\n",
      "Epoch 268/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9813\n",
      "Epoch 00268: loss did not improve from 0.11740\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1178 - accuracy: 0.9813\n",
      "Epoch 269/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.9805\n",
      "Epoch 00269: loss did not improve from 0.11740\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1177 - accuracy: 0.9805\n",
      "Epoch 270/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.9813\n",
      "Epoch 00270: loss did not improve from 0.11740\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1191 - accuracy: 0.9813\n",
      "Epoch 271/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.9808\n",
      "Epoch 00271: loss did not improve from 0.11740\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1179 - accuracy: 0.9808\n",
      "Epoch 272/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.9806\n",
      "Epoch 00272: loss improved from 0.11740 to 0.11631, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0272.ckpt\n",
      "2/2 [==============================] - 4s 3s/step - loss: 0.1163 - accuracy: 0.9806\n",
      "Epoch 273/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9808\n",
      "Epoch 00273: loss did not improve from 0.11631\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1176 - accuracy: 0.9808\n",
      "Epoch 274/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9811\n",
      "Epoch 00274: loss did not improve from 0.11631\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1164 - accuracy: 0.9811\n",
      "Epoch 275/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9812\n",
      "Epoch 00275: loss improved from 0.11631 to 0.11485, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0275.ckpt\n",
      "2/2 [==============================] - 10s 9s/step - loss: 0.1148 - accuracy: 0.9812\n",
      "Epoch 276/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9817\n",
      "Epoch 00276: loss improved from 0.11485 to 0.11158, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0276.ckpt\n",
      "2/2 [==============================] - 4s 3s/step - loss: 0.1116 - accuracy: 0.9817\n",
      "Epoch 277/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9816\n",
      "Epoch 00277: loss did not improve from 0.11158\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1121 - accuracy: 0.9816\n",
      "Epoch 278/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1126 - accuracy: 0.9818\n",
      "Epoch 00278: loss did not improve from 0.11158\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1126 - accuracy: 0.9818\n",
      "Epoch 279/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.9816\n",
      "Epoch 00279: loss improved from 0.11158 to 0.11105, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0279.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1111 - accuracy: 0.9816\n",
      "Epoch 280/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9823\n",
      "Epoch 00280: loss improved from 0.11105 to 0.10856, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0280.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1086 - accuracy: 0.9823\n",
      "Epoch 281/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9820\n",
      "Epoch 00281: loss improved from 0.10856 to 0.10855, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0281.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1086 - accuracy: 0.9820\n",
      "Epoch 282/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9815\n",
      "Epoch 00282: loss did not improve from 0.10855\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1089 - accuracy: 0.9815\n",
      "Epoch 283/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9822\n",
      "Epoch 00283: loss improved from 0.10855 to 0.10702, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0283.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1070 - accuracy: 0.9822\n",
      "Epoch 284/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9820\n",
      "Epoch 00284: loss did not improve from 0.10702\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1083 - accuracy: 0.9820\n",
      "Epoch 285/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9826\n",
      "Epoch 00285: loss did not improve from 0.10702\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1073 - accuracy: 0.9826\n",
      "Epoch 286/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.9822\n",
      "Epoch 00286: loss improved from 0.10702 to 0.10592, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0286.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 2s/step - loss: 0.1059 - accuracy: 0.9822\n",
      "Epoch 287/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9822\n",
      "Epoch 00287: loss did not improve from 0.10592\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1081 - accuracy: 0.9822\n",
      "Epoch 288/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9821\n",
      "Epoch 00288: loss improved from 0.10592 to 0.10569, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0288.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1057 - accuracy: 0.9821\n",
      "Epoch 289/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9821\n",
      "Epoch 00289: loss improved from 0.10569 to 0.10566, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0289.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.1057 - accuracy: 0.9821\n",
      "Epoch 290/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1065 - accuracy: 0.9823\n",
      "Epoch 00290: loss did not improve from 0.10566\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1065 - accuracy: 0.9823\n",
      "Epoch 291/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9833\n",
      "Epoch 00291: loss improved from 0.10566 to 0.10349, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0291.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.1035 - accuracy: 0.9833\n",
      "Epoch 292/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9825\n",
      "Epoch 00292: loss improved from 0.10349 to 0.10245, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0292.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1024 - accuracy: 0.9825\n",
      "Epoch 293/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9830\n",
      "Epoch 00293: loss improved from 0.10245 to 0.10085, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0293.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1009 - accuracy: 0.9830\n",
      "Epoch 294/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9832\n",
      "Epoch 00294: loss did not improve from 0.10085\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1016 - accuracy: 0.9832\n",
      "Epoch 295/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9825\n",
      "Epoch 00295: loss did not improve from 0.10085\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1024 - accuracy: 0.9825\n",
      "Epoch 296/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9832\n",
      "Epoch 00296: loss did not improve from 0.10085\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1021 - accuracy: 0.9832\n",
      "Epoch 297/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9833\n",
      "Epoch 00297: loss did not improve from 0.10085\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1033 - accuracy: 0.9833\n",
      "Epoch 298/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9833\n",
      "Epoch 00298: loss improved from 0.10085 to 0.09993, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0298.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0999 - accuracy: 0.9833\n",
      "Epoch 299/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9827\n",
      "Epoch 00299: loss did not improve from 0.09993\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1012 - accuracy: 0.9827\n",
      "Epoch 300/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9835\n",
      "Epoch 00300: loss improved from 0.09993 to 0.09722, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0300.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0972 - accuracy: 0.9835\n",
      "Epoch 301/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9830\n",
      "Epoch 00301: loss did not improve from 0.09722\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0999 - accuracy: 0.9830\n",
      "Epoch 302/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 0.9832\n",
      "Epoch 00302: loss did not improve from 0.09722\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0997 - accuracy: 0.9832\n",
      "Epoch 303/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9831\n",
      "Epoch 00303: loss did not improve from 0.09722\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0978 - accuracy: 0.9831\n",
      "Epoch 304/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9836\n",
      "Epoch 00304: loss did not improve from 0.09722\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0981 - accuracy: 0.9836\n",
      "Epoch 305/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9837\n",
      "Epoch 00305: loss did not improve from 0.09722\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0979 - accuracy: 0.9837\n",
      "Epoch 306/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9837\n",
      "Epoch 00306: loss improved from 0.09722 to 0.09478, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0306.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0948 - accuracy: 0.9837\n",
      "Epoch 307/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9837\n",
      "Epoch 00307: loss did not improve from 0.09478\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0974 - accuracy: 0.9837\n",
      "Epoch 308/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9835\n",
      "Epoch 00308: loss did not improve from 0.09478\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0972 - accuracy: 0.9835\n",
      "Epoch 309/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9841\n",
      "Epoch 00309: loss did not improve from 0.09478\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0957 - accuracy: 0.9841\n",
      "Epoch 310/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9839\n",
      "Epoch 00310: loss did not improve from 0.09478\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0953 - accuracy: 0.9839\n",
      "Epoch 311/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9840\n",
      "Epoch 00311: loss improved from 0.09478 to 0.09327, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0311.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0933 - accuracy: 0.9840\n",
      "Epoch 312/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9837\n",
      "Epoch 00312: loss did not improve from 0.09327\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0942 - accuracy: 0.9837\n",
      "Epoch 313/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9842\n",
      "Epoch 00313: loss improved from 0.09327 to 0.09222, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0313.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0922 - accuracy: 0.9842\n",
      "Epoch 314/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9842\n",
      "Epoch 00314: loss did not improve from 0.09222\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0939 - accuracy: 0.9842\n",
      "Epoch 315/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9838\n",
      "Epoch 00315: loss did not improve from 0.09222\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0944 - accuracy: 0.9838\n",
      "Epoch 316/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9843\n",
      "Epoch 00316: loss did not improve from 0.09222\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0923 - accuracy: 0.9843\n",
      "Epoch 317/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9844\n",
      "Epoch 00317: loss did not improve from 0.09222\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0923 - accuracy: 0.9844\n",
      "Epoch 318/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9845\n",
      "Epoch 00318: loss improved from 0.09222 to 0.09060, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0318.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0906 - accuracy: 0.9845\n",
      "Epoch 319/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9842\n",
      "Epoch 00319: loss did not improve from 0.09060\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0920 - accuracy: 0.9842\n",
      "Epoch 320/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9844\n",
      "Epoch 00320: loss did not improve from 0.09060\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0919 - accuracy: 0.9844\n",
      "Epoch 321/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.9846\n",
      "Epoch 00321: loss improved from 0.09060 to 0.09048, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0321.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0905 - accuracy: 0.9846\n",
      "Epoch 322/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9845\n",
      "Epoch 00322: loss improved from 0.09048 to 0.09035, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0322.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0904 - accuracy: 0.9845\n",
      "Epoch 323/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9849\n",
      "Epoch 00323: loss improved from 0.09035 to 0.08860, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0323.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0886 - accuracy: 0.9849\n",
      "Epoch 324/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9844\n",
      "Epoch 00324: loss did not improve from 0.08860\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0892 - accuracy: 0.9844\n",
      "Epoch 325/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9844\n",
      "Epoch 00325: loss did not improve from 0.08860\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0914 - accuracy: 0.9844\n",
      "Epoch 326/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9848\n",
      "Epoch 00326: loss did not improve from 0.08860\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0890 - accuracy: 0.9848\n",
      "Epoch 327/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9848\n",
      "Epoch 00327: loss improved from 0.08860 to 0.08703, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0327.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0870 - accuracy: 0.9848\n",
      "Epoch 328/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9847\n",
      "Epoch 00328: loss improved from 0.08703 to 0.08660, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0328.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0866 - accuracy: 0.9847\n",
      "Epoch 329/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9852\n",
      "Epoch 00329: loss improved from 0.08660 to 0.08647, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0329.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0865 - accuracy: 0.9852\n",
      "Epoch 330/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9849\n",
      "Epoch 00330: loss improved from 0.08647 to 0.08564, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0330.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0856 - accuracy: 0.9849\n",
      "Epoch 331/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9845\n",
      "Epoch 00331: loss did not improve from 0.08564\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0898 - accuracy: 0.9845\n",
      "Epoch 332/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9850\n",
      "Epoch 00332: loss improved from 0.08564 to 0.08562, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0332.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0856 - accuracy: 0.9850\n",
      "Epoch 333/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9852\n",
      "Epoch 00333: loss did not improve from 0.08562\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0873 - accuracy: 0.9852\n",
      "Epoch 334/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9848\n",
      "Epoch 00334: loss did not improve from 0.08562\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0885 - accuracy: 0.9848\n",
      "Epoch 335/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9847\n",
      "Epoch 00335: loss did not improve from 0.08562\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0886 - accuracy: 0.9847\n",
      "Epoch 336/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9857\n",
      "Epoch 00336: loss improved from 0.08562 to 0.08351, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0336.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0835 - accuracy: 0.9857\n",
      "Epoch 337/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9851\n",
      "Epoch 00337: loss did not improve from 0.08351\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0869 - accuracy: 0.9851\n",
      "Epoch 338/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9853\n",
      "Epoch 00338: loss did not improve from 0.08351\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0878 - accuracy: 0.9853\n",
      "Epoch 339/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9853\n",
      "Epoch 00339: loss did not improve from 0.08351\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0863 - accuracy: 0.9853\n",
      "Epoch 340/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9849\n",
      "Epoch 00340: loss did not improve from 0.08351\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0857 - accuracy: 0.9849\n",
      "Epoch 341/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9853\n",
      "Epoch 00341: loss did not improve from 0.08351\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0854 - accuracy: 0.9853\n",
      "Epoch 342/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9855\n",
      "Epoch 00342: loss did not improve from 0.08351\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0859 - accuracy: 0.9855\n",
      "Epoch 343/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9851\n",
      "Epoch 00343: loss did not improve from 0.08351\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0859 - accuracy: 0.9851\n",
      "Epoch 344/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9853\n",
      "Epoch 00344: loss did not improve from 0.08351\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0843 - accuracy: 0.9853\n",
      "Epoch 345/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9852\n",
      "Epoch 00345: loss did not improve from 0.08351\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0857 - accuracy: 0.9852\n",
      "Epoch 346/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9857\n",
      "Epoch 00346: loss did not improve from 0.08351\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0849 - accuracy: 0.9857\n",
      "Epoch 347/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9856\n",
      "Epoch 00347: loss improved from 0.08351 to 0.08230, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0347.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0823 - accuracy: 0.9856\n",
      "Epoch 348/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9857\n",
      "Epoch 00348: loss improved from 0.08230 to 0.08228, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0348.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0823 - accuracy: 0.9857\n",
      "Epoch 349/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9858\n",
      "Epoch 00349: loss improved from 0.08228 to 0.08155, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0349.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0815 - accuracy: 0.9858\n",
      "Epoch 350/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.9855\n",
      "Epoch 00350: loss improved from 0.08155 to 0.08132, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0350.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0813 - accuracy: 0.9855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9857\n",
      "Epoch 00351: loss did not improve from 0.08132\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0815 - accuracy: 0.9857\n",
      "Epoch 352/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9857\n",
      "Epoch 00352: loss did not improve from 0.08132\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0825 - accuracy: 0.9857\n",
      "Epoch 353/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9859\n",
      "Epoch 00353: loss improved from 0.08132 to 0.08037, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0353.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0804 - accuracy: 0.9859\n",
      "Epoch 354/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9860\n",
      "Epoch 00354: loss improved from 0.08037 to 0.07964, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0354.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0796 - accuracy: 0.9860\n",
      "Epoch 355/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9860\n",
      "Epoch 00355: loss did not improve from 0.07964\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0797 - accuracy: 0.9860\n",
      "Epoch 356/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9860\n",
      "Epoch 00356: loss improved from 0.07964 to 0.07785, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0356.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0779 - accuracy: 0.9860\n",
      "Epoch 357/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9860\n",
      "Epoch 00357: loss did not improve from 0.07785\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0793 - accuracy: 0.9860\n",
      "Epoch 358/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9861\n",
      "Epoch 00358: loss did not improve from 0.07785\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0782 - accuracy: 0.9861\n",
      "Epoch 359/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9860\n",
      "Epoch 00359: loss did not improve from 0.07785\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0798 - accuracy: 0.9860\n",
      "Epoch 360/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9860\n",
      "Epoch 00360: loss did not improve from 0.07785\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0789 - accuracy: 0.9860\n",
      "Epoch 361/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9863\n",
      "Epoch 00361: loss improved from 0.07785 to 0.07669, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0361.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0767 - accuracy: 0.9863\n",
      "Epoch 362/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9860\n",
      "Epoch 00362: loss did not improve from 0.07669\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0787 - accuracy: 0.9860\n",
      "Epoch 363/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9867\n",
      "Epoch 00363: loss improved from 0.07669 to 0.07587, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0363.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0759 - accuracy: 0.9867\n",
      "Epoch 364/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.9868\n",
      "Epoch 00364: loss improved from 0.07587 to 0.07439, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0364.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0744 - accuracy: 0.9868\n",
      "Epoch 365/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9865\n",
      "Epoch 00365: loss did not improve from 0.07439\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0765 - accuracy: 0.9865\n",
      "Epoch 366/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9863\n",
      "Epoch 00366: loss did not improve from 0.07439\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0776 - accuracy: 0.9863\n",
      "Epoch 367/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9867\n",
      "Epoch 00367: loss did not improve from 0.07439\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0763 - accuracy: 0.9867\n",
      "Epoch 368/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9862\n",
      "Epoch 00368: loss did not improve from 0.07439\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0774 - accuracy: 0.9862\n",
      "Epoch 369/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9864\n",
      "Epoch 00369: loss did not improve from 0.07439\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0752 - accuracy: 0.9864\n",
      "Epoch 370/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9866\n",
      "Epoch 00370: loss did not improve from 0.07439\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0758 - accuracy: 0.9866\n",
      "Epoch 371/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9864\n",
      "Epoch 00371: loss did not improve from 0.07439\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0758 - accuracy: 0.9864\n",
      "Epoch 372/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9864\n",
      "Epoch 00372: loss did not improve from 0.07439\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0763 - accuracy: 0.9864\n",
      "Epoch 373/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9868\n",
      "Epoch 00373: loss improved from 0.07439 to 0.07417, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0373.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0742 - accuracy: 0.9868\n",
      "Epoch 374/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9869\n",
      "Epoch 00374: loss improved from 0.07417 to 0.07380, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0374.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0738 - accuracy: 0.9869\n",
      "Epoch 375/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9872\n",
      "Epoch 00375: loss improved from 0.07380 to 0.07249, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0375.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0725 - accuracy: 0.9872\n",
      "Epoch 376/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9865\n",
      "Epoch 00376: loss did not improve from 0.07249\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0752 - accuracy: 0.9865\n",
      "Epoch 377/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9871\n",
      "Epoch 00377: loss did not improve from 0.07249\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0738 - accuracy: 0.9871\n",
      "Epoch 378/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9861\n",
      "Epoch 00378: loss did not improve from 0.07249\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0760 - accuracy: 0.9861\n",
      "Epoch 379/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9871\n",
      "Epoch 00379: loss improved from 0.07249 to 0.07198, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0379.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0720 - accuracy: 0.9871\n",
      "Epoch 380/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9874\n",
      "Epoch 00380: loss did not improve from 0.07198\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0733 - accuracy: 0.9874\n",
      "Epoch 381/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9868\n",
      "Epoch 00381: loss did not improve from 0.07198\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0748 - accuracy: 0.9868\n",
      "Epoch 382/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9870\n",
      "Epoch 00382: loss did not improve from 0.07198\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0731 - accuracy: 0.9870\n",
      "Epoch 383/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9872\n",
      "Epoch 00383: loss did not improve from 0.07198\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0729 - accuracy: 0.9872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9867\n",
      "Epoch 00384: loss did not improve from 0.07198\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0750 - accuracy: 0.9867\n",
      "Epoch 385/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 0.9870\n",
      "Epoch 00385: loss did not improve from 0.07198\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0721 - accuracy: 0.9870\n",
      "Epoch 386/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9873\n",
      "Epoch 00386: loss improved from 0.07198 to 0.07081, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0386.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0708 - accuracy: 0.9873\n",
      "Epoch 387/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9872\n",
      "Epoch 00387: loss did not improve from 0.07081\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0722 - accuracy: 0.9872\n",
      "Epoch 388/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9868\n",
      "Epoch 00388: loss did not improve from 0.07081\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0713 - accuracy: 0.9868\n",
      "Epoch 389/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9871\n",
      "Epoch 00389: loss did not improve from 0.07081\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0719 - accuracy: 0.9871\n",
      "Epoch 390/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9872\n",
      "Epoch 00390: loss did not improve from 0.07081\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0709 - accuracy: 0.9872\n",
      "Epoch 391/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9874\n",
      "Epoch 00391: loss improved from 0.07081 to 0.06968, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0391.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0697 - accuracy: 0.9874\n",
      "Epoch 392/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9874\n",
      "Epoch 00392: loss did not improve from 0.06968\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0722 - accuracy: 0.9874\n",
      "Epoch 393/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9872\n",
      "Epoch 00393: loss did not improve from 0.06968\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0707 - accuracy: 0.9872\n",
      "Epoch 394/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9873\n",
      "Epoch 00394: loss did not improve from 0.06968\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0700 - accuracy: 0.9873\n",
      "Epoch 395/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9872\n",
      "Epoch 00395: loss did not improve from 0.06968\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0707 - accuracy: 0.9872\n",
      "Epoch 396/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9871\n",
      "Epoch 00396: loss did not improve from 0.06968\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0724 - accuracy: 0.9871\n",
      "Epoch 397/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9873\n",
      "Epoch 00397: loss did not improve from 0.06968\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0703 - accuracy: 0.9873\n",
      "Epoch 398/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9874\n",
      "Epoch 00398: loss did not improve from 0.06968\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0697 - accuracy: 0.9874\n",
      "Epoch 399/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9874\n",
      "Epoch 00399: loss did not improve from 0.06968\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0711 - accuracy: 0.9874\n",
      "Epoch 400/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9878\n",
      "Epoch 00400: loss improved from 0.06968 to 0.06945, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0400.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0695 - accuracy: 0.9878\n",
      "Epoch 401/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9872\n",
      "Epoch 00401: loss did not improve from 0.06945\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0706 - accuracy: 0.9872\n",
      "Epoch 402/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9871\n",
      "Epoch 00402: loss did not improve from 0.06945\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0709 - accuracy: 0.9871\n",
      "Epoch 403/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9879\n",
      "Epoch 00403: loss improved from 0.06945 to 0.06678, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0403.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0668 - accuracy: 0.9879\n",
      "Epoch 404/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9874\n",
      "Epoch 00404: loss did not improve from 0.06678\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0689 - accuracy: 0.9874\n",
      "Epoch 405/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9874\n",
      "Epoch 00405: loss did not improve from 0.06678\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0694 - accuracy: 0.9874\n",
      "Epoch 406/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9877\n",
      "Epoch 00406: loss did not improve from 0.06678\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0674 - accuracy: 0.9877\n",
      "Epoch 407/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.9878\n",
      "Epoch 00407: loss did not improve from 0.06678\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0679 - accuracy: 0.9878\n",
      "Epoch 408/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9876\n",
      "Epoch 00408: loss did not improve from 0.06678\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0688 - accuracy: 0.9876\n",
      "Epoch 409/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9875\n",
      "Epoch 00409: loss did not improve from 0.06678\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0675 - accuracy: 0.9875\n",
      "Epoch 410/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9879\n",
      "Epoch 00410: loss improved from 0.06678 to 0.06608, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0410.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0661 - accuracy: 0.9879\n",
      "Epoch 411/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9874\n",
      "Epoch 00411: loss did not improve from 0.06608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0692 - accuracy: 0.9874\n",
      "Epoch 412/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9879\n",
      "Epoch 00412: loss did not improve from 0.06608\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0671 - accuracy: 0.9879\n",
      "Epoch 413/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9879\n",
      "Epoch 00413: loss did not improve from 0.06608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0668 - accuracy: 0.9879\n",
      "Epoch 414/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9876\n",
      "Epoch 00414: loss did not improve from 0.06608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0690 - accuracy: 0.9876\n",
      "Epoch 415/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9877\n",
      "Epoch 00415: loss did not improve from 0.06608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0672 - accuracy: 0.9877\n",
      "Epoch 416/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9878\n",
      "Epoch 00416: loss did not improve from 0.06608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0671 - accuracy: 0.9878\n",
      "Epoch 417/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9881\n",
      "Epoch 00417: loss improved from 0.06608 to 0.06495, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0417.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0649 - accuracy: 0.9881\n",
      "Epoch 418/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9881\n",
      "Epoch 00418: loss did not improve from 0.06495\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0660 - accuracy: 0.9881\n",
      "Epoch 419/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9877\n",
      "Epoch 00419: loss did not improve from 0.06495\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0673 - accuracy: 0.9877\n",
      "Epoch 420/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9878\n",
      "Epoch 00420: loss did not improve from 0.06495\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0664 - accuracy: 0.9878\n",
      "Epoch 421/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9880\n",
      "Epoch 00421: loss did not improve from 0.06495\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0663 - accuracy: 0.9880\n",
      "Epoch 422/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9881\n",
      "Epoch 00422: loss did not improve from 0.06495\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0660 - accuracy: 0.9881\n",
      "Epoch 423/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9877\n",
      "Epoch 00423: loss did not improve from 0.06495\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0676 - accuracy: 0.9877\n",
      "Epoch 424/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9881\n",
      "Epoch 00424: loss improved from 0.06495 to 0.06469, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0424.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0647 - accuracy: 0.9881\n",
      "Epoch 425/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9880\n",
      "Epoch 00425: loss improved from 0.06469 to 0.06451, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0425.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0645 - accuracy: 0.9880\n",
      "Epoch 426/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9884\n",
      "Epoch 00426: loss did not improve from 0.06451\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0646 - accuracy: 0.9884\n",
      "Epoch 427/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9881\n",
      "Epoch 00427: loss did not improve from 0.06451\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0664 - accuracy: 0.9881\n",
      "Epoch 428/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9885\n",
      "Epoch 00428: loss improved from 0.06451 to 0.06332, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0428.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0633 - accuracy: 0.9885\n",
      "Epoch 429/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9883\n",
      "Epoch 00429: loss improved from 0.06332 to 0.06290, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0429.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0629 - accuracy: 0.9883\n",
      "Epoch 430/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9883\n",
      "Epoch 00430: loss did not improve from 0.06290\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0652 - accuracy: 0.9883\n",
      "Epoch 431/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9883\n",
      "Epoch 00431: loss did not improve from 0.06290\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0629 - accuracy: 0.9883\n",
      "Epoch 432/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9879\n",
      "Epoch 00432: loss did not improve from 0.06290\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0647 - accuracy: 0.9879\n",
      "Epoch 433/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9884\n",
      "Epoch 00433: loss did not improve from 0.06290\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0649 - accuracy: 0.9884\n",
      "Epoch 434/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9884\n",
      "Epoch 00434: loss did not improve from 0.06290\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0634 - accuracy: 0.9884\n",
      "Epoch 435/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9886\n",
      "Epoch 00435: loss improved from 0.06290 to 0.06232, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0435.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0623 - accuracy: 0.9886\n",
      "Epoch 436/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9887\n",
      "Epoch 00436: loss did not improve from 0.06232\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0635 - accuracy: 0.9887\n",
      "Epoch 437/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9885\n",
      "Epoch 00437: loss did not improve from 0.06232\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0625 - accuracy: 0.9885\n",
      "Epoch 438/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9888\n",
      "Epoch 00438: loss improved from 0.06232 to 0.06194, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0438.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0619 - accuracy: 0.9888\n",
      "Epoch 439/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9882\n",
      "Epoch 00439: loss did not improve from 0.06194\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0634 - accuracy: 0.9882\n",
      "Epoch 440/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9885\n",
      "Epoch 00440: loss improved from 0.06194 to 0.06159, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0440.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0616 - accuracy: 0.9885\n",
      "Epoch 441/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9888\n",
      "Epoch 00441: loss did not improve from 0.06159\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0630 - accuracy: 0.9888\n",
      "Epoch 442/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9890\n",
      "Epoch 00442: loss did not improve from 0.06159\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0619 - accuracy: 0.9890\n",
      "Epoch 443/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9887\n",
      "Epoch 00443: loss improved from 0.06159 to 0.06152, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0443.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0615 - accuracy: 0.9887\n",
      "Epoch 444/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9887\n",
      "Epoch 00444: loss improved from 0.06152 to 0.06105, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0444.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0611 - accuracy: 0.9887\n",
      "Epoch 445/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9888\n",
      "Epoch 00445: loss did not improve from 0.06105\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0613 - accuracy: 0.9888\n",
      "Epoch 446/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9888\n",
      "Epoch 00446: loss did not improve from 0.06105\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0621 - accuracy: 0.9888\n",
      "Epoch 447/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9882\n",
      "Epoch 00447: loss did not improve from 0.06105\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0636 - accuracy: 0.9882\n",
      "Epoch 448/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9886\n",
      "Epoch 00448: loss improved from 0.06105 to 0.06078, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0448.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0608 - accuracy: 0.9886\n",
      "Epoch 449/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9885\n",
      "Epoch 00449: loss did not improve from 0.06078\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0622 - accuracy: 0.9885\n",
      "Epoch 450/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9885\n",
      "Epoch 00450: loss did not improve from 0.06078\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0617 - accuracy: 0.9885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9888\n",
      "Epoch 00451: loss did not improve from 0.06078\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0608 - accuracy: 0.9888\n",
      "Epoch 452/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9886\n",
      "Epoch 00452: loss did not improve from 0.06078\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0619 - accuracy: 0.9886\n",
      "Epoch 453/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9883\n",
      "Epoch 00453: loss did not improve from 0.06078\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0625 - accuracy: 0.9883\n",
      "Epoch 454/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9888\n",
      "Epoch 00454: loss did not improve from 0.06078\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0613 - accuracy: 0.9888\n",
      "Epoch 455/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9888\n",
      "Epoch 00455: loss did not improve from 0.06078\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0617 - accuracy: 0.9888\n",
      "Epoch 456/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9890\n",
      "Epoch 00456: loss improved from 0.06078 to 0.05999, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0456.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0600 - accuracy: 0.9890\n",
      "Epoch 457/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9888\n",
      "Epoch 00457: loss did not improve from 0.05999\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0607 - accuracy: 0.9888\n",
      "Epoch 458/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9890\n",
      "Epoch 00458: loss did not improve from 0.05999\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0611 - accuracy: 0.9890\n",
      "Epoch 459/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9890\n",
      "Epoch 00459: loss did not improve from 0.05999\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0601 - accuracy: 0.9890\n",
      "Epoch 460/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9890\n",
      "Epoch 00460: loss improved from 0.05999 to 0.05960, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0460.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0596 - accuracy: 0.9890\n",
      "Epoch 461/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9892\n",
      "Epoch 00461: loss did not improve from 0.05960\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0604 - accuracy: 0.9892\n",
      "Epoch 462/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9889\n",
      "Epoch 00462: loss improved from 0.05960 to 0.05953, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0462.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0595 - accuracy: 0.9889\n",
      "Epoch 463/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9891\n",
      "Epoch 00463: loss did not improve from 0.05953\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0622 - accuracy: 0.9891\n",
      "Epoch 464/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9893\n",
      "Epoch 00464: loss improved from 0.05953 to 0.05852, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_0464.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0585 - accuracy: 0.9893\n",
      "Epoch 465/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9892\n",
      "Epoch 00465: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0603 - accuracy: 0.9892\n",
      "Epoch 466/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9891\n",
      "Epoch 00466: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0591 - accuracy: 0.9891\n",
      "Epoch 467/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9890\n",
      "Epoch 00467: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0599 - accuracy: 0.9890\n",
      "Epoch 468/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 0.9605\n",
      "Epoch 00468: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1521 - accuracy: 0.9605\n",
      "Epoch 469/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 4.1027 - accuracy: 0.3405\n",
      "Epoch 00469: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 4.1027 - accuracy: 0.3405\n",
      "Epoch 470/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.3586 - accuracy: 0.3030\n",
      "Epoch 00470: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 3.3586 - accuracy: 0.3030\n",
      "Epoch 471/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.4795 - accuracy: 0.3349\n",
      "Epoch 00471: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 2.4795 - accuracy: 0.3349\n",
      "Epoch 472/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1755 - accuracy: 0.3830\n",
      "Epoch 00472: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 2.1755 - accuracy: 0.3830\n",
      "Epoch 473/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0262 - accuracy: 0.4016\n",
      "Epoch 00473: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 2.0262 - accuracy: 0.4016\n",
      "Epoch 474/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9496 - accuracy: 0.4057\n",
      "Epoch 00474: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.9496 - accuracy: 0.4057\n",
      "Epoch 475/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.9016 - accuracy: 0.4097\n",
      "Epoch 00475: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.9016 - accuracy: 0.4097\n",
      "Epoch 476/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8617 - accuracy: 0.4202\n",
      "Epoch 00476: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.8617 - accuracy: 0.4202\n",
      "Epoch 477/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8470 - accuracy: 0.4271\n",
      "Epoch 00477: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.8470 - accuracy: 0.4271\n",
      "Epoch 478/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8099 - accuracy: 0.4366\n",
      "Epoch 00478: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.8099 - accuracy: 0.4366\n",
      "Epoch 479/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7754 - accuracy: 0.4454\n",
      "Epoch 00479: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.7754 - accuracy: 0.4454\n",
      "Epoch 480/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7531 - accuracy: 0.4511\n",
      "Epoch 00480: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.7531 - accuracy: 0.4511\n",
      "Epoch 481/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7503 - accuracy: 0.4531\n",
      "Epoch 00481: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.7503 - accuracy: 0.4531\n",
      "Epoch 482/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7213 - accuracy: 0.4602\n",
      "Epoch 00482: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.7213 - accuracy: 0.4602\n",
      "Epoch 483/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7050 - accuracy: 0.4660\n",
      "Epoch 00483: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.7050 - accuracy: 0.4660\n",
      "Epoch 484/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6809 - accuracy: 0.4747\n",
      "Epoch 00484: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6809 - accuracy: 0.4747\n",
      "Epoch 485/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6711 - accuracy: 0.4783\n",
      "Epoch 00485: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6711 - accuracy: 0.4783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6476 - accuracy: 0.4843\n",
      "Epoch 00486: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6476 - accuracy: 0.4843\n",
      "Epoch 487/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6452 - accuracy: 0.4871\n",
      "Epoch 00487: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6452 - accuracy: 0.4871\n",
      "Epoch 488/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6171 - accuracy: 0.4967\n",
      "Epoch 00488: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6171 - accuracy: 0.4967\n",
      "Epoch 489/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6233 - accuracy: 0.4930\n",
      "Epoch 00489: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6233 - accuracy: 0.4930\n",
      "Epoch 490/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6040 - accuracy: 0.4997\n",
      "Epoch 00490: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6040 - accuracy: 0.4997\n",
      "Epoch 491/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5931 - accuracy: 0.5032\n",
      "Epoch 00491: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5931 - accuracy: 0.5032\n",
      "Epoch 492/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5810 - accuracy: 0.5073\n",
      "Epoch 00492: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5810 - accuracy: 0.5073\n",
      "Epoch 493/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5762 - accuracy: 0.5088\n",
      "Epoch 00493: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5762 - accuracy: 0.5088\n",
      "Epoch 494/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5624 - accuracy: 0.5126\n",
      "Epoch 00494: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5624 - accuracy: 0.5126\n",
      "Epoch 495/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5554 - accuracy: 0.5142\n",
      "Epoch 00495: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5554 - accuracy: 0.5142\n",
      "Epoch 496/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5485 - accuracy: 0.5157\n",
      "Epoch 00496: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5485 - accuracy: 0.5157\n",
      "Epoch 497/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5337 - accuracy: 0.5210\n",
      "Epoch 00497: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5337 - accuracy: 0.5210\n",
      "Epoch 498/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.5239\n",
      "Epoch 00498: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5289 - accuracy: 0.5239\n",
      "Epoch 499/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5159 - accuracy: 0.5279\n",
      "Epoch 00499: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5159 - accuracy: 0.5279\n",
      "Epoch 500/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5124 - accuracy: 0.5280\n",
      "Epoch 00500: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.5124 - accuracy: 0.5280\n",
      "Epoch 501/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4971 - accuracy: 0.5317\n",
      "Epoch 00501: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4971 - accuracy: 0.5317\n",
      "Epoch 502/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4954 - accuracy: 0.5352\n",
      "Epoch 00502: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4954 - accuracy: 0.5352\n",
      "Epoch 503/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4806 - accuracy: 0.5395\n",
      "Epoch 00503: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4806 - accuracy: 0.5395\n",
      "Epoch 504/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4820 - accuracy: 0.5388\n",
      "Epoch 00504: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4820 - accuracy: 0.5388\n",
      "Epoch 505/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4786 - accuracy: 0.5387\n",
      "Epoch 00505: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4786 - accuracy: 0.5387\n",
      "Epoch 506/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4583 - accuracy: 0.5467\n",
      "Epoch 00506: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4583 - accuracy: 0.5467\n",
      "Epoch 507/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4623 - accuracy: 0.5453\n",
      "Epoch 00507: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4623 - accuracy: 0.5453\n",
      "Epoch 508/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4465 - accuracy: 0.5502\n",
      "Epoch 00508: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4465 - accuracy: 0.5502\n",
      "Epoch 509/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4445 - accuracy: 0.5517\n",
      "Epoch 00509: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4445 - accuracy: 0.5517\n",
      "Epoch 510/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4441 - accuracy: 0.5500\n",
      "Epoch 00510: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4441 - accuracy: 0.5500\n",
      "Epoch 511/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4356 - accuracy: 0.5545\n",
      "Epoch 00511: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4356 - accuracy: 0.5545\n",
      "Epoch 512/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4339 - accuracy: 0.5542\n",
      "Epoch 00512: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4339 - accuracy: 0.5542\n",
      "Epoch 513/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4260 - accuracy: 0.5594\n",
      "Epoch 00513: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4260 - accuracy: 0.5594\n",
      "Epoch 514/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4045 - accuracy: 0.5655\n",
      "Epoch 00514: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4045 - accuracy: 0.5655\n",
      "Epoch 515/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4136 - accuracy: 0.5618\n",
      "Epoch 00515: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4136 - accuracy: 0.5618\n",
      "Epoch 516/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4055 - accuracy: 0.5632\n",
      "Epoch 00516: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.4055 - accuracy: 0.5632\n",
      "Epoch 517/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3873 - accuracy: 0.5691\n",
      "Epoch 00517: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3873 - accuracy: 0.5691\n",
      "Epoch 518/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3934 - accuracy: 0.5678\n",
      "Epoch 00518: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3934 - accuracy: 0.5678\n",
      "Epoch 519/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3788 - accuracy: 0.5720\n",
      "Epoch 00519: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3788 - accuracy: 0.5720\n",
      "Epoch 520/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3692 - accuracy: 0.5772\n",
      "Epoch 00520: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3692 - accuracy: 0.5772\n",
      "Epoch 521/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3646 - accuracy: 0.5790\n",
      "Epoch 00521: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3646 - accuracy: 0.5790\n",
      "Epoch 522/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.3722 - accuracy: 0.5755\n",
      "Epoch 00522: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3722 - accuracy: 0.5755\n",
      "Epoch 523/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3523 - accuracy: 0.5824\n",
      "Epoch 00523: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3523 - accuracy: 0.5824\n",
      "Epoch 524/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3505 - accuracy: 0.5829\n",
      "Epoch 00524: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3505 - accuracy: 0.5829\n",
      "Epoch 525/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3504 - accuracy: 0.5836\n",
      "Epoch 00525: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3504 - accuracy: 0.5836\n",
      "Epoch 526/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3476 - accuracy: 0.5832\n",
      "Epoch 00526: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3476 - accuracy: 0.5832\n",
      "Epoch 527/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3331 - accuracy: 0.5899\n",
      "Epoch 00527: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3331 - accuracy: 0.5899\n",
      "Epoch 528/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3253 - accuracy: 0.5912\n",
      "Epoch 00528: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3253 - accuracy: 0.5912\n",
      "Epoch 529/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3234 - accuracy: 0.5925\n",
      "Epoch 00529: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3234 - accuracy: 0.5925\n",
      "Epoch 530/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3233 - accuracy: 0.5928\n",
      "Epoch 00530: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.3233 - accuracy: 0.5928\n",
      "Epoch 531/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3211 - accuracy: 0.5939\n",
      "Epoch 00531: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3211 - accuracy: 0.5939\n",
      "Epoch 532/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3022 - accuracy: 0.6003\n",
      "Epoch 00532: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3022 - accuracy: 0.6003\n",
      "Epoch 533/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3094 - accuracy: 0.5974\n",
      "Epoch 00533: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3094 - accuracy: 0.5974\n",
      "Epoch 534/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3040 - accuracy: 0.6001\n",
      "Epoch 00534: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3040 - accuracy: 0.6001\n",
      "Epoch 535/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2950 - accuracy: 0.6024\n",
      "Epoch 00535: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2950 - accuracy: 0.6024\n",
      "Epoch 536/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2892 - accuracy: 0.6047\n",
      "Epoch 00536: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2892 - accuracy: 0.6047\n",
      "Epoch 537/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2888 - accuracy: 0.6058\n",
      "Epoch 00537: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2888 - accuracy: 0.6058\n",
      "Epoch 538/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2844 - accuracy: 0.6056\n",
      "Epoch 00538: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2844 - accuracy: 0.6056\n",
      "Epoch 539/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2806 - accuracy: 0.6073\n",
      "Epoch 00539: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2806 - accuracy: 0.6073\n",
      "Epoch 540/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2682 - accuracy: 0.6120\n",
      "Epoch 00540: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2682 - accuracy: 0.6120\n",
      "Epoch 541/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2711 - accuracy: 0.6106\n",
      "Epoch 00541: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2711 - accuracy: 0.6106\n",
      "Epoch 542/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2535 - accuracy: 0.6164\n",
      "Epoch 00542: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2535 - accuracy: 0.6164\n",
      "Epoch 543/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2599 - accuracy: 0.6141\n",
      "Epoch 00543: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2599 - accuracy: 0.6141\n",
      "Epoch 544/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2355 - accuracy: 0.6230\n",
      "Epoch 00544: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2355 - accuracy: 0.6230\n",
      "Epoch 545/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2459 - accuracy: 0.6197\n",
      "Epoch 00545: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2459 - accuracy: 0.6197\n",
      "Epoch 546/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2256 - accuracy: 0.6275\n",
      "Epoch 00546: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2256 - accuracy: 0.6275\n",
      "Epoch 547/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2340 - accuracy: 0.6229\n",
      "Epoch 00547: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2340 - accuracy: 0.6229\n",
      "Epoch 548/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2269 - accuracy: 0.6254\n",
      "Epoch 00548: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2269 - accuracy: 0.6254\n",
      "Epoch 549/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2085 - accuracy: 0.6341\n",
      "Epoch 00549: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2085 - accuracy: 0.6341\n",
      "Epoch 550/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2286 - accuracy: 0.6251\n",
      "Epoch 00550: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2286 - accuracy: 0.6251\n",
      "Epoch 551/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2231 - accuracy: 0.6272\n",
      "Epoch 00551: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2231 - accuracy: 0.6272\n",
      "Epoch 552/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2135 - accuracy: 0.6306\n",
      "Epoch 00552: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2135 - accuracy: 0.6306\n",
      "Epoch 553/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2044 - accuracy: 0.6331\n",
      "Epoch 00553: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2044 - accuracy: 0.6331\n",
      "Epoch 554/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2033 - accuracy: 0.6335\n",
      "Epoch 00554: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2033 - accuracy: 0.6335\n",
      "Epoch 555/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1880 - accuracy: 0.6381\n",
      "Epoch 00555: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1880 - accuracy: 0.6381\n",
      "Epoch 556/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2047 - accuracy: 0.6331\n",
      "Epoch 00556: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2047 - accuracy: 0.6331\n",
      "Epoch 557/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1926 - accuracy: 0.6383\n",
      "Epoch 00557: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1926 - accuracy: 0.6383\n",
      "Epoch 558/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.1779 - accuracy: 0.6414\n",
      "Epoch 00558: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1779 - accuracy: 0.6414\n",
      "Epoch 559/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1696 - accuracy: 0.6470\n",
      "Epoch 00559: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1696 - accuracy: 0.6470\n",
      "Epoch 560/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1680 - accuracy: 0.6470\n",
      "Epoch 00560: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.1680 - accuracy: 0.6470\n",
      "Epoch 561/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1693 - accuracy: 0.6467\n",
      "Epoch 00561: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.1693 - accuracy: 0.6467\n",
      "Epoch 562/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1689 - accuracy: 0.6466\n",
      "Epoch 00562: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1.1689 - accuracy: 0.6466\n",
      "Epoch 563/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1544 - accuracy: 0.6509\n",
      "Epoch 00563: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1544 - accuracy: 0.6509\n",
      "Epoch 564/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1501 - accuracy: 0.6532\n",
      "Epoch 00564: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1501 - accuracy: 0.6532\n",
      "Epoch 565/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1425 - accuracy: 0.6553\n",
      "Epoch 00565: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1425 - accuracy: 0.6553\n",
      "Epoch 566/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1420 - accuracy: 0.6549\n",
      "Epoch 00566: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1420 - accuracy: 0.6549\n",
      "Epoch 567/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1350 - accuracy: 0.6570\n",
      "Epoch 00567: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1350 - accuracy: 0.6570\n",
      "Epoch 568/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1371 - accuracy: 0.6565\n",
      "Epoch 00568: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1371 - accuracy: 0.6565\n",
      "Epoch 569/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1226 - accuracy: 0.6624\n",
      "Epoch 00569: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1226 - accuracy: 0.6624\n",
      "Epoch 570/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1201 - accuracy: 0.6623\n",
      "Epoch 00570: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1201 - accuracy: 0.6623\n",
      "Epoch 571/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1265 - accuracy: 0.6598\n",
      "Epoch 00571: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1265 - accuracy: 0.6598\n",
      "Epoch 572/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1192 - accuracy: 0.6639\n",
      "Epoch 00572: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1192 - accuracy: 0.6639\n",
      "Epoch 573/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1263 - accuracy: 0.6608\n",
      "Epoch 00573: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1263 - accuracy: 0.6608\n",
      "Epoch 574/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0997 - accuracy: 0.6699\n",
      "Epoch 00574: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0997 - accuracy: 0.6699\n",
      "Epoch 575/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1035 - accuracy: 0.6688\n",
      "Epoch 00575: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1035 - accuracy: 0.6688\n",
      "Epoch 576/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0935 - accuracy: 0.6706\n",
      "Epoch 00576: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0935 - accuracy: 0.6706\n",
      "Epoch 577/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0988 - accuracy: 0.6692\n",
      "Epoch 00577: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0988 - accuracy: 0.6692\n",
      "Epoch 578/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0861 - accuracy: 0.6731\n",
      "Epoch 00578: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0861 - accuracy: 0.6731\n",
      "Epoch 579/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0850 - accuracy: 0.6745\n",
      "Epoch 00579: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0850 - accuracy: 0.6745\n",
      "Epoch 580/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0892 - accuracy: 0.6733\n",
      "Epoch 00580: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0892 - accuracy: 0.6733\n",
      "Epoch 581/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0693 - accuracy: 0.6812\n",
      "Epoch 00581: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0693 - accuracy: 0.6812\n",
      "Epoch 582/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0669 - accuracy: 0.6806\n",
      "Epoch 00582: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0669 - accuracy: 0.6806\n",
      "Epoch 583/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0661 - accuracy: 0.6807\n",
      "Epoch 00583: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0661 - accuracy: 0.6807\n",
      "Epoch 584/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0515 - accuracy: 0.6851\n",
      "Epoch 00584: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0515 - accuracy: 0.6851\n",
      "Epoch 585/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0405 - accuracy: 0.6909\n",
      "Epoch 00585: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0405 - accuracy: 0.6909\n",
      "Epoch 586/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0477 - accuracy: 0.6872\n",
      "Epoch 00586: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0477 - accuracy: 0.6872\n",
      "Epoch 587/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0380 - accuracy: 0.6912\n",
      "Epoch 00587: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0380 - accuracy: 0.6912\n",
      "Epoch 588/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0203 - accuracy: 0.6967\n",
      "Epoch 00588: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0203 - accuracy: 0.6967\n",
      "Epoch 589/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0245 - accuracy: 0.6958\n",
      "Epoch 00589: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0245 - accuracy: 0.6958\n",
      "Epoch 590/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0252 - accuracy: 0.6953\n",
      "Epoch 00590: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0252 - accuracy: 0.6953\n",
      "Epoch 591/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0141 - accuracy: 0.6972\n",
      "Epoch 00591: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0141 - accuracy: 0.6972\n",
      "Epoch 592/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0121 - accuracy: 0.6992\n",
      "Epoch 00592: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0121 - accuracy: 0.6992\n",
      "Epoch 593/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.7015\n",
      "Epoch 00593: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0063 - accuracy: 0.7015\n",
      "Epoch 594/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.0060 - accuracy: 0.7008\n",
      "Epoch 00594: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0060 - accuracy: 0.7008\n",
      "Epoch 595/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9952 - accuracy: 0.7051\n",
      "Epoch 00595: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9952 - accuracy: 0.7051\n",
      "Epoch 596/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9934 - accuracy: 0.7059\n",
      "Epoch 00596: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9934 - accuracy: 0.7059\n",
      "Epoch 597/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0079 - accuracy: 0.7010\n",
      "Epoch 00597: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0079 - accuracy: 0.7010\n",
      "Epoch 598/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9880 - accuracy: 0.7079\n",
      "Epoch 00598: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9880 - accuracy: 0.7079\n",
      "Epoch 599/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9819 - accuracy: 0.7088\n",
      "Epoch 00599: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9819 - accuracy: 0.7088\n",
      "Epoch 600/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9658 - accuracy: 0.7152\n",
      "Epoch 00600: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9658 - accuracy: 0.7152\n",
      "Epoch 601/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9626 - accuracy: 0.7156\n",
      "Epoch 00601: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9626 - accuracy: 0.7156\n",
      "Epoch 602/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9735 - accuracy: 0.7123\n",
      "Epoch 00602: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9735 - accuracy: 0.7123\n",
      "Epoch 603/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9563 - accuracy: 0.7177\n",
      "Epoch 00603: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9563 - accuracy: 0.7177\n",
      "Epoch 604/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9609 - accuracy: 0.7161\n",
      "Epoch 00604: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9609 - accuracy: 0.7161\n",
      "Epoch 605/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9446 - accuracy: 0.7233\n",
      "Epoch 00605: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9446 - accuracy: 0.7233\n",
      "Epoch 606/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9400 - accuracy: 0.7243\n",
      "Epoch 00606: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9400 - accuracy: 0.7243\n",
      "Epoch 607/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9436 - accuracy: 0.7220\n",
      "Epoch 00607: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9436 - accuracy: 0.7220\n",
      "Epoch 608/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9337 - accuracy: 0.7279\n",
      "Epoch 00608: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9337 - accuracy: 0.7279\n",
      "Epoch 609/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9217 - accuracy: 0.7316\n",
      "Epoch 00609: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9217 - accuracy: 0.7316\n",
      "Epoch 610/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9361 - accuracy: 0.7251\n",
      "Epoch 00610: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9361 - accuracy: 0.7251\n",
      "Epoch 611/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9181 - accuracy: 0.7319\n",
      "Epoch 00611: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9181 - accuracy: 0.7319\n",
      "Epoch 612/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9098 - accuracy: 0.7346\n",
      "Epoch 00612: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9098 - accuracy: 0.7346\n",
      "Epoch 613/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8993 - accuracy: 0.7389\n",
      "Epoch 00613: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8993 - accuracy: 0.7389\n",
      "Epoch 614/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9121 - accuracy: 0.7351\n",
      "Epoch 00614: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9121 - accuracy: 0.7351\n",
      "Epoch 615/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9012 - accuracy: 0.7374\n",
      "Epoch 00615: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9012 - accuracy: 0.7374\n",
      "Epoch 616/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9029 - accuracy: 0.7371\n",
      "Epoch 00616: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9029 - accuracy: 0.7371\n",
      "Epoch 617/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8890 - accuracy: 0.7423\n",
      "Epoch 00617: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8890 - accuracy: 0.7423\n",
      "Epoch 618/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8748 - accuracy: 0.7470\n",
      "Epoch 00618: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8748 - accuracy: 0.7470\n",
      "Epoch 619/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8747 - accuracy: 0.7476\n",
      "Epoch 00619: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8747 - accuracy: 0.7476\n",
      "Epoch 620/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8740 - accuracy: 0.7484\n",
      "Epoch 00620: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8740 - accuracy: 0.7484\n",
      "Epoch 621/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8654 - accuracy: 0.7508\n",
      "Epoch 00621: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8654 - accuracy: 0.7508\n",
      "Epoch 622/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8609 - accuracy: 0.7515\n",
      "Epoch 00622: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8609 - accuracy: 0.7515\n",
      "Epoch 623/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8581 - accuracy: 0.7531\n",
      "Epoch 00623: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8581 - accuracy: 0.7531\n",
      "Epoch 624/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8562 - accuracy: 0.7536\n",
      "Epoch 00624: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8562 - accuracy: 0.7536\n",
      "Epoch 625/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8388 - accuracy: 0.7602\n",
      "Epoch 00625: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8388 - accuracy: 0.7602\n",
      "Epoch 626/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8323 - accuracy: 0.7626\n",
      "Epoch 00626: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8323 - accuracy: 0.7626\n",
      "Epoch 627/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8371 - accuracy: 0.7607\n",
      "Epoch 00627: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.8371 - accuracy: 0.7607\n",
      "Epoch 628/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8307 - accuracy: 0.7624\n",
      "Epoch 00628: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8307 - accuracy: 0.7624\n",
      "Epoch 629/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8363 - accuracy: 0.7611\n",
      "Epoch 00629: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8363 - accuracy: 0.7611\n",
      "Epoch 630/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.8209 - accuracy: 0.7666\n",
      "Epoch 00630: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8209 - accuracy: 0.7666\n",
      "Epoch 631/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8294 - accuracy: 0.7632\n",
      "Epoch 00631: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8294 - accuracy: 0.7632\n",
      "Epoch 632/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8195 - accuracy: 0.7667\n",
      "Epoch 00632: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8195 - accuracy: 0.7667\n",
      "Epoch 633/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8080 - accuracy: 0.7703\n",
      "Epoch 00633: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8080 - accuracy: 0.7703\n",
      "Epoch 634/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8062 - accuracy: 0.7722\n",
      "Epoch 00634: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8062 - accuracy: 0.7722\n",
      "Epoch 635/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7904 - accuracy: 0.7773\n",
      "Epoch 00635: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7904 - accuracy: 0.7773\n",
      "Epoch 636/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7920 - accuracy: 0.7769\n",
      "Epoch 00636: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7920 - accuracy: 0.7769\n",
      "Epoch 637/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7830 - accuracy: 0.7811\n",
      "Epoch 00637: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7830 - accuracy: 0.7811\n",
      "Epoch 638/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7743 - accuracy: 0.7837\n",
      "Epoch 00638: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7743 - accuracy: 0.7837\n",
      "Epoch 639/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7749 - accuracy: 0.7837\n",
      "Epoch 00639: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7749 - accuracy: 0.7837\n",
      "Epoch 640/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7727 - accuracy: 0.7830\n",
      "Epoch 00640: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7727 - accuracy: 0.7830\n",
      "Epoch 641/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7732 - accuracy: 0.7835\n",
      "Epoch 00641: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.7732 - accuracy: 0.7835\n",
      "Epoch 642/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7592 - accuracy: 0.7884\n",
      "Epoch 00642: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7592 - accuracy: 0.7884\n",
      "Epoch 643/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7573 - accuracy: 0.7885\n",
      "Epoch 00643: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.7573 - accuracy: 0.7885\n",
      "Epoch 644/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7421 - accuracy: 0.7947\n",
      "Epoch 00644: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7421 - accuracy: 0.7947\n",
      "Epoch 645/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7414 - accuracy: 0.7939\n",
      "Epoch 00645: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7414 - accuracy: 0.7939\n",
      "Epoch 646/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7312 - accuracy: 0.7981\n",
      "Epoch 00646: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7312 - accuracy: 0.7981\n",
      "Epoch 647/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7289 - accuracy: 0.7990\n",
      "Epoch 00647: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7289 - accuracy: 0.7990\n",
      "Epoch 648/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7353 - accuracy: 0.7966\n",
      "Epoch 00648: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7353 - accuracy: 0.7966\n",
      "Epoch 649/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7215 - accuracy: 0.8014\n",
      "Epoch 00649: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7215 - accuracy: 0.8014\n",
      "Epoch 650/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7160 - accuracy: 0.8034\n",
      "Epoch 00650: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7160 - accuracy: 0.8034\n",
      "Epoch 651/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7297 - accuracy: 0.7977\n",
      "Epoch 00651: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7297 - accuracy: 0.7977\n",
      "Epoch 652/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7102 - accuracy: 0.8071\n",
      "Epoch 00652: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7102 - accuracy: 0.8071\n",
      "Epoch 653/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.8098\n",
      "Epoch 00653: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6968 - accuracy: 0.8098\n",
      "Epoch 654/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.8131\n",
      "Epoch 00654: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6882 - accuracy: 0.8131\n",
      "Epoch 655/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6741 - accuracy: 0.8178\n",
      "Epoch 00655: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6741 - accuracy: 0.8178\n",
      "Epoch 656/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6959 - accuracy: 0.8096\n",
      "Epoch 00656: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6959 - accuracy: 0.8096\n",
      "Epoch 657/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6843 - accuracy: 0.8141\n",
      "Epoch 00657: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6843 - accuracy: 0.8141\n",
      "Epoch 658/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.8170\n",
      "Epoch 00658: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6803 - accuracy: 0.8170\n",
      "Epoch 659/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6754 - accuracy: 0.8176\n",
      "Epoch 00659: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6754 - accuracy: 0.8176\n",
      "Epoch 660/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6698 - accuracy: 0.8193\n",
      "Epoch 00660: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6698 - accuracy: 0.8193\n",
      "Epoch 661/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.8231\n",
      "Epoch 00661: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6624 - accuracy: 0.8231\n",
      "Epoch 662/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6458 - accuracy: 0.8276\n",
      "Epoch 00662: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6458 - accuracy: 0.8276\n",
      "Epoch 663/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6570 - accuracy: 0.8243\n",
      "Epoch 00663: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.6570 - accuracy: 0.8243\n",
      "Epoch 664/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6467 - accuracy: 0.8280\n",
      "Epoch 00664: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6467 - accuracy: 0.8280\n",
      "Epoch 665/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6397 - accuracy: 0.8307\n",
      "Epoch 00665: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6397 - accuracy: 0.8307\n",
      "Epoch 666/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6501 - accuracy: 0.8264\n",
      "Epoch 00666: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6501 - accuracy: 0.8264\n",
      "Epoch 667/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6257 - accuracy: 0.8363\n",
      "Epoch 00667: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.6257 - accuracy: 0.8363\n",
      "Epoch 668/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6202 - accuracy: 0.8373\n",
      "Epoch 00668: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6202 - accuracy: 0.8373\n",
      "Epoch 669/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6161 - accuracy: 0.8380\n",
      "Epoch 00669: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6161 - accuracy: 0.8380\n",
      "Epoch 670/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.8392\n",
      "Epoch 00670: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.6138 - accuracy: 0.8392\n",
      "Epoch 671/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5999 - accuracy: 0.8455\n",
      "Epoch 00671: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5999 - accuracy: 0.8455\n",
      "Epoch 672/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5983 - accuracy: 0.8451\n",
      "Epoch 00672: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5983 - accuracy: 0.8451\n",
      "Epoch 673/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5987 - accuracy: 0.8455\n",
      "Epoch 00673: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5987 - accuracy: 0.8455\n",
      "Epoch 674/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5950 - accuracy: 0.8477\n",
      "Epoch 00674: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5950 - accuracy: 0.8477\n",
      "Epoch 675/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5920 - accuracy: 0.8474\n",
      "Epoch 00675: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5920 - accuracy: 0.8474\n",
      "Epoch 676/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5838 - accuracy: 0.8514\n",
      "Epoch 00676: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5838 - accuracy: 0.8514\n",
      "Epoch 677/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5837 - accuracy: 0.8514\n",
      "Epoch 00677: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5837 - accuracy: 0.8514\n",
      "Epoch 678/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.8491\n",
      "Epoch 00678: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5916 - accuracy: 0.8491\n",
      "Epoch 679/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5760 - accuracy: 0.8538\n",
      "Epoch 00679: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5760 - accuracy: 0.8538\n",
      "Epoch 680/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.8542\n",
      "Epoch 00680: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5719 - accuracy: 0.8542\n",
      "Epoch 681/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.8593\n",
      "Epoch 00681: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5611 - accuracy: 0.8593\n",
      "Epoch 682/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5515 - accuracy: 0.8625\n",
      "Epoch 00682: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5515 - accuracy: 0.8625\n",
      "Epoch 683/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5488 - accuracy: 0.8636\n",
      "Epoch 00683: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5488 - accuracy: 0.8636\n",
      "Epoch 684/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.8656\n",
      "Epoch 00684: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5412 - accuracy: 0.8656\n",
      "Epoch 685/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5449 - accuracy: 0.8645\n",
      "Epoch 00685: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5449 - accuracy: 0.8645\n",
      "Epoch 686/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5388 - accuracy: 0.8667\n",
      "Epoch 00686: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5388 - accuracy: 0.8667\n",
      "Epoch 687/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.8728\n",
      "Epoch 00687: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5230 - accuracy: 0.8728\n",
      "Epoch 688/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.8720\n",
      "Epoch 00688: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5277 - accuracy: 0.8720\n",
      "Epoch 689/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.8734\n",
      "Epoch 00689: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5188 - accuracy: 0.8734\n",
      "Epoch 690/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5239 - accuracy: 0.8728\n",
      "Epoch 00690: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5239 - accuracy: 0.8728\n",
      "Epoch 691/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.8748\n",
      "Epoch 00691: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5171 - accuracy: 0.8748\n",
      "Epoch 692/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5005 - accuracy: 0.8808\n",
      "Epoch 00692: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5005 - accuracy: 0.8808\n",
      "Epoch 693/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.8800\n",
      "Epoch 00693: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5032 - accuracy: 0.8800\n",
      "Epoch 694/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.8800\n",
      "Epoch 00694: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5062 - accuracy: 0.8800\n",
      "Epoch 695/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5013 - accuracy: 0.8809\n",
      "Epoch 00695: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5013 - accuracy: 0.8809\n",
      "Epoch 696/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4924 - accuracy: 0.8838\n",
      "Epoch 00696: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4924 - accuracy: 0.8838\n",
      "Epoch 697/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4871 - accuracy: 0.8861\n",
      "Epoch 00697: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4871 - accuracy: 0.8861\n",
      "Epoch 698/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.8863\n",
      "Epoch 00698: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4867 - accuracy: 0.8863\n",
      "Epoch 699/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4767 - accuracy: 0.8897\n",
      "Epoch 00699: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4767 - accuracy: 0.8897\n",
      "Epoch 700/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.8899\n",
      "Epoch 00700: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4738 - accuracy: 0.8899\n",
      "Epoch 701/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.8934\n",
      "Epoch 00701: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4655 - accuracy: 0.8934\n",
      "Epoch 702/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.8933\n",
      "Epoch 00702: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4682 - accuracy: 0.8933\n",
      "Epoch 703/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4627 - accuracy: 0.8943\n",
      "Epoch 00703: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4627 - accuracy: 0.8943\n",
      "Epoch 704/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.8986\n",
      "Epoch 00704: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4501 - accuracy: 0.8986\n",
      "Epoch 705/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.8982\n",
      "Epoch 00705: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4496 - accuracy: 0.8982\n",
      "Epoch 706/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.8984\n",
      "Epoch 00706: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4516 - accuracy: 0.8984\n",
      "Epoch 707/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.9005\n",
      "Epoch 00707: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4453 - accuracy: 0.9005\n",
      "Epoch 708/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.9031\n",
      "Epoch 00708: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4344 - accuracy: 0.9031\n",
      "Epoch 709/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.9042\n",
      "Epoch 00709: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4369 - accuracy: 0.9042\n",
      "Epoch 710/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4310 - accuracy: 0.9054\n",
      "Epoch 00710: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4310 - accuracy: 0.9054\n",
      "Epoch 711/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4273 - accuracy: 0.9070\n",
      "Epoch 00711: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4273 - accuracy: 0.9070\n",
      "Epoch 712/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4155 - accuracy: 0.9110\n",
      "Epoch 00712: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4155 - accuracy: 0.9110\n",
      "Epoch 713/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4165 - accuracy: 0.9111\n",
      "Epoch 00713: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4165 - accuracy: 0.9111\n",
      "Epoch 714/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.9139\n",
      "Epoch 00714: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4059 - accuracy: 0.9139\n",
      "Epoch 715/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.9148\n",
      "Epoch 00715: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4041 - accuracy: 0.9148\n",
      "Epoch 716/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3983 - accuracy: 0.9170\n",
      "Epoch 00716: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3983 - accuracy: 0.9170\n",
      "Epoch 717/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.9191\n",
      "Epoch 00717: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3895 - accuracy: 0.9191\n",
      "Epoch 718/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3996 - accuracy: 0.9176\n",
      "Epoch 00718: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3996 - accuracy: 0.9176\n",
      "Epoch 719/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.9211\n",
      "Epoch 00719: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3841 - accuracy: 0.9211\n",
      "Epoch 720/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.9216\n",
      "Epoch 00720: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3832 - accuracy: 0.9216\n",
      "Epoch 721/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.9212\n",
      "Epoch 00721: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3868 - accuracy: 0.9212\n",
      "Epoch 722/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.9234\n",
      "Epoch 00722: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3779 - accuracy: 0.9234\n",
      "Epoch 723/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 0.9255\n",
      "Epoch 00723: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3718 - accuracy: 0.9255\n",
      "Epoch 724/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3722 - accuracy: 0.9250\n",
      "Epoch 00724: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3722 - accuracy: 0.9250\n",
      "Epoch 725/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.9293\n",
      "Epoch 00725: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3596 - accuracy: 0.9293\n",
      "Epoch 726/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.9297\n",
      "Epoch 00726: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3611 - accuracy: 0.9297\n",
      "Epoch 727/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.9291\n",
      "Epoch 00727: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3594 - accuracy: 0.9291\n",
      "Epoch 728/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.9296\n",
      "Epoch 00728: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3583 - accuracy: 0.9296\n",
      "Epoch 729/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.9312\n",
      "Epoch 00729: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3559 - accuracy: 0.9312\n",
      "Epoch 730/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.9316\n",
      "Epoch 00730: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3502 - accuracy: 0.9316\n",
      "Epoch 731/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3516 - accuracy: 0.9318\n",
      "Epoch 00731: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3516 - accuracy: 0.9318\n",
      "Epoch 732/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3393 - accuracy: 0.9370\n",
      "Epoch 00732: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3393 - accuracy: 0.9370\n",
      "Epoch 733/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3459 - accuracy: 0.9346\n",
      "Epoch 00733: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3459 - accuracy: 0.9346\n",
      "Epoch 734/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.9376\n",
      "Epoch 00734: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3352 - accuracy: 0.9376\n",
      "Epoch 735/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3307 - accuracy: 0.9386\n",
      "Epoch 00735: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3307 - accuracy: 0.9386\n",
      "Epoch 736/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.9399\n",
      "Epoch 00736: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3327 - accuracy: 0.9399\n",
      "Epoch 737/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.9406\n",
      "Epoch 00737: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3287 - accuracy: 0.9406\n",
      "Epoch 738/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.3268 - accuracy: 0.9409\n",
      "Epoch 00738: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3268 - accuracy: 0.9409\n",
      "Epoch 739/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.9427\n",
      "Epoch 00739: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3184 - accuracy: 0.9427\n",
      "Epoch 740/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3174 - accuracy: 0.9440\n",
      "Epoch 00740: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3174 - accuracy: 0.9440\n",
      "Epoch 741/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.9451\n",
      "Epoch 00741: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3142 - accuracy: 0.9451\n",
      "Epoch 742/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3121 - accuracy: 0.9456\n",
      "Epoch 00742: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3121 - accuracy: 0.9456\n",
      "Epoch 743/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.9475\n",
      "Epoch 00743: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3033 - accuracy: 0.9475\n",
      "Epoch 744/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.9489\n",
      "Epoch 00744: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3001 - accuracy: 0.9489\n",
      "Epoch 745/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2986 - accuracy: 0.9494\n",
      "Epoch 00745: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2986 - accuracy: 0.9494\n",
      "Epoch 746/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.9505\n",
      "Epoch 00746: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2961 - accuracy: 0.9505\n",
      "Epoch 747/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.9514\n",
      "Epoch 00747: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2928 - accuracy: 0.9514\n",
      "Epoch 748/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.9516\n",
      "Epoch 00748: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2926 - accuracy: 0.9516\n",
      "Epoch 749/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.9534\n",
      "Epoch 00749: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2867 - accuracy: 0.9534\n",
      "Epoch 750/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.9527\n",
      "Epoch 00750: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2918 - accuracy: 0.9527\n",
      "Epoch 751/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.9540\n",
      "Epoch 00751: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2816 - accuracy: 0.9540\n",
      "Epoch 752/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.9556\n",
      "Epoch 00752: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2816 - accuracy: 0.9556\n",
      "Epoch 753/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2776 - accuracy: 0.9556\n",
      "Epoch 00753: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2776 - accuracy: 0.9556\n",
      "Epoch 754/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.9564\n",
      "Epoch 00754: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2747 - accuracy: 0.9564\n",
      "Epoch 755/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.9563\n",
      "Epoch 00755: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2778 - accuracy: 0.9563\n",
      "Epoch 756/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2722 - accuracy: 0.9586\n",
      "Epoch 00756: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2722 - accuracy: 0.9586\n",
      "Epoch 757/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.9572\n",
      "Epoch 00757: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2720 - accuracy: 0.9572\n",
      "Epoch 758/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2668 - accuracy: 0.9590\n",
      "Epoch 00758: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2668 - accuracy: 0.9590\n",
      "Epoch 759/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.9612\n",
      "Epoch 00759: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2617 - accuracy: 0.9612\n",
      "Epoch 760/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2634 - accuracy: 0.9596\n",
      "Epoch 00760: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2634 - accuracy: 0.9596\n",
      "Epoch 761/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.9610\n",
      "Epoch 00761: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2563 - accuracy: 0.9610\n",
      "Epoch 762/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.9626\n",
      "Epoch 00762: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2513 - accuracy: 0.9626\n",
      "Epoch 763/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2554 - accuracy: 0.9626\n",
      "Epoch 00763: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2554 - accuracy: 0.9626\n",
      "Epoch 764/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2533 - accuracy: 0.9624\n",
      "Epoch 00764: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2533 - accuracy: 0.9624\n",
      "Epoch 765/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9630\n",
      "Epoch 00765: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2514 - accuracy: 0.9630\n",
      "Epoch 766/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.9632\n",
      "Epoch 00766: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2493 - accuracy: 0.9632\n",
      "Epoch 767/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.9640\n",
      "Epoch 00767: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2453 - accuracy: 0.9640\n",
      "Epoch 768/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2402 - accuracy: 0.9648\n",
      "Epoch 00768: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2402 - accuracy: 0.9648\n",
      "Epoch 769/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.9663\n",
      "Epoch 00769: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2380 - accuracy: 0.9663\n",
      "Epoch 770/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.9658\n",
      "Epoch 00770: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2394 - accuracy: 0.9658\n",
      "Epoch 771/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2372 - accuracy: 0.9664\n",
      "Epoch 00771: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2372 - accuracy: 0.9664\n",
      "Epoch 772/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.9674\n",
      "Epoch 00772: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2348 - accuracy: 0.9674\n",
      "Epoch 773/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9680\n",
      "Epoch 00773: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2318 - accuracy: 0.9680\n",
      "Epoch 774/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.9678\n",
      "Epoch 00774: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2297 - accuracy: 0.9678\n",
      "Epoch 775/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9688\n",
      "Epoch 00775: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2262 - accuracy: 0.9688\n",
      "Epoch 776/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9685\n",
      "Epoch 00776: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2261 - accuracy: 0.9685\n",
      "Epoch 777/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.9680\n",
      "Epoch 00777: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2275 - accuracy: 0.9680\n",
      "Epoch 778/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.9688\n",
      "Epoch 00778: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2264 - accuracy: 0.9688\n",
      "Epoch 779/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.9700\n",
      "Epoch 00779: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2186 - accuracy: 0.9700\n",
      "Epoch 780/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.9693\n",
      "Epoch 00780: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2243 - accuracy: 0.9693\n",
      "Epoch 781/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2170 - accuracy: 0.9703\n",
      "Epoch 00781: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2170 - accuracy: 0.9703\n",
      "Epoch 782/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9709\n",
      "Epoch 00782: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2147 - accuracy: 0.9709\n",
      "Epoch 783/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.9719\n",
      "Epoch 00783: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2112 - accuracy: 0.9719\n",
      "Epoch 784/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.9721\n",
      "Epoch 00784: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2107 - accuracy: 0.9721\n",
      "Epoch 785/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.9719\n",
      "Epoch 00785: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2102 - accuracy: 0.9719\n",
      "Epoch 786/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.9723\n",
      "Epoch 00786: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2096 - accuracy: 0.9723\n",
      "Epoch 787/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.9729\n",
      "Epoch 00787: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2057 - accuracy: 0.9729\n",
      "Epoch 788/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2039 - accuracy: 0.9729\n",
      "Epoch 00788: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2039 - accuracy: 0.9729\n",
      "Epoch 789/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2033 - accuracy: 0.9725\n",
      "Epoch 00789: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2033 - accuracy: 0.9725\n",
      "Epoch 790/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1988 - accuracy: 0.9737\n",
      "Epoch 00790: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1988 - accuracy: 0.9737\n",
      "Epoch 791/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9734\n",
      "Epoch 00791: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2015 - accuracy: 0.9734\n",
      "Epoch 792/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9739\n",
      "Epoch 00792: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1990 - accuracy: 0.9739\n",
      "Epoch 793/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.9739\n",
      "Epoch 00793: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1979 - accuracy: 0.9739\n",
      "Epoch 794/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.9746\n",
      "Epoch 00794: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1947 - accuracy: 0.9746\n",
      "Epoch 795/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1926 - accuracy: 0.9750\n",
      "Epoch 00795: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1926 - accuracy: 0.9750\n",
      "Epoch 796/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9742\n",
      "Epoch 00796: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1935 - accuracy: 0.9742\n",
      "Epoch 797/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1916 - accuracy: 0.9750\n",
      "Epoch 00797: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1916 - accuracy: 0.9750\n",
      "Epoch 798/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9752\n",
      "Epoch 00798: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1864 - accuracy: 0.9752\n",
      "Epoch 799/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.9756\n",
      "Epoch 00799: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1867 - accuracy: 0.9756\n",
      "Epoch 800/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1891 - accuracy: 0.9759\n",
      "Epoch 00800: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1891 - accuracy: 0.9759\n",
      "Epoch 801/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.9764\n",
      "Epoch 00801: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1857 - accuracy: 0.9764\n",
      "Epoch 802/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.9759\n",
      "Epoch 00802: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1826 - accuracy: 0.9759\n",
      "Epoch 803/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9754\n",
      "Epoch 00803: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1847 - accuracy: 0.9754\n",
      "Epoch 804/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.9759\n",
      "Epoch 00804: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1835 - accuracy: 0.9759\n",
      "Epoch 805/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.9767\n",
      "Epoch 00805: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1789 - accuracy: 0.9767\n",
      "Epoch 806/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.9764\n",
      "Epoch 00806: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1800 - accuracy: 0.9764\n",
      "Epoch 807/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9769\n",
      "Epoch 00807: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1778 - accuracy: 0.9769\n",
      "Epoch 808/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9771\n",
      "Epoch 00808: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1790 - accuracy: 0.9771\n",
      "Epoch 809/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.9768\n",
      "Epoch 00809: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1768 - accuracy: 0.9768\n",
      "Epoch 810/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.9774\n",
      "Epoch 00810: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1763 - accuracy: 0.9774\n",
      "Epoch 811/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.9778\n",
      "Epoch 00811: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1732 - accuracy: 0.9778\n",
      "Epoch 812/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.9769\n",
      "Epoch 00812: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1743 - accuracy: 0.9769\n",
      "Epoch 813/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9775\n",
      "Epoch 00813: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1720 - accuracy: 0.9775\n",
      "Epoch 814/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1716 - accuracy: 0.9777\n",
      "Epoch 00814: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1716 - accuracy: 0.9777\n",
      "Epoch 815/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.9783\n",
      "Epoch 00815: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1686 - accuracy: 0.9783\n",
      "Epoch 816/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.9774\n",
      "Epoch 00816: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1718 - accuracy: 0.9774\n",
      "Epoch 817/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.9782\n",
      "Epoch 00817: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1686 - accuracy: 0.9782\n",
      "Epoch 818/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.9784\n",
      "Epoch 00818: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1658 - accuracy: 0.9784\n",
      "Epoch 819/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9789\n",
      "Epoch 00819: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1644 - accuracy: 0.9789\n",
      "Epoch 820/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9792\n",
      "Epoch 00820: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1627 - accuracy: 0.9792\n",
      "Epoch 821/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1649 - accuracy: 0.9788\n",
      "Epoch 00821: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1649 - accuracy: 0.9788\n",
      "Epoch 822/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 0.9787\n",
      "Epoch 00822: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1631 - accuracy: 0.9787\n",
      "Epoch 823/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9784\n",
      "Epoch 00823: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1622 - accuracy: 0.9784\n",
      "Epoch 824/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.9793\n",
      "Epoch 00824: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1605 - accuracy: 0.9793\n",
      "Epoch 825/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.9794\n",
      "Epoch 00825: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1575 - accuracy: 0.9794\n",
      "Epoch 826/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9795\n",
      "Epoch 00826: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1565 - accuracy: 0.9795\n",
      "Epoch 827/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.9795\n",
      "Epoch 00827: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1555 - accuracy: 0.9795\n",
      "Epoch 828/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9802\n",
      "Epoch 00828: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1535 - accuracy: 0.9802\n",
      "Epoch 829/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9786\n",
      "Epoch 00829: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1565 - accuracy: 0.9786\n",
      "Epoch 830/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.9792\n",
      "Epoch 00830: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1548 - accuracy: 0.9792\n",
      "Epoch 831/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.9785\n",
      "Epoch 00831: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1559 - accuracy: 0.9785\n",
      "Epoch 832/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.9793\n",
      "Epoch 00832: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1548 - accuracy: 0.9793\n",
      "Epoch 833/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.9792\n",
      "Epoch 00833: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1536 - accuracy: 0.9792\n",
      "Epoch 834/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9799\n",
      "Epoch 00834: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1497 - accuracy: 0.9799\n",
      "Epoch 835/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1499 - accuracy: 0.9796\n",
      "Epoch 00835: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1499 - accuracy: 0.9796\n",
      "Epoch 836/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 0.9797\n",
      "Epoch 00836: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1487 - accuracy: 0.9797\n",
      "Epoch 837/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9797\n",
      "Epoch 00837: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1488 - accuracy: 0.9797\n",
      "Epoch 838/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9796\n",
      "Epoch 00838: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1497 - accuracy: 0.9796\n",
      "Epoch 839/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9805\n",
      "Epoch 00839: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1473 - accuracy: 0.9805\n",
      "Epoch 840/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9803\n",
      "Epoch 00840: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1469 - accuracy: 0.9803\n",
      "Epoch 841/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.9803\n",
      "Epoch 00841: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1471 - accuracy: 0.9803\n",
      "Epoch 842/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.9799\n",
      "Epoch 00842: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1482 - accuracy: 0.9799\n",
      "Epoch 843/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.9802\n",
      "Epoch 00843: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1466 - accuracy: 0.9802\n",
      "Epoch 844/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.9795\n",
      "Epoch 00844: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1458 - accuracy: 0.9795\n",
      "Epoch 845/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.9802\n",
      "Epoch 00845: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1435 - accuracy: 0.9802\n",
      "Epoch 846/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.1412 - accuracy: 0.9810\n",
      "Epoch 00846: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1412 - accuracy: 0.9810\n",
      "Epoch 847/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.9807\n",
      "Epoch 00847: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1401 - accuracy: 0.9807\n",
      "Epoch 848/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.9810\n",
      "Epoch 00848: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1401 - accuracy: 0.9810\n",
      "Epoch 849/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1408 - accuracy: 0.9804\n",
      "Epoch 00849: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1408 - accuracy: 0.9804\n",
      "Epoch 850/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9803\n",
      "Epoch 00850: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1414 - accuracy: 0.9803\n",
      "Epoch 851/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9808\n",
      "Epoch 00851: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1392 - accuracy: 0.9808\n",
      "Epoch 852/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.9804\n",
      "Epoch 00852: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1384 - accuracy: 0.9804\n",
      "Epoch 853/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9812\n",
      "Epoch 00853: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1381 - accuracy: 0.9812\n",
      "Epoch 854/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9812\n",
      "Epoch 00854: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1346 - accuracy: 0.9812\n",
      "Epoch 855/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9809\n",
      "Epoch 00855: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1385 - accuracy: 0.9809\n",
      "Epoch 856/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9813\n",
      "Epoch 00856: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1341 - accuracy: 0.9813\n",
      "Epoch 857/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.9809\n",
      "Epoch 00857: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1337 - accuracy: 0.9809\n",
      "Epoch 858/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.9810\n",
      "Epoch 00858: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1358 - accuracy: 0.9810\n",
      "Epoch 859/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.9811\n",
      "Epoch 00859: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1354 - accuracy: 0.9811\n",
      "Epoch 860/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9810\n",
      "Epoch 00860: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1342 - accuracy: 0.9810\n",
      "Epoch 861/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.9807\n",
      "Epoch 00861: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1337 - accuracy: 0.9807\n",
      "Epoch 862/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9818\n",
      "Epoch 00862: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1333 - accuracy: 0.9818\n",
      "Epoch 863/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9812\n",
      "Epoch 00863: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1325 - accuracy: 0.9812\n",
      "Epoch 864/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.9810\n",
      "Epoch 00864: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1337 - accuracy: 0.9810\n",
      "Epoch 865/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9809\n",
      "Epoch 00865: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1332 - accuracy: 0.9809\n",
      "Epoch 866/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9812\n",
      "Epoch 00866: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1311 - accuracy: 0.9812\n",
      "Epoch 867/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.9817\n",
      "Epoch 00867: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1276 - accuracy: 0.9817\n",
      "Epoch 868/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1313 - accuracy: 0.9815\n",
      "Epoch 00868: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1313 - accuracy: 0.9815\n",
      "Epoch 869/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9815\n",
      "Epoch 00869: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1288 - accuracy: 0.9815\n",
      "Epoch 870/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9810\n",
      "Epoch 00870: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1298 - accuracy: 0.9810\n",
      "Epoch 871/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 0.9821\n",
      "Epoch 00871: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1266 - accuracy: 0.9821\n",
      "Epoch 872/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9817\n",
      "Epoch 00872: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1264 - accuracy: 0.9817\n",
      "Epoch 873/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9820\n",
      "Epoch 00873: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1264 - accuracy: 0.9820\n",
      "Epoch 874/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.9822\n",
      "Epoch 00874: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1261 - accuracy: 0.9822\n",
      "Epoch 875/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 0.9821\n",
      "Epoch 00875: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1266 - accuracy: 0.9821\n",
      "Epoch 876/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9827\n",
      "Epoch 00876: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1241 - accuracy: 0.9827\n",
      "Epoch 877/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9819\n",
      "Epoch 00877: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1269 - accuracy: 0.9819\n",
      "Epoch 878/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9816\n",
      "Epoch 00878: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1269 - accuracy: 0.9816\n",
      "Epoch 879/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.9827\n",
      "Epoch 00879: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1228 - accuracy: 0.9827\n",
      "Epoch 880/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9817\n",
      "Epoch 00880: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1268 - accuracy: 0.9817\n",
      "Epoch 881/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9815\n",
      "Epoch 00881: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1234 - accuracy: 0.9815\n",
      "Epoch 882/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9830\n",
      "Epoch 00882: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1212 - accuracy: 0.9830\n",
      "Epoch 883/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9821\n",
      "Epoch 00883: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1238 - accuracy: 0.9821\n",
      "Epoch 884/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.9824\n",
      "Epoch 00884: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1222 - accuracy: 0.9824\n",
      "Epoch 885/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.9823\n",
      "Epoch 00885: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1228 - accuracy: 0.9823\n",
      "Epoch 886/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.9822\n",
      "Epoch 00886: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1215 - accuracy: 0.9822\n",
      "Epoch 887/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.9824\n",
      "Epoch 00887: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1206 - accuracy: 0.9824\n",
      "Epoch 888/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.9824\n",
      "Epoch 00888: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1206 - accuracy: 0.9824\n",
      "Epoch 889/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9825\n",
      "Epoch 00889: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1204 - accuracy: 0.9825\n",
      "Epoch 890/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9824\n",
      "Epoch 00890: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1212 - accuracy: 0.9824\n",
      "Epoch 891/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9826\n",
      "Epoch 00891: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1189 - accuracy: 0.9826\n",
      "Epoch 892/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9825\n",
      "Epoch 00892: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1209 - accuracy: 0.9825\n",
      "Epoch 893/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9827\n",
      "Epoch 00893: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1181 - accuracy: 0.9827\n",
      "Epoch 894/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9824\n",
      "Epoch 00894: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1160 - accuracy: 0.9824\n",
      "Epoch 895/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9827\n",
      "Epoch 00895: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1200 - accuracy: 0.9827\n",
      "Epoch 896/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9830\n",
      "Epoch 00896: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1156 - accuracy: 0.9830\n",
      "Epoch 897/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9827\n",
      "Epoch 00897: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1159 - accuracy: 0.9827\n",
      "Epoch 898/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.9829\n",
      "Epoch 00898: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1180 - accuracy: 0.9829\n",
      "Epoch 899/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1183 - accuracy: 0.9823\n",
      "Epoch 00899: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1183 - accuracy: 0.9823\n",
      "Epoch 900/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9830\n",
      "Epoch 00900: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1150 - accuracy: 0.9830\n",
      "Epoch 901/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9829\n",
      "Epoch 00901: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1155 - accuracy: 0.9829\n",
      "Epoch 902/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.9831\n",
      "Epoch 00902: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1141 - accuracy: 0.9831\n",
      "Epoch 903/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9827\n",
      "Epoch 00903: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1166 - accuracy: 0.9827\n",
      "Epoch 904/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.9828\n",
      "Epoch 00904: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1144 - accuracy: 0.9828\n",
      "Epoch 905/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9834\n",
      "Epoch 00905: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1119 - accuracy: 0.9834\n",
      "Epoch 906/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.9831\n",
      "Epoch 00906: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1130 - accuracy: 0.9831\n",
      "Epoch 907/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9833\n",
      "Epoch 00907: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1133 - accuracy: 0.9833\n",
      "Epoch 908/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.9831\n",
      "Epoch 00908: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1123 - accuracy: 0.9831\n",
      "Epoch 909/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9835\n",
      "Epoch 00909: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1131 - accuracy: 0.9835\n",
      "Epoch 910/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9830\n",
      "Epoch 00910: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1138 - accuracy: 0.9830\n",
      "Epoch 911/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9837\n",
      "Epoch 00911: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1119 - accuracy: 0.9837\n",
      "Epoch 912/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9835\n",
      "Epoch 00912: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1083 - accuracy: 0.9835\n",
      "Epoch 913/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9833\n",
      "Epoch 00913: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1097 - accuracy: 0.9833\n",
      "Epoch 914/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.9835\n",
      "Epoch 00914: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1091 - accuracy: 0.9835\n",
      "Epoch 915/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1082 - accuracy: 0.9835\n",
      "Epoch 00915: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1082 - accuracy: 0.9835\n",
      "Epoch 916/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9833\n",
      "Epoch 00916: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1117 - accuracy: 0.9833\n",
      "Epoch 917/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9833\n",
      "Epoch 00917: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.1118 - accuracy: 0.9833\n",
      "Epoch 918/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9835\n",
      "Epoch 00918: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1095 - accuracy: 0.9835\n",
      "Epoch 919/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9834\n",
      "Epoch 00919: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1103 - accuracy: 0.9834\n",
      "Epoch 920/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9833\n",
      "Epoch 00920: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1098 - accuracy: 0.9833\n",
      "Epoch 921/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9838\n",
      "Epoch 00921: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1081 - accuracy: 0.9838\n",
      "Epoch 922/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9839\n",
      "Epoch 00922: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1090 - accuracy: 0.9839\n",
      "Epoch 923/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9834\n",
      "Epoch 00923: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1079 - accuracy: 0.9834\n",
      "Epoch 924/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9841\n",
      "Epoch 00924: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1070 - accuracy: 0.9841\n",
      "Epoch 925/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9839\n",
      "Epoch 00925: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1076 - accuracy: 0.9839\n",
      "Epoch 926/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.9838\n",
      "Epoch 00926: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1056 - accuracy: 0.9838\n",
      "Epoch 927/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9835\n",
      "Epoch 00927: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1077 - accuracy: 0.9835\n",
      "Epoch 928/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9835\n",
      "Epoch 00928: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1068 - accuracy: 0.9835\n",
      "Epoch 929/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9831\n",
      "Epoch 00929: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1083 - accuracy: 0.9831\n",
      "Epoch 930/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9839\n",
      "Epoch 00930: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1072 - accuracy: 0.9839\n",
      "Epoch 931/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9837\n",
      "Epoch 00931: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1064 - accuracy: 0.9837\n",
      "Epoch 932/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9837\n",
      "Epoch 00932: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1058 - accuracy: 0.9837\n",
      "Epoch 933/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9839\n",
      "Epoch 00933: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1054 - accuracy: 0.9839\n",
      "Epoch 934/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.9840\n",
      "Epoch 00934: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1053 - accuracy: 0.9840\n",
      "Epoch 935/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9841\n",
      "Epoch 00935: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1068 - accuracy: 0.9841\n",
      "Epoch 936/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9838\n",
      "Epoch 00936: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1035 - accuracy: 0.9838\n",
      "Epoch 937/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.9838\n",
      "Epoch 00937: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1044 - accuracy: 0.9838\n",
      "Epoch 938/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 0.9838\n",
      "Epoch 00938: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1049 - accuracy: 0.9838\n",
      "Epoch 939/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9842\n",
      "Epoch 00939: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1035 - accuracy: 0.9842\n",
      "Epoch 940/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9842\n",
      "Epoch 00940: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1034 - accuracy: 0.9842\n",
      "Epoch 941/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9844\n",
      "Epoch 00941: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0993 - accuracy: 0.9844\n",
      "Epoch 942/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9843\n",
      "Epoch 00942: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1007 - accuracy: 0.9843\n",
      "Epoch 943/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9839\n",
      "Epoch 00943: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1037 - accuracy: 0.9839\n",
      "Epoch 944/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9848\n",
      "Epoch 00944: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1006 - accuracy: 0.9848\n",
      "Epoch 945/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9843\n",
      "Epoch 00945: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1020 - accuracy: 0.9843\n",
      "Epoch 946/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9845\n",
      "Epoch 00946: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1015 - accuracy: 0.9845\n",
      "Epoch 947/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9845\n",
      "Epoch 00947: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1006 - accuracy: 0.9845\n",
      "Epoch 948/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9844\n",
      "Epoch 00948: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1017 - accuracy: 0.9844\n",
      "Epoch 949/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.9846\n",
      "Epoch 00949: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0994 - accuracy: 0.9846\n",
      "Epoch 950/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.9847\n",
      "Epoch 00950: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0994 - accuracy: 0.9847\n",
      "Epoch 951/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9846\n",
      "Epoch 00951: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1011 - accuracy: 0.9846\n",
      "Epoch 952/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9845\n",
      "Epoch 00952: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1001 - accuracy: 0.9845\n",
      "Epoch 953/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9844\n",
      "Epoch 00953: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1016 - accuracy: 0.9844\n",
      "Epoch 954/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9849\n",
      "Epoch 00954: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0972 - accuracy: 0.9849\n",
      "Epoch 955/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9839\n",
      "Epoch 00955: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1020 - accuracy: 0.9839\n",
      "Epoch 956/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9850\n",
      "Epoch 00956: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0999 - accuracy: 0.9850\n",
      "Epoch 957/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9845\n",
      "Epoch 00957: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1002 - accuracy: 0.9845\n",
      "Epoch 958/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9847\n",
      "Epoch 00958: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0987 - accuracy: 0.9847\n",
      "Epoch 959/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9849\n",
      "Epoch 00959: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0974 - accuracy: 0.9849\n",
      "Epoch 960/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9843\n",
      "Epoch 00960: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0996 - accuracy: 0.9843\n",
      "Epoch 961/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9846\n",
      "Epoch 00961: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0993 - accuracy: 0.9846\n",
      "Epoch 962/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9845\n",
      "Epoch 00962: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0988 - accuracy: 0.9845\n",
      "Epoch 963/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9846\n",
      "Epoch 00963: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0963 - accuracy: 0.9846\n",
      "Epoch 964/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9851\n",
      "Epoch 00964: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0960 - accuracy: 0.9851\n",
      "Epoch 965/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9849\n",
      "Epoch 00965: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0981 - accuracy: 0.9849\n",
      "Epoch 966/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9850\n",
      "Epoch 00966: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0976 - accuracy: 0.9850\n",
      "Epoch 967/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9849\n",
      "Epoch 00967: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0966 - accuracy: 0.9849\n",
      "Epoch 968/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9846\n",
      "Epoch 00968: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0966 - accuracy: 0.9846\n",
      "Epoch 969/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9842\n",
      "Epoch 00969: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0975 - accuracy: 0.9842\n",
      "Epoch 970/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9846\n",
      "Epoch 00970: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0974 - accuracy: 0.9846\n",
      "Epoch 971/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9853\n",
      "Epoch 00971: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0960 - accuracy: 0.9853\n",
      "Epoch 972/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9852\n",
      "Epoch 00972: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0948 - accuracy: 0.9852\n",
      "Epoch 973/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9848\n",
      "Epoch 00973: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0960 - accuracy: 0.9848\n",
      "Epoch 974/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9853\n",
      "Epoch 00974: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0962 - accuracy: 0.9853\n",
      "Epoch 975/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9851\n",
      "Epoch 00975: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0962 - accuracy: 0.9851\n",
      "Epoch 976/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9849\n",
      "Epoch 00976: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0968 - accuracy: 0.9849\n",
      "Epoch 977/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9851\n",
      "Epoch 00977: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0950 - accuracy: 0.9851\n",
      "Epoch 978/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9849\n",
      "Epoch 00978: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0964 - accuracy: 0.9849\n",
      "Epoch 979/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9848\n",
      "Epoch 00979: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0950 - accuracy: 0.9848\n",
      "Epoch 980/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9855\n",
      "Epoch 00980: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0951 - accuracy: 0.9855\n",
      "Epoch 981/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9854\n",
      "Epoch 00981: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0963 - accuracy: 0.9854\n",
      "Epoch 982/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9851\n",
      "Epoch 00982: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0942 - accuracy: 0.9851\n",
      "Epoch 983/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9851\n",
      "Epoch 00983: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0965 - accuracy: 0.9851\n",
      "Epoch 984/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9853\n",
      "Epoch 00984: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0937 - accuracy: 0.9853\n",
      "Epoch 985/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9852\n",
      "Epoch 00985: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0946 - accuracy: 0.9852\n",
      "Epoch 986/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9856\n",
      "Epoch 00986: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0932 - accuracy: 0.9856\n",
      "Epoch 987/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9854\n",
      "Epoch 00987: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0918 - accuracy: 0.9854\n",
      "Epoch 988/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9856\n",
      "Epoch 00988: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0931 - accuracy: 0.9856\n",
      "Epoch 989/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9850\n",
      "Epoch 00989: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0941 - accuracy: 0.9850\n",
      "Epoch 990/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9851\n",
      "Epoch 00990: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0938 - accuracy: 0.9851\n",
      "Epoch 991/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9851\n",
      "Epoch 00991: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0940 - accuracy: 0.9851\n",
      "Epoch 992/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9860\n",
      "Epoch 00992: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0919 - accuracy: 0.9860\n",
      "Epoch 993/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9853\n",
      "Epoch 00993: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0933 - accuracy: 0.9853\n",
      "Epoch 994/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9854\n",
      "Epoch 00994: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0929 - accuracy: 0.9854\n",
      "Epoch 995/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9855\n",
      "Epoch 00995: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0913 - accuracy: 0.9855\n",
      "Epoch 996/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9855\n",
      "Epoch 00996: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0934 - accuracy: 0.9855\n",
      "Epoch 997/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9857\n",
      "Epoch 00997: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0894 - accuracy: 0.9857\n",
      "Epoch 998/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9852\n",
      "Epoch 00998: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0924 - accuracy: 0.9852\n",
      "Epoch 999/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9858\n",
      "Epoch 00999: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0878 - accuracy: 0.9858\n",
      "Epoch 1000/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9853\n",
      "Epoch 01000: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0922 - accuracy: 0.9853\n",
      "Epoch 1001/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.9858\n",
      "Epoch 01001: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0912 - accuracy: 0.9858\n",
      "Epoch 1002/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9853\n",
      "Epoch 01002: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0917 - accuracy: 0.9853\n",
      "Epoch 1003/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9852\n",
      "Epoch 01003: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0925 - accuracy: 0.9852\n",
      "Epoch 1004/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9857\n",
      "Epoch 01004: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0904 - accuracy: 0.9857\n",
      "Epoch 1005/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9858\n",
      "Epoch 01005: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0908 - accuracy: 0.9858\n",
      "Epoch 1006/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9859\n",
      "Epoch 01006: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0897 - accuracy: 0.9859\n",
      "Epoch 1007/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9855\n",
      "Epoch 01007: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0893 - accuracy: 0.9855\n",
      "Epoch 1008/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9855\n",
      "Epoch 01008: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0913 - accuracy: 0.9855\n",
      "Epoch 1009/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9854\n",
      "Epoch 01009: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0893 - accuracy: 0.9854\n",
      "Epoch 1010/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9852\n",
      "Epoch 01010: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0891 - accuracy: 0.9852\n",
      "Epoch 1011/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9853\n",
      "Epoch 01011: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0924 - accuracy: 0.9853\n",
      "Epoch 1012/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9854\n",
      "Epoch 01012: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0890 - accuracy: 0.9854\n",
      "Epoch 1013/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9853\n",
      "Epoch 01013: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0918 - accuracy: 0.9853\n",
      "Epoch 1014/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9858\n",
      "Epoch 01014: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0874 - accuracy: 0.9858\n",
      "Epoch 1015/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9855\n",
      "Epoch 01015: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0873 - accuracy: 0.9855\n",
      "Epoch 1016/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9864\n",
      "Epoch 01016: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0859 - accuracy: 0.9864\n",
      "Epoch 1017/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9855\n",
      "Epoch 01017: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0903 - accuracy: 0.9855\n",
      "Epoch 1018/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9857\n",
      "Epoch 01018: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0873 - accuracy: 0.9857\n",
      "Epoch 1019/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9859\n",
      "Epoch 01019: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0891 - accuracy: 0.9859\n",
      "Epoch 1020/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9858\n",
      "Epoch 01020: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0898 - accuracy: 0.9858\n",
      "Epoch 1021/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9857\n",
      "Epoch 01021: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0907 - accuracy: 0.9857\n",
      "Epoch 1022/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9858\n",
      "Epoch 01022: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0890 - accuracy: 0.9858\n",
      "Epoch 1023/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9862\n",
      "Epoch 01023: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0867 - accuracy: 0.9862\n",
      "Epoch 1024/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9856\n",
      "Epoch 01024: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0897 - accuracy: 0.9856\n",
      "Epoch 1025/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9858\n",
      "Epoch 01025: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0854 - accuracy: 0.9858\n",
      "Epoch 1026/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9861\n",
      "Epoch 01026: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0880 - accuracy: 0.9861\n",
      "Epoch 1027/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9859\n",
      "Epoch 01027: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0888 - accuracy: 0.9859\n",
      "Epoch 1028/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9856\n",
      "Epoch 01028: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0873 - accuracy: 0.9856\n",
      "Epoch 1029/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9858\n",
      "Epoch 01029: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0859 - accuracy: 0.9858\n",
      "Epoch 1030/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9858\n",
      "Epoch 01030: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0879 - accuracy: 0.9858\n",
      "Epoch 1031/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9864\n",
      "Epoch 01031: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0855 - accuracy: 0.9864\n",
      "Epoch 1032/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9862\n",
      "Epoch 01032: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0836 - accuracy: 0.9862\n",
      "Epoch 1033/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9863\n",
      "Epoch 01033: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0870 - accuracy: 0.9863\n",
      "Epoch 1034/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9857\n",
      "Epoch 01034: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0874 - accuracy: 0.9857\n",
      "Epoch 1035/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9864\n",
      "Epoch 01035: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0863 - accuracy: 0.9864\n",
      "Epoch 1036/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9858\n",
      "Epoch 01036: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0881 - accuracy: 0.9858\n",
      "Epoch 1037/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9859\n",
      "Epoch 01037: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0857 - accuracy: 0.9859\n",
      "Epoch 1038/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9862\n",
      "Epoch 01038: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0848 - accuracy: 0.9862\n",
      "Epoch 1039/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9864\n",
      "Epoch 01039: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0835 - accuracy: 0.9864\n",
      "Epoch 1040/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9862\n",
      "Epoch 01040: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0853 - accuracy: 0.9862\n",
      "Epoch 1041/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9862\n",
      "Epoch 01041: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0828 - accuracy: 0.9862\n",
      "Epoch 1042/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9866\n",
      "Epoch 01042: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0830 - accuracy: 0.9866\n",
      "Epoch 1043/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9861\n",
      "Epoch 01043: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0868 - accuracy: 0.9861\n",
      "Epoch 1044/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9863\n",
      "Epoch 01044: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0828 - accuracy: 0.9863\n",
      "Epoch 1045/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9865\n",
      "Epoch 01045: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0846 - accuracy: 0.9865\n",
      "Epoch 1046/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9865\n",
      "Epoch 01046: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0838 - accuracy: 0.9865\n",
      "Epoch 1047/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9864\n",
      "Epoch 01047: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0843 - accuracy: 0.9864\n",
      "Epoch 1048/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9862\n",
      "Epoch 01048: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0847 - accuracy: 0.9862\n",
      "Epoch 1049/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9867\n",
      "Epoch 01049: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0833 - accuracy: 0.9867\n",
      "Epoch 1050/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9865\n",
      "Epoch 01050: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0833 - accuracy: 0.9865\n",
      "Epoch 1051/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9868\n",
      "Epoch 01051: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0823 - accuracy: 0.9868\n",
      "Epoch 1052/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9868\n",
      "Epoch 01052: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0835 - accuracy: 0.9868\n",
      "Epoch 1053/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9863\n",
      "Epoch 01053: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0844 - accuracy: 0.9863\n",
      "Epoch 1054/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9862\n",
      "Epoch 01054: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0847 - accuracy: 0.9862\n",
      "Epoch 1055/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9865\n",
      "Epoch 01055: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0827 - accuracy: 0.9865\n",
      "Epoch 1056/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9865\n",
      "Epoch 01056: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0836 - accuracy: 0.9865\n",
      "Epoch 1057/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9868\n",
      "Epoch 01057: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0833 - accuracy: 0.9868\n",
      "Epoch 1058/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9868\n",
      "Epoch 01058: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0814 - accuracy: 0.9868\n",
      "Epoch 1059/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9872\n",
      "Epoch 01059: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0820 - accuracy: 0.9872\n",
      "Epoch 1060/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9864\n",
      "Epoch 01060: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0812 - accuracy: 0.9864\n",
      "Epoch 1061/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9868\n",
      "Epoch 01061: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0833 - accuracy: 0.9868\n",
      "Epoch 1062/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9869\n",
      "Epoch 01062: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0827 - accuracy: 0.9869\n",
      "Epoch 1063/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9865\n",
      "Epoch 01063: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0823 - accuracy: 0.9865\n",
      "Epoch 1064/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9872\n",
      "Epoch 01064: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0803 - accuracy: 0.9872\n",
      "Epoch 1065/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9867\n",
      "Epoch 01065: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0828 - accuracy: 0.9867\n",
      "Epoch 1066/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9872\n",
      "Epoch 01066: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0787 - accuracy: 0.9872\n",
      "Epoch 1067/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9867\n",
      "Epoch 01067: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0818 - accuracy: 0.9867\n",
      "Epoch 1068/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9870\n",
      "Epoch 01068: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0815 - accuracy: 0.9870\n",
      "Epoch 1069/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9863\n",
      "Epoch 01069: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0828 - accuracy: 0.9863\n",
      "Epoch 1070/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9869\n",
      "Epoch 01070: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0825 - accuracy: 0.9869\n",
      "Epoch 1071/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9867\n",
      "Epoch 01071: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0795 - accuracy: 0.9867\n",
      "Epoch 1072/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9867\n",
      "Epoch 01072: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0801 - accuracy: 0.9867\n",
      "Epoch 1073/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9869\n",
      "Epoch 01073: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0815 - accuracy: 0.9869\n",
      "Epoch 1074/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9869\n",
      "Epoch 01074: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0811 - accuracy: 0.9869\n",
      "Epoch 1075/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9870\n",
      "Epoch 01075: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0786 - accuracy: 0.9870\n",
      "Epoch 1076/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9869\n",
      "Epoch 01076: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0791 - accuracy: 0.9869\n",
      "Epoch 1077/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9867\n",
      "Epoch 01077: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0810 - accuracy: 0.9867\n",
      "Epoch 1078/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9869\n",
      "Epoch 01078: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0837 - accuracy: 0.9869\n",
      "Epoch 1079/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9870\n",
      "Epoch 01079: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0815 - accuracy: 0.9870\n",
      "Epoch 1080/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9867\n",
      "Epoch 01080: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0806 - accuracy: 0.9867\n",
      "Epoch 1081/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9865\n",
      "Epoch 01081: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0812 - accuracy: 0.9865\n",
      "Epoch 1082/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9870\n",
      "Epoch 01082: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0787 - accuracy: 0.9870\n",
      "Epoch 1083/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9868\n",
      "Epoch 01083: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0817 - accuracy: 0.9868\n",
      "Epoch 1084/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9868\n",
      "Epoch 01084: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0795 - accuracy: 0.9868\n",
      "Epoch 1085/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9869\n",
      "Epoch 01085: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0797 - accuracy: 0.9869\n",
      "Epoch 1086/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9869\n",
      "Epoch 01086: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0777 - accuracy: 0.9869\n",
      "Epoch 1087/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9871\n",
      "Epoch 01087: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0784 - accuracy: 0.9871\n",
      "Epoch 1088/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9870\n",
      "Epoch 01088: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0782 - accuracy: 0.9870\n",
      "Epoch 1089/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9874\n",
      "Epoch 01089: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0793 - accuracy: 0.9874\n",
      "Epoch 1090/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9870\n",
      "Epoch 01090: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0789 - accuracy: 0.9870\n",
      "Epoch 1091/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9868\n",
      "Epoch 01091: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0764 - accuracy: 0.9868\n",
      "Epoch 1092/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9868\n",
      "Epoch 01092: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0806 - accuracy: 0.9868\n",
      "Epoch 1093/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9871\n",
      "Epoch 01093: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0798 - accuracy: 0.9871\n",
      "Epoch 1094/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9871\n",
      "Epoch 01094: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0778 - accuracy: 0.9871\n",
      "Epoch 1095/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9871\n",
      "Epoch 01095: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0766 - accuracy: 0.9871\n",
      "Epoch 1096/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9874\n",
      "Epoch 01096: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0779 - accuracy: 0.9874\n",
      "Epoch 1097/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9873\n",
      "Epoch 01097: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0765 - accuracy: 0.9873\n",
      "Epoch 1098/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9869\n",
      "Epoch 01098: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0786 - accuracy: 0.9869\n",
      "Epoch 1099/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9873\n",
      "Epoch 01099: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0769 - accuracy: 0.9873\n",
      "Epoch 1100/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9868\n",
      "Epoch 01100: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0786 - accuracy: 0.9868\n",
      "Epoch 1101/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9871\n",
      "Epoch 01101: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0791 - accuracy: 0.9871\n",
      "Epoch 1102/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9870\n",
      "Epoch 01102: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0770 - accuracy: 0.9870\n",
      "Epoch 1103/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9870\n",
      "Epoch 01103: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0774 - accuracy: 0.9870\n",
      "Epoch 1104/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9871\n",
      "Epoch 01104: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0784 - accuracy: 0.9871\n",
      "Epoch 1105/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9874\n",
      "Epoch 01105: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0755 - accuracy: 0.9874\n",
      "Epoch 1106/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9871\n",
      "Epoch 01106: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0773 - accuracy: 0.9871\n",
      "Epoch 1107/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9871\n",
      "Epoch 01107: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0753 - accuracy: 0.9871\n",
      "Epoch 1108/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9873\n",
      "Epoch 01108: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0768 - accuracy: 0.9873\n",
      "Epoch 1109/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9872\n",
      "Epoch 01109: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0754 - accuracy: 0.9872\n",
      "Epoch 1110/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9869\n",
      "Epoch 01110: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0774 - accuracy: 0.9869\n",
      "Epoch 1111/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9874\n",
      "Epoch 01111: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0757 - accuracy: 0.9874\n",
      "Epoch 1112/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9876\n",
      "Epoch 01112: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0774 - accuracy: 0.9876\n",
      "Epoch 1113/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9870\n",
      "Epoch 01113: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0766 - accuracy: 0.9870\n",
      "Epoch 1114/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9877\n",
      "Epoch 01114: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0776 - accuracy: 0.9877\n",
      "Epoch 1115/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9874\n",
      "Epoch 01115: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0743 - accuracy: 0.9874\n",
      "Epoch 1116/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9873\n",
      "Epoch 01116: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0775 - accuracy: 0.9873\n",
      "Epoch 1117/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9875\n",
      "Epoch 01117: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0776 - accuracy: 0.9875\n",
      "Epoch 1118/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9874\n",
      "Epoch 01118: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0753 - accuracy: 0.9874\n",
      "Epoch 1119/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9870\n",
      "Epoch 01119: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0772 - accuracy: 0.9870\n",
      "Epoch 1120/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9874\n",
      "Epoch 01120: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0758 - accuracy: 0.9874\n",
      "Epoch 1121/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9870\n",
      "Epoch 01121: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0778 - accuracy: 0.9870\n",
      "Epoch 1122/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9875\n",
      "Epoch 01122: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0758 - accuracy: 0.9875\n",
      "Epoch 1123/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9875\n",
      "Epoch 01123: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0750 - accuracy: 0.9875\n",
      "Epoch 1124/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9877\n",
      "Epoch 01124: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0742 - accuracy: 0.9877\n",
      "Epoch 1125/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9876\n",
      "Epoch 01125: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0734 - accuracy: 0.9876\n",
      "Epoch 1126/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9876\n",
      "Epoch 01126: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0750 - accuracy: 0.9876\n",
      "Epoch 1127/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9873\n",
      "Epoch 01127: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0753 - accuracy: 0.9873\n",
      "Epoch 1128/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9877\n",
      "Epoch 01128: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0757 - accuracy: 0.9877\n",
      "Epoch 1129/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9873\n",
      "Epoch 01129: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0750 - accuracy: 0.9873\n",
      "Epoch 1130/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9876\n",
      "Epoch 01130: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0733 - accuracy: 0.9876\n",
      "Epoch 1131/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9873\n",
      "Epoch 01131: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0757 - accuracy: 0.9873\n",
      "Epoch 1132/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9877\n",
      "Epoch 01132: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0743 - accuracy: 0.9877\n",
      "Epoch 1133/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9876\n",
      "Epoch 01133: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0739 - accuracy: 0.9876\n",
      "Epoch 1134/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9875\n",
      "Epoch 01134: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0764 - accuracy: 0.9875\n",
      "Epoch 1135/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9878\n",
      "Epoch 01135: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0750 - accuracy: 0.9878\n",
      "Epoch 1136/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9877\n",
      "Epoch 01136: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0727 - accuracy: 0.9877\n",
      "Epoch 1137/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9876\n",
      "Epoch 01137: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0742 - accuracy: 0.9876\n",
      "Epoch 1138/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9879\n",
      "Epoch 01138: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0741 - accuracy: 0.9879\n",
      "Epoch 1139/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9876\n",
      "Epoch 01139: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0748 - accuracy: 0.9876\n",
      "Epoch 1140/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9876\n",
      "Epoch 01140: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0736 - accuracy: 0.9876\n",
      "Epoch 1141/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9878\n",
      "Epoch 01141: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0748 - accuracy: 0.9878\n",
      "Epoch 1142/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9876\n",
      "Epoch 01142: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0746 - accuracy: 0.9876\n",
      "Epoch 1143/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9878\n",
      "Epoch 01143: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0728 - accuracy: 0.9878\n",
      "Epoch 1144/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9873\n",
      "Epoch 01144: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0766 - accuracy: 0.9873\n",
      "Epoch 1145/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9875\n",
      "Epoch 01145: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0739 - accuracy: 0.9875\n",
      "Epoch 1146/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9879\n",
      "Epoch 01146: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0733 - accuracy: 0.9879\n",
      "Epoch 1147/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9878\n",
      "Epoch 01147: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0731 - accuracy: 0.9878\n",
      "Epoch 1148/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9878\n",
      "Epoch 01148: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0735 - accuracy: 0.9878\n",
      "Epoch 1149/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9878\n",
      "Epoch 01149: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0714 - accuracy: 0.9878\n",
      "Epoch 1150/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9876\n",
      "Epoch 01150: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0718 - accuracy: 0.9876\n",
      "Epoch 1151/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9882\n",
      "Epoch 01151: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0717 - accuracy: 0.9882\n",
      "Epoch 1152/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9878\n",
      "Epoch 01152: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0738 - accuracy: 0.9878\n",
      "Epoch 1153/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9876\n",
      "Epoch 01153: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0724 - accuracy: 0.9876\n",
      "Epoch 1154/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9878\n",
      "Epoch 01154: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0728 - accuracy: 0.9878\n",
      "Epoch 1155/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9876\n",
      "Epoch 01155: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0749 - accuracy: 0.9876\n",
      "Epoch 1156/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9881\n",
      "Epoch 01156: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0743 - accuracy: 0.9881\n",
      "Epoch 1157/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9874\n",
      "Epoch 01157: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0748 - accuracy: 0.9874\n",
      "Epoch 1158/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9884\n",
      "Epoch 01158: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0702 - accuracy: 0.9884\n",
      "Epoch 1159/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9882\n",
      "Epoch 01159: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0689 - accuracy: 0.9882\n",
      "Epoch 1160/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9879\n",
      "Epoch 01160: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0733 - accuracy: 0.9879\n",
      "Epoch 1161/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9877\n",
      "Epoch 01161: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0705 - accuracy: 0.9877\n",
      "Epoch 1162/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9876\n",
      "Epoch 01162: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0713 - accuracy: 0.9876\n",
      "Epoch 1163/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9883\n",
      "Epoch 01163: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0702 - accuracy: 0.9883\n",
      "Epoch 1164/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9882\n",
      "Epoch 01164: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0704 - accuracy: 0.9882\n",
      "Epoch 1165/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9879\n",
      "Epoch 01165: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0707 - accuracy: 0.9879\n",
      "Epoch 1166/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9879\n",
      "Epoch 01166: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0697 - accuracy: 0.9879\n",
      "Epoch 1167/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9879\n",
      "Epoch 01167: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0711 - accuracy: 0.9879\n",
      "Epoch 1168/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9884\n",
      "Epoch 01168: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0708 - accuracy: 0.9884\n",
      "Epoch 1169/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9885\n",
      "Epoch 01169: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0700 - accuracy: 0.9885\n",
      "Epoch 1170/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9877\n",
      "Epoch 01170: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0720 - accuracy: 0.9877\n",
      "Epoch 1171/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9881\n",
      "Epoch 01171: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0697 - accuracy: 0.9881\n",
      "Epoch 1172/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9878\n",
      "Epoch 01172: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0738 - accuracy: 0.9878\n",
      "Epoch 1173/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9886\n",
      "Epoch 01173: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0683 - accuracy: 0.9886\n",
      "Epoch 1174/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9882\n",
      "Epoch 01174: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0701 - accuracy: 0.9882\n",
      "Epoch 1175/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9884\n",
      "Epoch 01175: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0687 - accuracy: 0.9884\n",
      "Epoch 1176/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9882\n",
      "Epoch 01176: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0718 - accuracy: 0.9882\n",
      "Epoch 1177/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9883\n",
      "Epoch 01177: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0695 - accuracy: 0.9883\n",
      "Epoch 1178/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9881\n",
      "Epoch 01178: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0698 - accuracy: 0.9881\n",
      "Epoch 1179/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9880\n",
      "Epoch 01179: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0719 - accuracy: 0.9880\n",
      "Epoch 1180/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9881\n",
      "Epoch 01180: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0719 - accuracy: 0.9881\n",
      "Epoch 1181/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9882\n",
      "Epoch 01181: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0697 - accuracy: 0.9882\n",
      "Epoch 1182/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9880\n",
      "Epoch 01182: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0687 - accuracy: 0.9880\n",
      "Epoch 1183/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9884\n",
      "Epoch 01183: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0699 - accuracy: 0.9884\n",
      "Epoch 1184/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9885\n",
      "Epoch 01184: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0688 - accuracy: 0.9885\n",
      "Epoch 1185/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9877\n",
      "Epoch 01185: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0707 - accuracy: 0.9877\n",
      "Epoch 1186/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9878\n",
      "Epoch 01186: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0705 - accuracy: 0.9878\n",
      "Epoch 1187/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9883\n",
      "Epoch 01187: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0692 - accuracy: 0.9883\n",
      "Epoch 1188/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9879\n",
      "Epoch 01188: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0711 - accuracy: 0.9879\n",
      "Epoch 1189/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9882\n",
      "Epoch 01189: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0704 - accuracy: 0.9882\n",
      "Epoch 1190/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9885\n",
      "Epoch 01190: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0678 - accuracy: 0.9885\n",
      "Epoch 1191/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9883\n",
      "Epoch 01191: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0694 - accuracy: 0.9883\n",
      "Epoch 1192/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9882\n",
      "Epoch 01192: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0698 - accuracy: 0.9882\n",
      "Epoch 1193/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9880\n",
      "Epoch 01193: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0701 - accuracy: 0.9880\n",
      "Epoch 1194/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9885\n",
      "Epoch 01194: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0684 - accuracy: 0.9885\n",
      "Epoch 1195/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9879\n",
      "Epoch 01195: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0700 - accuracy: 0.9879\n",
      "Epoch 1196/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9883\n",
      "Epoch 01196: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0697 - accuracy: 0.9883\n",
      "Epoch 1197/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9883\n",
      "Epoch 01197: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0682 - accuracy: 0.9883\n",
      "Epoch 1198/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9882\n",
      "Epoch 01198: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0691 - accuracy: 0.9882\n",
      "Epoch 1199/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9883\n",
      "Epoch 01199: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0672 - accuracy: 0.9883\n",
      "Epoch 1200/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9885\n",
      "Epoch 01200: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0675 - accuracy: 0.9885\n",
      "Epoch 1201/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9879\n",
      "Epoch 01201: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0676 - accuracy: 0.9879\n",
      "Epoch 1202/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9878\n",
      "Epoch 01202: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0711 - accuracy: 0.9878\n",
      "Epoch 1203/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9882\n",
      "Epoch 01203: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0708 - accuracy: 0.9882\n",
      "Epoch 1204/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9881\n",
      "Epoch 01204: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0681 - accuracy: 0.9881\n",
      "Epoch 1205/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9889\n",
      "Epoch 01205: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0678 - accuracy: 0.9889\n",
      "Epoch 1206/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9882\n",
      "Epoch 01206: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0700 - accuracy: 0.9882\n",
      "Epoch 1207/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9884\n",
      "Epoch 01207: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0685 - accuracy: 0.9884\n",
      "Epoch 1208/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9886\n",
      "Epoch 01208: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0676 - accuracy: 0.9886\n",
      "Epoch 1209/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9886\n",
      "Epoch 01209: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0686 - accuracy: 0.9886\n",
      "Epoch 1210/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9886\n",
      "Epoch 01210: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0693 - accuracy: 0.9886\n",
      "Epoch 1211/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9885\n",
      "Epoch 01211: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0680 - accuracy: 0.9885\n",
      "Epoch 1212/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9881\n",
      "Epoch 01212: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0690 - accuracy: 0.9881\n",
      "Epoch 1213/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9889\n",
      "Epoch 01213: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0657 - accuracy: 0.9889\n",
      "Epoch 1214/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9884\n",
      "Epoch 01214: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0664 - accuracy: 0.9884\n",
      "Epoch 1215/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9888\n",
      "Epoch 01215: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0654 - accuracy: 0.9888\n",
      "Epoch 1216/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9885\n",
      "Epoch 01216: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0683 - accuracy: 0.9885\n",
      "Epoch 1217/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9890\n",
      "Epoch 01217: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0659 - accuracy: 0.9890\n",
      "Epoch 1218/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9881\n",
      "Epoch 01218: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0697 - accuracy: 0.9881\n",
      "Epoch 1219/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9887\n",
      "Epoch 01219: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0660 - accuracy: 0.9887\n",
      "Epoch 1220/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9884\n",
      "Epoch 01220: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0674 - accuracy: 0.9884\n",
      "Epoch 1221/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9888\n",
      "Epoch 01221: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0677 - accuracy: 0.9888\n",
      "Epoch 1222/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9888\n",
      "Epoch 01222: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0674 - accuracy: 0.9888\n",
      "Epoch 1223/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9887\n",
      "Epoch 01223: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0662 - accuracy: 0.9887\n",
      "Epoch 1224/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9891\n",
      "Epoch 01224: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0654 - accuracy: 0.9891\n",
      "Epoch 1225/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9887\n",
      "Epoch 01225: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0639 - accuracy: 0.9887\n",
      "Epoch 1226/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9889\n",
      "Epoch 01226: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0674 - accuracy: 0.9889\n",
      "Epoch 1227/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9890\n",
      "Epoch 01227: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0659 - accuracy: 0.9890\n",
      "Epoch 1228/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9886\n",
      "Epoch 01228: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0660 - accuracy: 0.9886\n",
      "Epoch 1229/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9886\n",
      "Epoch 01229: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0658 - accuracy: 0.9886\n",
      "Epoch 1230/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9890\n",
      "Epoch 01230: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0650 - accuracy: 0.9890\n",
      "Epoch 1231/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9887\n",
      "Epoch 01231: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0661 - accuracy: 0.9887\n",
      "Epoch 1232/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9885\n",
      "Epoch 01232: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0668 - accuracy: 0.9885\n",
      "Epoch 1233/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9889\n",
      "Epoch 01233: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0653 - accuracy: 0.9889\n",
      "Epoch 1234/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9886\n",
      "Epoch 01234: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0669 - accuracy: 0.9886\n",
      "Epoch 1235/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9887\n",
      "Epoch 01235: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0655 - accuracy: 0.9887\n",
      "Epoch 1236/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9889\n",
      "Epoch 01236: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0644 - accuracy: 0.9889\n",
      "Epoch 1237/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9889\n",
      "Epoch 01237: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0656 - accuracy: 0.9889\n",
      "Epoch 1238/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9890\n",
      "Epoch 01238: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0643 - accuracy: 0.9890\n",
      "Epoch 1239/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9890\n",
      "Epoch 01239: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0659 - accuracy: 0.9890\n",
      "Epoch 1240/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9887\n",
      "Epoch 01240: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0644 - accuracy: 0.9887\n",
      "Epoch 1241/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9895\n",
      "Epoch 01241: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0626 - accuracy: 0.9895\n",
      "Epoch 1242/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9886\n",
      "Epoch 01242: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0650 - accuracy: 0.9886\n",
      "Epoch 1243/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9887\n",
      "Epoch 01243: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0650 - accuracy: 0.9887\n",
      "Epoch 1244/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9893\n",
      "Epoch 01244: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0637 - accuracy: 0.9893\n",
      "Epoch 1245/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9885\n",
      "Epoch 01245: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0666 - accuracy: 0.9885\n",
      "Epoch 1246/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9888\n",
      "Epoch 01246: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0655 - accuracy: 0.9888\n",
      "Epoch 1247/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9888\n",
      "Epoch 01247: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0650 - accuracy: 0.9888\n",
      "Epoch 1248/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9887\n",
      "Epoch 01248: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0642 - accuracy: 0.9887\n",
      "Epoch 1249/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9886\n",
      "Epoch 01249: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0659 - accuracy: 0.9886\n",
      "Epoch 1250/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9891\n",
      "Epoch 01250: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0648 - accuracy: 0.9891\n",
      "Epoch 1251/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9892\n",
      "Epoch 01251: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0635 - accuracy: 0.9892\n",
      "Epoch 1252/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9890\n",
      "Epoch 01252: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0642 - accuracy: 0.9890\n",
      "Epoch 1253/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9888\n",
      "Epoch 01253: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0645 - accuracy: 0.9888\n",
      "Epoch 1254/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9887\n",
      "Epoch 01254: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0658 - accuracy: 0.9887\n",
      "Epoch 1255/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9893\n",
      "Epoch 01255: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0628 - accuracy: 0.9893\n",
      "Epoch 1256/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9889\n",
      "Epoch 01256: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0661 - accuracy: 0.9889\n",
      "Epoch 1257/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9888\n",
      "Epoch 01257: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0647 - accuracy: 0.9888\n",
      "Epoch 1258/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9887\n",
      "Epoch 01258: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0646 - accuracy: 0.9887\n",
      "Epoch 1259/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9887\n",
      "Epoch 01259: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0645 - accuracy: 0.9887\n",
      "Epoch 1260/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9895\n",
      "Epoch 01260: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0628 - accuracy: 0.9895\n",
      "Epoch 1261/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9890\n",
      "Epoch 01261: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0635 - accuracy: 0.9890\n",
      "Epoch 1262/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9891\n",
      "Epoch 01262: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0651 - accuracy: 0.9891\n",
      "Epoch 1263/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9888\n",
      "Epoch 01263: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0639 - accuracy: 0.9888\n",
      "Epoch 1264/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9888\n",
      "Epoch 01264: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0651 - accuracy: 0.9888\n",
      "Epoch 1265/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9893\n",
      "Epoch 01265: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0632 - accuracy: 0.9893\n",
      "Epoch 1266/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9893\n",
      "Epoch 01266: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0628 - accuracy: 0.9893\n",
      "Epoch 1267/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9890\n",
      "Epoch 01267: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0635 - accuracy: 0.9890\n",
      "Epoch 1268/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9886\n",
      "Epoch 01268: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0652 - accuracy: 0.9886\n",
      "Epoch 1269/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9891\n",
      "Epoch 01269: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0637 - accuracy: 0.9891\n",
      "Epoch 1270/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9889\n",
      "Epoch 01270: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0645 - accuracy: 0.9889\n",
      "Epoch 1271/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9890\n",
      "Epoch 01271: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0628 - accuracy: 0.9890\n",
      "Epoch 1272/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9892\n",
      "Epoch 01272: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0631 - accuracy: 0.9892\n",
      "Epoch 1273/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9892\n",
      "Epoch 01273: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0628 - accuracy: 0.9892\n",
      "Epoch 1274/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9893\n",
      "Epoch 01274: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0631 - accuracy: 0.9893\n",
      "Epoch 1275/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9892\n",
      "Epoch 01275: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0644 - accuracy: 0.9892\n",
      "Epoch 1276/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9892\n",
      "Epoch 01276: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0630 - accuracy: 0.9892\n",
      "Epoch 1277/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9890\n",
      "Epoch 01277: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0630 - accuracy: 0.9890\n",
      "Epoch 1278/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9893\n",
      "Epoch 01278: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0631 - accuracy: 0.9893\n",
      "Epoch 1279/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9893\n",
      "Epoch 01279: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0615 - accuracy: 0.9893\n",
      "Epoch 1280/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9890\n",
      "Epoch 01280: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0641 - accuracy: 0.9890\n",
      "Epoch 1281/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9889\n",
      "Epoch 01281: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0639 - accuracy: 0.9889\n",
      "Epoch 1282/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9892\n",
      "Epoch 01282: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0639 - accuracy: 0.9892\n",
      "Epoch 1283/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9888\n",
      "Epoch 01283: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0640 - accuracy: 0.9888\n",
      "Epoch 1284/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9893\n",
      "Epoch 01284: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0608 - accuracy: 0.9893\n",
      "Epoch 1285/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9892\n",
      "Epoch 01285: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0621 - accuracy: 0.9892\n",
      "Epoch 1286/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9888\n",
      "Epoch 01286: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0648 - accuracy: 0.9888\n",
      "Epoch 1287/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9893\n",
      "Epoch 01287: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0614 - accuracy: 0.9893\n",
      "Epoch 1288/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9891\n",
      "Epoch 01288: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0638 - accuracy: 0.9891\n",
      "Epoch 1289/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9891\n",
      "Epoch 01289: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0629 - accuracy: 0.9891\n",
      "Epoch 1290/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9893\n",
      "Epoch 01290: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0618 - accuracy: 0.9893\n",
      "Epoch 1291/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9892\n",
      "Epoch 01291: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0627 - accuracy: 0.9892\n",
      "Epoch 1292/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9890\n",
      "Epoch 01292: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0627 - accuracy: 0.9890\n",
      "Epoch 1293/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9894\n",
      "Epoch 01293: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0615 - accuracy: 0.9894\n",
      "Epoch 1294/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9889\n",
      "Epoch 01294: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0626 - accuracy: 0.9889\n",
      "Epoch 1295/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9893\n",
      "Epoch 01295: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0621 - accuracy: 0.9893\n",
      "Epoch 1296/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9896\n",
      "Epoch 01296: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0620 - accuracy: 0.9896\n",
      "Epoch 1297/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9888\n",
      "Epoch 01297: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0620 - accuracy: 0.9888\n",
      "Epoch 1298/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9893\n",
      "Epoch 01298: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0624 - accuracy: 0.9893\n",
      "Epoch 1299/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9895\n",
      "Epoch 01299: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0614 - accuracy: 0.9895\n",
      "Epoch 1300/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9894\n",
      "Epoch 01300: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0606 - accuracy: 0.9894\n",
      "Epoch 1301/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9892\n",
      "Epoch 01301: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0636 - accuracy: 0.9892\n",
      "Epoch 1302/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9896\n",
      "Epoch 01302: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0602 - accuracy: 0.9896\n",
      "Epoch 1303/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9896\n",
      "Epoch 01303: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0612 - accuracy: 0.9896\n",
      "Epoch 1304/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9891\n",
      "Epoch 01304: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0626 - accuracy: 0.9891\n",
      "Epoch 1305/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9892\n",
      "Epoch 01305: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0626 - accuracy: 0.9892\n",
      "Epoch 1306/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9898\n",
      "Epoch 01306: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0595 - accuracy: 0.9898\n",
      "Epoch 1307/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9894\n",
      "Epoch 01307: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0640 - accuracy: 0.9894\n",
      "Epoch 1308/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9892\n",
      "Epoch 01308: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0614 - accuracy: 0.9892\n",
      "Epoch 1309/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9892\n",
      "Epoch 01309: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0609 - accuracy: 0.9892\n",
      "Epoch 1310/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9893\n",
      "Epoch 01310: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0626 - accuracy: 0.9893\n",
      "Epoch 1311/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9895\n",
      "Epoch 01311: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0604 - accuracy: 0.9895\n",
      "Epoch 1312/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9891\n",
      "Epoch 01312: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0591 - accuracy: 0.9891\n",
      "Epoch 1313/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9894\n",
      "Epoch 01313: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0622 - accuracy: 0.9894\n",
      "Epoch 1314/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9892\n",
      "Epoch 01314: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0621 - accuracy: 0.9892\n",
      "Epoch 1315/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9894\n",
      "Epoch 01315: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0615 - accuracy: 0.9894\n",
      "Epoch 1316/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9894\n",
      "Epoch 01316: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0617 - accuracy: 0.9894\n",
      "Epoch 1317/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9894\n",
      "Epoch 01317: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0606 - accuracy: 0.9894\n",
      "Epoch 1318/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9898\n",
      "Epoch 01318: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0614 - accuracy: 0.9898\n",
      "Epoch 1319/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9893\n",
      "Epoch 01319: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0620 - accuracy: 0.9893\n",
      "Epoch 1320/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9894\n",
      "Epoch 01320: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0628 - accuracy: 0.9894\n",
      "Epoch 1321/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9896\n",
      "Epoch 01321: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0604 - accuracy: 0.9896\n",
      "Epoch 1322/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9897\n",
      "Epoch 01322: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0611 - accuracy: 0.9897\n",
      "Epoch 1323/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9897\n",
      "Epoch 01323: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0607 - accuracy: 0.9897\n",
      "Epoch 1324/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9895\n",
      "Epoch 01324: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0599 - accuracy: 0.9895\n",
      "Epoch 1325/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9899\n",
      "Epoch 01325: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0593 - accuracy: 0.9899\n",
      "Epoch 1326/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9896\n",
      "Epoch 01326: loss did not improve from 0.05852\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0612 - accuracy: 0.9896\n",
      "Epoch 1327/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9898\n",
      "Epoch 01327: loss improved from 0.05852 to 0.05838, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1327.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0584 - accuracy: 0.9898\n",
      "Epoch 1328/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9895\n",
      "Epoch 01328: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0617 - accuracy: 0.9895\n",
      "Epoch 1329/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9894\n",
      "Epoch 01329: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0607 - accuracy: 0.9894\n",
      "Epoch 1330/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9900\n",
      "Epoch 01330: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0590 - accuracy: 0.9900\n",
      "Epoch 1331/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9891\n",
      "Epoch 01331: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0606 - accuracy: 0.9891\n",
      "Epoch 1332/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9895\n",
      "Epoch 01332: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0607 - accuracy: 0.9895\n",
      "Epoch 1333/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9896\n",
      "Epoch 01333: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0601 - accuracy: 0.9896\n",
      "Epoch 1334/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9896\n",
      "Epoch 01334: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0593 - accuracy: 0.9896\n",
      "Epoch 1335/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9893\n",
      "Epoch 01335: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0606 - accuracy: 0.9893\n",
      "Epoch 1336/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9899\n",
      "Epoch 01336: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0584 - accuracy: 0.9899\n",
      "Epoch 1337/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9901\n",
      "Epoch 01337: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0600 - accuracy: 0.9901\n",
      "Epoch 1338/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9896\n",
      "Epoch 01338: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0594 - accuracy: 0.9896\n",
      "Epoch 1339/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9894\n",
      "Epoch 01339: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0613 - accuracy: 0.9894\n",
      "Epoch 1340/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9899\n",
      "Epoch 01340: loss did not improve from 0.05838\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0592 - accuracy: 0.9899\n",
      "Epoch 1341/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9900\n",
      "Epoch 01341: loss improved from 0.05838 to 0.05833, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1341.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0583 - accuracy: 0.9900\n",
      "Epoch 1342/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9893\n",
      "Epoch 01342: loss did not improve from 0.05833\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0604 - accuracy: 0.9893\n",
      "Epoch 1343/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9895\n",
      "Epoch 01343: loss improved from 0.05833 to 0.05825, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1343.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0583 - accuracy: 0.9895\n",
      "Epoch 1344/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9893\n",
      "Epoch 01344: loss did not improve from 0.05825\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0587 - accuracy: 0.9893\n",
      "Epoch 1345/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9897\n",
      "Epoch 01345: loss did not improve from 0.05825\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0598 - accuracy: 0.9897\n",
      "Epoch 1346/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9892\n",
      "Epoch 01346: loss did not improve from 0.05825\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0603 - accuracy: 0.9892\n",
      "Epoch 1347/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9897\n",
      "Epoch 01347: loss did not improve from 0.05825\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0605 - accuracy: 0.9897\n",
      "Epoch 1348/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9897\n",
      "Epoch 01348: loss did not improve from 0.05825\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0590 - accuracy: 0.9897\n",
      "Epoch 1349/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9894\n",
      "Epoch 01349: loss did not improve from 0.05825\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0587 - accuracy: 0.9894\n",
      "Epoch 1350/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9899\n",
      "Epoch 01350: loss did not improve from 0.05825\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0584 - accuracy: 0.9899\n",
      "Epoch 1351/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9897\n",
      "Epoch 01351: loss improved from 0.05825 to 0.05735, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1351.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0574 - accuracy: 0.9897\n",
      "Epoch 1352/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9896\n",
      "Epoch 01352: loss did not improve from 0.05735\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0598 - accuracy: 0.9896\n",
      "Epoch 1353/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9896\n",
      "Epoch 01353: loss did not improve from 0.05735\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0588 - accuracy: 0.9896\n",
      "Epoch 1354/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9902\n",
      "Epoch 01354: loss did not improve from 0.05735\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0577 - accuracy: 0.9902\n",
      "Epoch 1355/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9895\n",
      "Epoch 01355: loss did not improve from 0.05735\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0595 - accuracy: 0.9895\n",
      "Epoch 1356/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9897\n",
      "Epoch 01356: loss did not improve from 0.05735\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0600 - accuracy: 0.9897\n",
      "Epoch 1357/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9895\n",
      "Epoch 01357: loss did not improve from 0.05735\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0574 - accuracy: 0.9895\n",
      "Epoch 1358/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9896\n",
      "Epoch 01358: loss did not improve from 0.05735\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0588 - accuracy: 0.9896\n",
      "Epoch 1359/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9898\n",
      "Epoch 01359: loss did not improve from 0.05735\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0587 - accuracy: 0.9898\n",
      "Epoch 1360/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9896\n",
      "Epoch 01360: loss did not improve from 0.05735\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0593 - accuracy: 0.9896\n",
      "Epoch 1361/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9897\n",
      "Epoch 01361: loss did not improve from 0.05735\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0583 - accuracy: 0.9897\n",
      "Epoch 1362/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9899\n",
      "Epoch 01362: loss did not improve from 0.05735\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0581 - accuracy: 0.9899\n",
      "Epoch 1363/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9900\n",
      "Epoch 01363: loss improved from 0.05735 to 0.05706, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1363.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0571 - accuracy: 0.9900\n",
      "Epoch 1364/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9901\n",
      "Epoch 01364: loss did not improve from 0.05706\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0587 - accuracy: 0.9901\n",
      "Epoch 1365/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9900\n",
      "Epoch 01365: loss did not improve from 0.05706\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0585 - accuracy: 0.9900\n",
      "Epoch 1366/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9900\n",
      "Epoch 01366: loss did not improve from 0.05706\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0581 - accuracy: 0.9900\n",
      "Epoch 1367/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9901\n",
      "Epoch 01367: loss improved from 0.05706 to 0.05608, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1367.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0561 - accuracy: 0.9901\n",
      "Epoch 1368/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9897\n",
      "Epoch 01368: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0590 - accuracy: 0.9897\n",
      "Epoch 1369/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9899\n",
      "Epoch 01369: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0597 - accuracy: 0.9899\n",
      "Epoch 1370/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9898\n",
      "Epoch 01370: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0573 - accuracy: 0.9898\n",
      "Epoch 1371/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9898\n",
      "Epoch 01371: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0588 - accuracy: 0.9898\n",
      "Epoch 1372/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9899\n",
      "Epoch 01372: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0564 - accuracy: 0.9899\n",
      "Epoch 1373/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9898\n",
      "Epoch 01373: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0590 - accuracy: 0.9898\n",
      "Epoch 1374/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9898\n",
      "Epoch 01374: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0590 - accuracy: 0.9898\n",
      "Epoch 1375/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9903\n",
      "Epoch 01375: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0578 - accuracy: 0.9903\n",
      "Epoch 1376/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9905\n",
      "Epoch 01376: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0568 - accuracy: 0.9905\n",
      "Epoch 1377/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9900\n",
      "Epoch 01377: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0575 - accuracy: 0.9900\n",
      "Epoch 1378/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9897\n",
      "Epoch 01378: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0577 - accuracy: 0.9897\n",
      "Epoch 1379/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9902\n",
      "Epoch 01379: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0571 - accuracy: 0.9902\n",
      "Epoch 1380/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9902\n",
      "Epoch 01380: loss did not improve from 0.05608\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0571 - accuracy: 0.9902\n",
      "Epoch 1381/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9900\n",
      "Epoch 01381: loss improved from 0.05608 to 0.05604, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1381.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0560 - accuracy: 0.9900\n",
      "Epoch 1382/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9900\n",
      "Epoch 01382: loss did not improve from 0.05604\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0561 - accuracy: 0.9900\n",
      "Epoch 1383/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9897\n",
      "Epoch 01383: loss did not improve from 0.05604\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0584 - accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1384/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9899\n",
      "Epoch 01384: loss did not improve from 0.05604\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0575 - accuracy: 0.9899\n",
      "Epoch 1385/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9900\n",
      "Epoch 01385: loss did not improve from 0.05604\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0579 - accuracy: 0.9900\n",
      "Epoch 1386/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9897\n",
      "Epoch 01386: loss did not improve from 0.05604\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0593 - accuracy: 0.9897\n",
      "Epoch 1387/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9902\n",
      "Epoch 01387: loss improved from 0.05604 to 0.05529, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1387.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0553 - accuracy: 0.9902\n",
      "Epoch 1388/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9897\n",
      "Epoch 01388: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0583 - accuracy: 0.9897\n",
      "Epoch 1389/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9901\n",
      "Epoch 01389: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0571 - accuracy: 0.9901\n",
      "Epoch 1390/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9902\n",
      "Epoch 01390: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0554 - accuracy: 0.9902\n",
      "Epoch 1391/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9903\n",
      "Epoch 01391: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0566 - accuracy: 0.9903\n",
      "Epoch 1392/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9900\n",
      "Epoch 01392: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0577 - accuracy: 0.9900\n",
      "Epoch 1393/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9901\n",
      "Epoch 01393: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0580 - accuracy: 0.9901\n",
      "Epoch 1394/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9897\n",
      "Epoch 01394: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0586 - accuracy: 0.9897\n",
      "Epoch 1395/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9900\n",
      "Epoch 01395: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0570 - accuracy: 0.9900\n",
      "Epoch 1396/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9901\n",
      "Epoch 01396: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0556 - accuracy: 0.9901\n",
      "Epoch 1397/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9902\n",
      "Epoch 01397: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0555 - accuracy: 0.9902\n",
      "Epoch 1398/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9903\n",
      "Epoch 01398: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0562 - accuracy: 0.9903\n",
      "Epoch 1399/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9898\n",
      "Epoch 01399: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0579 - accuracy: 0.9898\n",
      "Epoch 1400/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9903\n",
      "Epoch 01400: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0556 - accuracy: 0.9903\n",
      "Epoch 1401/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9898\n",
      "Epoch 01401: loss did not improve from 0.05529\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0567 - accuracy: 0.9898\n",
      "Epoch 1402/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9901\n",
      "Epoch 01402: loss improved from 0.05529 to 0.05477, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1402.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0548 - accuracy: 0.9901\n",
      "Epoch 1403/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9901\n",
      "Epoch 01403: loss did not improve from 0.05477\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0556 - accuracy: 0.9901\n",
      "Epoch 1404/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9904\n",
      "Epoch 01404: loss improved from 0.05477 to 0.05433, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1404.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0543 - accuracy: 0.9904\n",
      "Epoch 1405/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9897\n",
      "Epoch 01405: loss did not improve from 0.05433\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0567 - accuracy: 0.9897\n",
      "Epoch 1406/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9903\n",
      "Epoch 01406: loss did not improve from 0.05433\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0568 - accuracy: 0.9903\n",
      "Epoch 1407/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9900\n",
      "Epoch 01407: loss did not improve from 0.05433\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0569 - accuracy: 0.9900\n",
      "Epoch 1408/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9899\n",
      "Epoch 01408: loss did not improve from 0.05433\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0568 - accuracy: 0.9899\n",
      "Epoch 1409/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9901\n",
      "Epoch 01409: loss did not improve from 0.05433\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0547 - accuracy: 0.9901\n",
      "Epoch 1410/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9902\n",
      "Epoch 01410: loss did not improve from 0.05433\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0557 - accuracy: 0.9902\n",
      "Epoch 1411/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9903\n",
      "Epoch 01411: loss did not improve from 0.05433\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0553 - accuracy: 0.9903\n",
      "Epoch 1412/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9903\n",
      "Epoch 01412: loss did not improve from 0.05433\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0554 - accuracy: 0.9903\n",
      "Epoch 1413/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9903\n",
      "Epoch 01413: loss did not improve from 0.05433\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0557 - accuracy: 0.9903\n",
      "Epoch 1414/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9904\n",
      "Epoch 01414: loss did not improve from 0.05433\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0561 - accuracy: 0.9904\n",
      "Epoch 1415/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9901\n",
      "Epoch 01415: loss did not improve from 0.05433\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0568 - accuracy: 0.9901\n",
      "Epoch 1416/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9905\n",
      "Epoch 01416: loss improved from 0.05433 to 0.05360, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1416.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0536 - accuracy: 0.9905\n",
      "Epoch 1417/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9897\n",
      "Epoch 01417: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0560 - accuracy: 0.9897\n",
      "Epoch 1418/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9902\n",
      "Epoch 01418: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0579 - accuracy: 0.9902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1419/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9900\n",
      "Epoch 01419: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0555 - accuracy: 0.9900\n",
      "Epoch 1420/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9903\n",
      "Epoch 01420: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0551 - accuracy: 0.9903\n",
      "Epoch 1421/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9899\n",
      "Epoch 01421: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0573 - accuracy: 0.9899\n",
      "Epoch 1422/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9901\n",
      "Epoch 01422: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0552 - accuracy: 0.9901\n",
      "Epoch 1423/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9899\n",
      "Epoch 01423: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0555 - accuracy: 0.9899\n",
      "Epoch 1424/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9904\n",
      "Epoch 01424: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0560 - accuracy: 0.9904\n",
      "Epoch 1425/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9905\n",
      "Epoch 01425: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0537 - accuracy: 0.9905\n",
      "Epoch 1426/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9902\n",
      "Epoch 01426: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0550 - accuracy: 0.9902\n",
      "Epoch 1427/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9904\n",
      "Epoch 01427: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0551 - accuracy: 0.9904\n",
      "Epoch 1428/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9900\n",
      "Epoch 01428: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0556 - accuracy: 0.9900\n",
      "Epoch 1429/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9903\n",
      "Epoch 01429: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0556 - accuracy: 0.9903\n",
      "Epoch 1430/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9903\n",
      "Epoch 01430: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0555 - accuracy: 0.9903\n",
      "Epoch 1431/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9904\n",
      "Epoch 01431: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0559 - accuracy: 0.9904\n",
      "Epoch 1432/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9902\n",
      "Epoch 01432: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0581 - accuracy: 0.9902\n",
      "Epoch 1433/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9906\n",
      "Epoch 01433: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0540 - accuracy: 0.9906\n",
      "Epoch 1434/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9903\n",
      "Epoch 01434: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0549 - accuracy: 0.9903\n",
      "Epoch 1435/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9903\n",
      "Epoch 01435: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0547 - accuracy: 0.9903\n",
      "Epoch 1436/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9902\n",
      "Epoch 01436: loss did not improve from 0.05360\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0557 - accuracy: 0.9902\n",
      "Epoch 1437/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9904\n",
      "Epoch 01437: loss improved from 0.05360 to 0.05253, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1437.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0525 - accuracy: 0.9904\n",
      "Epoch 1438/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9901\n",
      "Epoch 01438: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0540 - accuracy: 0.9901\n",
      "Epoch 1439/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9905\n",
      "Epoch 01439: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0546 - accuracy: 0.9905\n",
      "Epoch 1440/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9905\n",
      "Epoch 01440: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0539 - accuracy: 0.9905\n",
      "Epoch 1441/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9901\n",
      "Epoch 01441: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0547 - accuracy: 0.9901\n",
      "Epoch 1442/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9902\n",
      "Epoch 01442: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0559 - accuracy: 0.9902\n",
      "Epoch 1443/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9906\n",
      "Epoch 01443: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0526 - accuracy: 0.9906\n",
      "Epoch 1444/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9904\n",
      "Epoch 01444: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0552 - accuracy: 0.9904\n",
      "Epoch 1445/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9902\n",
      "Epoch 01445: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0551 - accuracy: 0.9902\n",
      "Epoch 1446/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9908\n",
      "Epoch 01446: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0544 - accuracy: 0.9908\n",
      "Epoch 1447/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9904\n",
      "Epoch 01447: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0551 - accuracy: 0.9904\n",
      "Epoch 1448/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9902\n",
      "Epoch 01448: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0539 - accuracy: 0.9902\n",
      "Epoch 1449/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.9907\n",
      "Epoch 01449: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0542 - accuracy: 0.9907\n",
      "Epoch 1450/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9907\n",
      "Epoch 01450: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0539 - accuracy: 0.9907\n",
      "Epoch 1451/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9904\n",
      "Epoch 01451: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0531 - accuracy: 0.9904\n",
      "Epoch 1452/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9904\n",
      "Epoch 01452: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0534 - accuracy: 0.9904\n",
      "Epoch 1453/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9901\n",
      "Epoch 01453: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0539 - accuracy: 0.9901\n",
      "Epoch 1454/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9906\n",
      "Epoch 01454: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0532 - accuracy: 0.9906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1455/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9905\n",
      "Epoch 01455: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0547 - accuracy: 0.9905\n",
      "Epoch 1456/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9908\n",
      "Epoch 01456: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0531 - accuracy: 0.9908\n",
      "Epoch 1457/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9902\n",
      "Epoch 01457: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0536 - accuracy: 0.9902\n",
      "Epoch 1458/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9904\n",
      "Epoch 01458: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0557 - accuracy: 0.9904\n",
      "Epoch 1459/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9904\n",
      "Epoch 01459: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0550 - accuracy: 0.9904\n",
      "Epoch 1460/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9906\n",
      "Epoch 01460: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0538 - accuracy: 0.9906\n",
      "Epoch 1461/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9904\n",
      "Epoch 01461: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0539 - accuracy: 0.9904\n",
      "Epoch 1462/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9905\n",
      "Epoch 01462: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0534 - accuracy: 0.9905\n",
      "Epoch 1463/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9905\n",
      "Epoch 01463: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0534 - accuracy: 0.9905\n",
      "Epoch 1464/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9906\n",
      "Epoch 01464: loss did not improve from 0.05253\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0534 - accuracy: 0.9906\n",
      "Epoch 1465/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9907\n",
      "Epoch 01465: loss improved from 0.05253 to 0.05177, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1465.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0518 - accuracy: 0.9907\n",
      "Epoch 1466/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9908\n",
      "Epoch 01466: loss improved from 0.05177 to 0.05088, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1466.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0509 - accuracy: 0.9908\n",
      "Epoch 1467/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9905\n",
      "Epoch 01467: loss did not improve from 0.05088\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0544 - accuracy: 0.9905\n",
      "Epoch 1468/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9907\n",
      "Epoch 01468: loss did not improve from 0.05088\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0527 - accuracy: 0.9907\n",
      "Epoch 1469/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9902\n",
      "Epoch 01469: loss did not improve from 0.05088\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0552 - accuracy: 0.9902\n",
      "Epoch 1470/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9907\n",
      "Epoch 01470: loss did not improve from 0.05088\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0528 - accuracy: 0.9907\n",
      "Epoch 1471/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9906\n",
      "Epoch 01471: loss did not improve from 0.05088\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0527 - accuracy: 0.9906\n",
      "Epoch 1472/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9903\n",
      "Epoch 01472: loss did not improve from 0.05088\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0536 - accuracy: 0.9903\n",
      "Epoch 1473/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9907\n",
      "Epoch 01473: loss did not improve from 0.05088\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0544 - accuracy: 0.9907\n",
      "Epoch 1474/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9909\n",
      "Epoch 01474: loss did not improve from 0.05088\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0512 - accuracy: 0.9909\n",
      "Epoch 1475/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9907\n",
      "Epoch 01475: loss did not improve from 0.05088\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0528 - accuracy: 0.9907\n",
      "Epoch 1476/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9904\n",
      "Epoch 01476: loss did not improve from 0.05088\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0535 - accuracy: 0.9904\n",
      "Epoch 1477/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9908\n",
      "Epoch 01477: loss did not improve from 0.05088\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0522 - accuracy: 0.9908\n",
      "Epoch 1478/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9907\n",
      "Epoch 01478: loss improved from 0.05088 to 0.05070, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1478.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0507 - accuracy: 0.9907\n",
      "Epoch 1479/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9907\n",
      "Epoch 01479: loss did not improve from 0.05070\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0531 - accuracy: 0.9907\n",
      "Epoch 1480/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.9906\n",
      "Epoch 01480: loss did not improve from 0.05070\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0532 - accuracy: 0.9906\n",
      "Epoch 1481/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9908\n",
      "Epoch 01481: loss did not improve from 0.05070\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0517 - accuracy: 0.9908\n",
      "Epoch 1482/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9902\n",
      "Epoch 01482: loss did not improve from 0.05070\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0536 - accuracy: 0.9902\n",
      "Epoch 1483/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9910\n",
      "Epoch 01483: loss improved from 0.05070 to 0.05047, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1483.ckpt\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0505 - accuracy: 0.9910\n",
      "Epoch 1484/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9906\n",
      "Epoch 01484: loss did not improve from 0.05047\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0531 - accuracy: 0.9906\n",
      "Epoch 1485/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9907\n",
      "Epoch 01485: loss did not improve from 0.05047\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0537 - accuracy: 0.9907\n",
      "Epoch 1486/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9905\n",
      "Epoch 01486: loss did not improve from 0.05047\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0538 - accuracy: 0.9905\n",
      "Epoch 1487/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9907\n",
      "Epoch 01487: loss did not improve from 0.05047\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0510 - accuracy: 0.9907\n",
      "Epoch 1488/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9911\n",
      "Epoch 01488: loss did not improve from 0.05047\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0509 - accuracy: 0.9911\n",
      "Epoch 1489/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9904\n",
      "Epoch 01489: loss did not improve from 0.05047\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0512 - accuracy: 0.9904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1490/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9908\n",
      "Epoch 01490: loss did not improve from 0.05047\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0528 - accuracy: 0.9908\n",
      "Epoch 1491/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9908\n",
      "Epoch 01491: loss did not improve from 0.05047\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0519 - accuracy: 0.9908\n",
      "Epoch 1492/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9907\n",
      "Epoch 01492: loss improved from 0.05047 to 0.05027, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1492.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0503 - accuracy: 0.9907\n",
      "Epoch 1493/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9908\n",
      "Epoch 01493: loss did not improve from 0.05027\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0521 - accuracy: 0.9908\n",
      "Epoch 1494/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9909\n",
      "Epoch 01494: loss did not improve from 0.05027\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0512 - accuracy: 0.9909\n",
      "Epoch 1495/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9907\n",
      "Epoch 01495: loss did not improve from 0.05027\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0504 - accuracy: 0.9907\n",
      "Epoch 1496/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9911\n",
      "Epoch 01496: loss improved from 0.05027 to 0.04944, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1496.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0494 - accuracy: 0.9911\n",
      "Epoch 1497/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9909\n",
      "Epoch 01497: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0505 - accuracy: 0.9909\n",
      "Epoch 1498/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9903\n",
      "Epoch 01498: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0500 - accuracy: 0.9903\n",
      "Epoch 1499/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9909\n",
      "Epoch 01499: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0516 - accuracy: 0.9909\n",
      "Epoch 1500/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9907\n",
      "Epoch 01500: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0528 - accuracy: 0.9907\n",
      "Epoch 1501/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9908\n",
      "Epoch 01501: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0528 - accuracy: 0.9908\n",
      "Epoch 1502/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9907\n",
      "Epoch 01502: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0521 - accuracy: 0.9907\n",
      "Epoch 1503/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9909\n",
      "Epoch 01503: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0506 - accuracy: 0.9909\n",
      "Epoch 1504/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9910\n",
      "Epoch 01504: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0523 - accuracy: 0.9910\n",
      "Epoch 1505/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9910\n",
      "Epoch 01505: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0495 - accuracy: 0.9910\n",
      "Epoch 1506/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9908\n",
      "Epoch 01506: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0504 - accuracy: 0.9908\n",
      "Epoch 1507/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9911\n",
      "Epoch 01507: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0500 - accuracy: 0.9911\n",
      "Epoch 1508/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9906\n",
      "Epoch 01508: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0524 - accuracy: 0.9906\n",
      "Epoch 1509/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9906\n",
      "Epoch 01509: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0530 - accuracy: 0.9906\n",
      "Epoch 1510/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9907\n",
      "Epoch 01510: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0511 - accuracy: 0.9907\n",
      "Epoch 1511/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9905\n",
      "Epoch 01511: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0525 - accuracy: 0.9905\n",
      "Epoch 1512/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9909\n",
      "Epoch 01512: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0502 - accuracy: 0.9909\n",
      "Epoch 1513/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9905\n",
      "Epoch 01513: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0524 - accuracy: 0.9905\n",
      "Epoch 1514/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9907\n",
      "Epoch 01514: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0523 - accuracy: 0.9907\n",
      "Epoch 1515/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9907\n",
      "Epoch 01515: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0516 - accuracy: 0.9907\n",
      "Epoch 1516/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9909\n",
      "Epoch 01516: loss did not improve from 0.04944\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0515 - accuracy: 0.9909\n",
      "Epoch 1517/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9910\n",
      "Epoch 01517: loss improved from 0.04944 to 0.04883, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1517.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0488 - accuracy: 0.9910\n",
      "Epoch 1518/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9909\n",
      "Epoch 01518: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0507 - accuracy: 0.9909\n",
      "Epoch 1519/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9908\n",
      "Epoch 01519: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0499 - accuracy: 0.9908\n",
      "Epoch 1520/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9906\n",
      "Epoch 01520: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0526 - accuracy: 0.9906\n",
      "Epoch 1521/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9907\n",
      "Epoch 01521: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0508 - accuracy: 0.9907\n",
      "Epoch 1522/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9910\n",
      "Epoch 01522: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0504 - accuracy: 0.9910\n",
      "Epoch 1523/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9909\n",
      "Epoch 01523: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0498 - accuracy: 0.9909\n",
      "Epoch 1524/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9906\n",
      "Epoch 01524: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0523 - accuracy: 0.9906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1525/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9907\n",
      "Epoch 01525: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0509 - accuracy: 0.9907\n",
      "Epoch 1526/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9911\n",
      "Epoch 01526: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0502 - accuracy: 0.9911\n",
      "Epoch 1527/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9909\n",
      "Epoch 01527: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0530 - accuracy: 0.9909\n",
      "Epoch 1528/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9910\n",
      "Epoch 01528: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0506 - accuracy: 0.9910\n",
      "Epoch 1529/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9910\n",
      "Epoch 01529: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0511 - accuracy: 0.9910\n",
      "Epoch 1530/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9910\n",
      "Epoch 01530: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0497 - accuracy: 0.9910\n",
      "Epoch 1531/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9909\n",
      "Epoch 01531: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0502 - accuracy: 0.9909\n",
      "Epoch 1532/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9911\n",
      "Epoch 01532: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0504 - accuracy: 0.9911\n",
      "Epoch 1533/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9912\n",
      "Epoch 01533: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0509 - accuracy: 0.9912\n",
      "Epoch 1534/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9910\n",
      "Epoch 01534: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0511 - accuracy: 0.9910\n",
      "Epoch 1535/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9906\n",
      "Epoch 01535: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0509 - accuracy: 0.9906\n",
      "Epoch 1536/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9908\n",
      "Epoch 01536: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0507 - accuracy: 0.9908\n",
      "Epoch 1537/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9910\n",
      "Epoch 01537: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0518 - accuracy: 0.9910\n",
      "Epoch 1538/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9907\n",
      "Epoch 01538: loss did not improve from 0.04883\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0518 - accuracy: 0.9907\n",
      "Epoch 1539/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9909\n",
      "Epoch 01539: loss improved from 0.04883 to 0.04870, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1539.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0487 - accuracy: 0.9909\n",
      "Epoch 1540/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9909\n",
      "Epoch 01540: loss did not improve from 0.04870\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0515 - accuracy: 0.9909\n",
      "Epoch 1541/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9908\n",
      "Epoch 01541: loss did not improve from 0.04870\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0511 - accuracy: 0.9908\n",
      "Epoch 1542/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9907\n",
      "Epoch 01542: loss did not improve from 0.04870\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0497 - accuracy: 0.9907\n",
      "Epoch 1543/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9910\n",
      "Epoch 01543: loss did not improve from 0.04870\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0510 - accuracy: 0.9910\n",
      "Epoch 1544/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9906\n",
      "Epoch 01544: loss did not improve from 0.04870\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0507 - accuracy: 0.9906\n",
      "Epoch 1545/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9912\n",
      "Epoch 01545: loss did not improve from 0.04870\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0490 - accuracy: 0.9912\n",
      "Epoch 1546/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9909\n",
      "Epoch 01546: loss improved from 0.04870 to 0.04861, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1546.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0486 - accuracy: 0.9909\n",
      "Epoch 1547/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9911\n",
      "Epoch 01547: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0514 - accuracy: 0.9911\n",
      "Epoch 1548/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9911\n",
      "Epoch 01548: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0494 - accuracy: 0.9911\n",
      "Epoch 1549/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9911\n",
      "Epoch 01549: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0487 - accuracy: 0.9911\n",
      "Epoch 1550/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9907\n",
      "Epoch 01550: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0513 - accuracy: 0.9907\n",
      "Epoch 1551/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9909\n",
      "Epoch 01551: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0503 - accuracy: 0.9909\n",
      "Epoch 1552/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9908\n",
      "Epoch 01552: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0510 - accuracy: 0.9908\n",
      "Epoch 1553/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9911\n",
      "Epoch 01553: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0491 - accuracy: 0.9911\n",
      "Epoch 1554/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9913\n",
      "Epoch 01554: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0494 - accuracy: 0.9913\n",
      "Epoch 1555/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9909\n",
      "Epoch 01555: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0506 - accuracy: 0.9909\n",
      "Epoch 1556/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9911\n",
      "Epoch 01556: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0490 - accuracy: 0.9911\n",
      "Epoch 1557/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9911\n",
      "Epoch 01557: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0500 - accuracy: 0.9911\n",
      "Epoch 1558/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9912\n",
      "Epoch 01558: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0501 - accuracy: 0.9912\n",
      "Epoch 1559/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9912\n",
      "Epoch 01559: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0493 - accuracy: 0.9912\n",
      "Epoch 1560/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9907\n",
      "Epoch 01560: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0496 - accuracy: 0.9907\n",
      "Epoch 1561/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9911\n",
      "Epoch 01561: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0498 - accuracy: 0.9911\n",
      "Epoch 1562/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9909\n",
      "Epoch 01562: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0490 - accuracy: 0.9909\n",
      "Epoch 1563/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9911\n",
      "Epoch 01563: loss did not improve from 0.04861\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0497 - accuracy: 0.9911\n",
      "Epoch 1564/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9916\n",
      "Epoch 01564: loss improved from 0.04861 to 0.04814, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1564.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0481 - accuracy: 0.9916\n",
      "Epoch 1565/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9908\n",
      "Epoch 01565: loss did not improve from 0.04814\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0502 - accuracy: 0.9908\n",
      "Epoch 1566/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9914\n",
      "Epoch 01566: loss improved from 0.04814 to 0.04808, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1566.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0481 - accuracy: 0.9914\n",
      "Epoch 1567/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9909\n",
      "Epoch 01567: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0487 - accuracy: 0.9909\n",
      "Epoch 1568/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9910\n",
      "Epoch 01568: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0507 - accuracy: 0.9910\n",
      "Epoch 1569/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9912\n",
      "Epoch 01569: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0493 - accuracy: 0.9912\n",
      "Epoch 1570/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9913\n",
      "Epoch 01570: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0495 - accuracy: 0.9913\n",
      "Epoch 1571/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9908\n",
      "Epoch 01571: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0510 - accuracy: 0.9908\n",
      "Epoch 1572/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9913\n",
      "Epoch 01572: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0500 - accuracy: 0.9913\n",
      "Epoch 1573/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9915\n",
      "Epoch 01573: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0482 - accuracy: 0.9915\n",
      "Epoch 1574/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9913\n",
      "Epoch 01574: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0504 - accuracy: 0.9913\n",
      "Epoch 1575/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9913\n",
      "Epoch 01575: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0498 - accuracy: 0.9913\n",
      "Epoch 1576/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9913\n",
      "Epoch 01576: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0486 - accuracy: 0.9913\n",
      "Epoch 1577/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9912\n",
      "Epoch 01577: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0488 - accuracy: 0.9912\n",
      "Epoch 1578/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9913\n",
      "Epoch 01578: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0491 - accuracy: 0.9913\n",
      "Epoch 1579/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9911\n",
      "Epoch 01579: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0498 - accuracy: 0.9911\n",
      "Epoch 1580/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9914\n",
      "Epoch 01580: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0487 - accuracy: 0.9914\n",
      "Epoch 1581/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9910\n",
      "Epoch 01581: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0495 - accuracy: 0.9910\n",
      "Epoch 1582/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9912\n",
      "Epoch 01582: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0502 - accuracy: 0.9912\n",
      "Epoch 1583/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9909\n",
      "Epoch 01583: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0505 - accuracy: 0.9909\n",
      "Epoch 1584/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9913\n",
      "Epoch 01584: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0486 - accuracy: 0.9913\n",
      "Epoch 1585/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9909\n",
      "Epoch 01585: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0503 - accuracy: 0.9909\n",
      "Epoch 1586/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9912\n",
      "Epoch 01586: loss did not improve from 0.04808\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0494 - accuracy: 0.9912\n",
      "Epoch 1587/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9916\n",
      "Epoch 01587: loss improved from 0.04808 to 0.04668, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1587.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0467 - accuracy: 0.9916\n",
      "Epoch 1588/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9915\n",
      "Epoch 01588: loss did not improve from 0.04668\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0485 - accuracy: 0.9915\n",
      "Epoch 1589/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9914\n",
      "Epoch 01589: loss did not improve from 0.04668\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0482 - accuracy: 0.9914\n",
      "Epoch 1590/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9917\n",
      "Epoch 01590: loss improved from 0.04668 to 0.04622, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1590.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0462 - accuracy: 0.9917\n",
      "Epoch 1591/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9912\n",
      "Epoch 01591: loss did not improve from 0.04622\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0473 - accuracy: 0.9912\n",
      "Epoch 1592/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9911\n",
      "Epoch 01592: loss did not improve from 0.04622\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0489 - accuracy: 0.9911\n",
      "Epoch 1593/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9913\n",
      "Epoch 01593: loss did not improve from 0.04622\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0482 - accuracy: 0.9913\n",
      "Epoch 1594/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9911\n",
      "Epoch 01594: loss did not improve from 0.04622\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0485 - accuracy: 0.9911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1595/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9914\n",
      "Epoch 01595: loss did not improve from 0.04622\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0482 - accuracy: 0.9914\n",
      "Epoch 1596/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9912\n",
      "Epoch 01596: loss did not improve from 0.04622\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0479 - accuracy: 0.9912\n",
      "Epoch 1597/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9913\n",
      "Epoch 01597: loss did not improve from 0.04622\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0477 - accuracy: 0.9913\n",
      "Epoch 1598/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9914\n",
      "Epoch 01598: loss did not improve from 0.04622\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0488 - accuracy: 0.9914\n",
      "Epoch 1599/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9914\n",
      "Epoch 01599: loss did not improve from 0.04622\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0482 - accuracy: 0.9914\n",
      "Epoch 1600/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9910\n",
      "Epoch 01600: loss did not improve from 0.04622\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0485 - accuracy: 0.9910\n",
      "Epoch 1601/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9917\n",
      "Epoch 01601: loss improved from 0.04622 to 0.04536, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1601.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0454 - accuracy: 0.9917\n",
      "Epoch 1602/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9912\n",
      "Epoch 01602: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0465 - accuracy: 0.9912\n",
      "Epoch 1603/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9914\n",
      "Epoch 01603: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0473 - accuracy: 0.9914\n",
      "Epoch 1604/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9914\n",
      "Epoch 01604: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0480 - accuracy: 0.9914\n",
      "Epoch 1605/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9912\n",
      "Epoch 01605: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 993ms/step - loss: 0.0496 - accuracy: 0.9912\n",
      "Epoch 1606/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9913\n",
      "Epoch 01606: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 992ms/step - loss: 0.0483 - accuracy: 0.9913\n",
      "Epoch 1607/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9913\n",
      "Epoch 01607: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 981ms/step - loss: 0.0484 - accuracy: 0.9913\n",
      "Epoch 1608/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9914\n",
      "Epoch 01608: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0470 - accuracy: 0.9914\n",
      "Epoch 1609/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9912\n",
      "Epoch 01609: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0486 - accuracy: 0.9912\n",
      "Epoch 1610/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9912\n",
      "Epoch 01610: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0484 - accuracy: 0.9912\n",
      "Epoch 1611/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9914\n",
      "Epoch 01611: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 981ms/step - loss: 0.0481 - accuracy: 0.9914\n",
      "Epoch 1612/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9915\n",
      "Epoch 01612: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0460 - accuracy: 0.9915\n",
      "Epoch 1613/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9915\n",
      "Epoch 01613: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0467 - accuracy: 0.9915\n",
      "Epoch 1614/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9914\n",
      "Epoch 01614: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 996ms/step - loss: 0.0481 - accuracy: 0.9914\n",
      "Epoch 1615/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9914\n",
      "Epoch 01615: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0468 - accuracy: 0.9914\n",
      "Epoch 1616/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9914\n",
      "Epoch 01616: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 986ms/step - loss: 0.0476 - accuracy: 0.9914\n",
      "Epoch 1617/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9910\n",
      "Epoch 01617: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 989ms/step - loss: 0.0492 - accuracy: 0.9910\n",
      "Epoch 1618/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9915\n",
      "Epoch 01618: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0481 - accuracy: 0.9915\n",
      "Epoch 1619/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9917\n",
      "Epoch 01619: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0459 - accuracy: 0.9917\n",
      "Epoch 1620/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9917\n",
      "Epoch 01620: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 999ms/step - loss: 0.0462 - accuracy: 0.9917\n",
      "Epoch 1621/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9911\n",
      "Epoch 01621: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 993ms/step - loss: 0.0470 - accuracy: 0.9911\n",
      "Epoch 1622/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9913\n",
      "Epoch 01622: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0478 - accuracy: 0.9913\n",
      "Epoch 1623/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9914\n",
      "Epoch 01623: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 983ms/step - loss: 0.0469 - accuracy: 0.9914\n",
      "Epoch 1624/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9913\n",
      "Epoch 01624: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0477 - accuracy: 0.9913\n",
      "Epoch 1625/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9915\n",
      "Epoch 01625: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0461 - accuracy: 0.9915\n",
      "Epoch 1626/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9915\n",
      "Epoch 01626: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0469 - accuracy: 0.9915\n",
      "Epoch 1627/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9914\n",
      "Epoch 01627: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0471 - accuracy: 0.9914\n",
      "Epoch 1628/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9913\n",
      "Epoch 01628: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0467 - accuracy: 0.9913\n",
      "Epoch 1629/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9912\n",
      "Epoch 01629: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0478 - accuracy: 0.9912\n",
      "Epoch 1630/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9915\n",
      "Epoch 01630: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0473 - accuracy: 0.9915\n",
      "Epoch 1631/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9910\n",
      "Epoch 01631: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0487 - accuracy: 0.9910\n",
      "Epoch 1632/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9911\n",
      "Epoch 01632: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0482 - accuracy: 0.9911\n",
      "Epoch 1633/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9919\n",
      "Epoch 01633: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0461 - accuracy: 0.9919\n",
      "Epoch 1634/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9914\n",
      "Epoch 01634: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 991ms/step - loss: 0.0473 - accuracy: 0.9914\n",
      "Epoch 1635/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9914\n",
      "Epoch 01635: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0474 - accuracy: 0.9914\n",
      "Epoch 1636/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9913\n",
      "Epoch 01636: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 983ms/step - loss: 0.0468 - accuracy: 0.9913\n",
      "Epoch 1637/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9913\n",
      "Epoch 01637: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 980ms/step - loss: 0.0464 - accuracy: 0.9913\n",
      "Epoch 1638/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9913\n",
      "Epoch 01638: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 988ms/step - loss: 0.0480 - accuracy: 0.9913\n",
      "Epoch 1639/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9916\n",
      "Epoch 01639: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 987ms/step - loss: 0.0474 - accuracy: 0.9916\n",
      "Epoch 1640/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9915\n",
      "Epoch 01640: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 983ms/step - loss: 0.0459 - accuracy: 0.9915\n",
      "Epoch 1641/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9917\n",
      "Epoch 01641: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0459 - accuracy: 0.9917\n",
      "Epoch 1642/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9916\n",
      "Epoch 01642: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0466 - accuracy: 0.9916\n",
      "Epoch 1643/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9913\n",
      "Epoch 01643: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0470 - accuracy: 0.9913\n",
      "Epoch 1644/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9912\n",
      "Epoch 01644: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 981ms/step - loss: 0.0481 - accuracy: 0.9912\n",
      "Epoch 1645/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9912\n",
      "Epoch 01645: loss did not improve from 0.04536\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0487 - accuracy: 0.9912\n",
      "Epoch 1646/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9919\n",
      "Epoch 01646: loss improved from 0.04536 to 0.04527, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1646.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0453 - accuracy: 0.9919\n",
      "Epoch 1647/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9913\n",
      "Epoch 01647: loss did not improve from 0.04527\n",
      "2/2 [==============================] - 2s 984ms/step - loss: 0.0462 - accuracy: 0.9913\n",
      "Epoch 1648/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9914\n",
      "Epoch 01648: loss did not improve from 0.04527\n",
      "2/2 [==============================] - 2s 991ms/step - loss: 0.0457 - accuracy: 0.9914\n",
      "Epoch 1649/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9914\n",
      "Epoch 01649: loss did not improve from 0.04527\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0472 - accuracy: 0.9914\n",
      "Epoch 1650/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9917\n",
      "Epoch 01650: loss did not improve from 0.04527\n",
      "2/2 [==============================] - 2s 992ms/step - loss: 0.0458 - accuracy: 0.9917\n",
      "Epoch 1651/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9919\n",
      "Epoch 01651: loss improved from 0.04527 to 0.04515, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1651.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0452 - accuracy: 0.9919\n",
      "Epoch 1652/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9916\n",
      "Epoch 01652: loss did not improve from 0.04515\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0452 - accuracy: 0.9916\n",
      "Epoch 1653/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9915\n",
      "Epoch 01653: loss did not improve from 0.04515\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0487 - accuracy: 0.9915\n",
      "Epoch 1654/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9912\n",
      "Epoch 01654: loss did not improve from 0.04515\n",
      "2/2 [==============================] - 2s 980ms/step - loss: 0.0473 - accuracy: 0.9912\n",
      "Epoch 1655/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9918\n",
      "Epoch 01655: loss did not improve from 0.04515\n",
      "2/2 [==============================] - 2s 987ms/step - loss: 0.0462 - accuracy: 0.9918\n",
      "Epoch 1656/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9918\n",
      "Epoch 01656: loss improved from 0.04515 to 0.04505, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1656.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0451 - accuracy: 0.9918\n",
      "Epoch 1657/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9915\n",
      "Epoch 01657: loss did not improve from 0.04505\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0461 - accuracy: 0.9915\n",
      "Epoch 1658/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9914\n",
      "Epoch 01658: loss did not improve from 0.04505\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0460 - accuracy: 0.9914\n",
      "Epoch 1659/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9917\n",
      "Epoch 01659: loss did not improve from 0.04505\n",
      "2/2 [==============================] - 2s 987ms/step - loss: 0.0456 - accuracy: 0.9917\n",
      "Epoch 1660/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9915\n",
      "Epoch 01660: loss did not improve from 0.04505\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0472 - accuracy: 0.9915\n",
      "Epoch 1661/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9917\n",
      "Epoch 01661: loss improved from 0.04505 to 0.04494, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1661.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0449 - accuracy: 0.9917\n",
      "Epoch 1662/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9916\n",
      "Epoch 01662: loss did not improve from 0.04494\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0456 - accuracy: 0.9916\n",
      "Epoch 1663/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9913\n",
      "Epoch 01663: loss did not improve from 0.04494\n",
      "2/2 [==============================] - 2s 983ms/step - loss: 0.0462 - accuracy: 0.9913\n",
      "Epoch 1664/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9917\n",
      "Epoch 01664: loss did not improve from 0.04494\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0470 - accuracy: 0.9917\n",
      "Epoch 1665/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9917\n",
      "Epoch 01665: loss did not improve from 0.04494\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0463 - accuracy: 0.9917\n",
      "Epoch 1666/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9914\n",
      "Epoch 01666: loss did not improve from 0.04494\n",
      "2/2 [==============================] - 2s 989ms/step - loss: 0.0454 - accuracy: 0.9914\n",
      "Epoch 1667/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9916\n",
      "Epoch 01667: loss did not improve from 0.04494\n",
      "2/2 [==============================] - 2s 980ms/step - loss: 0.0452 - accuracy: 0.9916\n",
      "Epoch 1668/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9916\n",
      "Epoch 01668: loss improved from 0.04494 to 0.04449, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1668.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0445 - accuracy: 0.9916\n",
      "Epoch 1669/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9914\n",
      "Epoch 01669: loss did not improve from 0.04449\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0459 - accuracy: 0.9914\n",
      "Epoch 1670/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9920\n",
      "Epoch 01670: loss improved from 0.04449 to 0.04316, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1670.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0432 - accuracy: 0.9920\n",
      "Epoch 1671/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9914\n",
      "Epoch 01671: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 986ms/step - loss: 0.0458 - accuracy: 0.9914\n",
      "Epoch 1672/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9918\n",
      "Epoch 01672: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 983ms/step - loss: 0.0459 - accuracy: 0.9918\n",
      "Epoch 1673/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9919\n",
      "Epoch 01673: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 989ms/step - loss: 0.0468 - accuracy: 0.9919\n",
      "Epoch 1674/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9918\n",
      "Epoch 01674: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 984ms/step - loss: 0.0449 - accuracy: 0.9918\n",
      "Epoch 1675/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9917\n",
      "Epoch 01675: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 990ms/step - loss: 0.0460 - accuracy: 0.9917\n",
      "Epoch 1676/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9915\n",
      "Epoch 01676: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 990ms/step - loss: 0.0465 - accuracy: 0.9915\n",
      "Epoch 1677/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9913\n",
      "Epoch 01677: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 986ms/step - loss: 0.0457 - accuracy: 0.9913\n",
      "Epoch 1678/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9915\n",
      "Epoch 01678: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0449 - accuracy: 0.9915\n",
      "Epoch 1679/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9916\n",
      "Epoch 01679: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 983ms/step - loss: 0.0472 - accuracy: 0.9916\n",
      "Epoch 1680/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9914\n",
      "Epoch 01680: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 988ms/step - loss: 0.0481 - accuracy: 0.9914\n",
      "Epoch 1681/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9914\n",
      "Epoch 01681: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0475 - accuracy: 0.9914\n",
      "Epoch 1682/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9916\n",
      "Epoch 01682: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0453 - accuracy: 0.9916\n",
      "Epoch 1683/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9914\n",
      "Epoch 01683: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 983ms/step - loss: 0.0474 - accuracy: 0.9914\n",
      "Epoch 1684/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9917\n",
      "Epoch 01684: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0454 - accuracy: 0.9917\n",
      "Epoch 1685/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9920\n",
      "Epoch 01685: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0456 - accuracy: 0.9920\n",
      "Epoch 1686/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9914\n",
      "Epoch 01686: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0455 - accuracy: 0.9914\n",
      "Epoch 1687/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9915\n",
      "Epoch 01687: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0473 - accuracy: 0.9915\n",
      "Epoch 1688/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9916\n",
      "Epoch 01688: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0443 - accuracy: 0.9916\n",
      "Epoch 1689/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9916\n",
      "Epoch 01689: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0451 - accuracy: 0.9916\n",
      "Epoch 1690/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9912\n",
      "Epoch 01690: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0466 - accuracy: 0.9912\n",
      "Epoch 1691/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9915\n",
      "Epoch 01691: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0476 - accuracy: 0.9915\n",
      "Epoch 1692/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9916\n",
      "Epoch 01692: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0439 - accuracy: 0.9916\n",
      "Epoch 1693/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9919\n",
      "Epoch 01693: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 981ms/step - loss: 0.0435 - accuracy: 0.9919\n",
      "Epoch 1694/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9917\n",
      "Epoch 01694: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0457 - accuracy: 0.9917\n",
      "Epoch 1695/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9916\n",
      "Epoch 01695: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0465 - accuracy: 0.9916\n",
      "Epoch 1696/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9918\n",
      "Epoch 01696: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0440 - accuracy: 0.9918\n",
      "Epoch 1697/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9914\n",
      "Epoch 01697: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0464 - accuracy: 0.9914\n",
      "Epoch 1698/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9917\n",
      "Epoch 01698: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0440 - accuracy: 0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1699/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9916\n",
      "Epoch 01699: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0456 - accuracy: 0.9916\n",
      "Epoch 1700/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9913\n",
      "Epoch 01700: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 983ms/step - loss: 0.0448 - accuracy: 0.9913\n",
      "Epoch 1701/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9918\n",
      "Epoch 01701: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 983ms/step - loss: 0.0453 - accuracy: 0.9918\n",
      "Epoch 1702/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9914\n",
      "Epoch 01702: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0449 - accuracy: 0.9914\n",
      "Epoch 1703/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9916\n",
      "Epoch 01703: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 994ms/step - loss: 0.0457 - accuracy: 0.9916\n",
      "Epoch 1704/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9917\n",
      "Epoch 01704: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 986ms/step - loss: 0.0464 - accuracy: 0.9917\n",
      "Epoch 1705/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9920\n",
      "Epoch 01705: loss did not improve from 0.04316\n",
      "2/2 [==============================] - 2s 980ms/step - loss: 0.0456 - accuracy: 0.9920\n",
      "Epoch 1706/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9917\n",
      "Epoch 01706: loss improved from 0.04316 to 0.04282, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1706.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0428 - accuracy: 0.9917\n",
      "Epoch 1707/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9918\n",
      "Epoch 01707: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0440 - accuracy: 0.9918\n",
      "Epoch 1708/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9920\n",
      "Epoch 01708: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0447 - accuracy: 0.9920\n",
      "Epoch 1709/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9914\n",
      "Epoch 01709: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0454 - accuracy: 0.9914\n",
      "Epoch 1710/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9918\n",
      "Epoch 01710: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0450 - accuracy: 0.9918\n",
      "Epoch 1711/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9917\n",
      "Epoch 01711: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0464 - accuracy: 0.9917\n",
      "Epoch 1712/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9918\n",
      "Epoch 01712: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 980ms/step - loss: 0.0443 - accuracy: 0.9918\n",
      "Epoch 1713/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9917\n",
      "Epoch 01713: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0449 - accuracy: 0.9917\n",
      "Epoch 1714/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9919\n",
      "Epoch 01714: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 989ms/step - loss: 0.0428 - accuracy: 0.9919\n",
      "Epoch 1715/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9919\n",
      "Epoch 01715: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0433 - accuracy: 0.9919\n",
      "Epoch 1716/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9914\n",
      "Epoch 01716: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 986ms/step - loss: 0.0467 - accuracy: 0.9914\n",
      "Epoch 1717/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9917\n",
      "Epoch 01717: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0445 - accuracy: 0.9917\n",
      "Epoch 1718/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9917\n",
      "Epoch 01718: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0447 - accuracy: 0.9917\n",
      "Epoch 1719/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9919\n",
      "Epoch 01719: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 980ms/step - loss: 0.0448 - accuracy: 0.9919\n",
      "Epoch 1720/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9918\n",
      "Epoch 01720: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0440 - accuracy: 0.9918\n",
      "Epoch 1721/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9916\n",
      "Epoch 01721: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 981ms/step - loss: 0.0445 - accuracy: 0.9916\n",
      "Epoch 1722/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9919\n",
      "Epoch 01722: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 997ms/step - loss: 0.0440 - accuracy: 0.9919\n",
      "Epoch 1723/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9920\n",
      "Epoch 01723: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 993ms/step - loss: 0.0447 - accuracy: 0.9920\n",
      "Epoch 1724/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9919\n",
      "Epoch 01724: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 992ms/step - loss: 0.0444 - accuracy: 0.9919\n",
      "Epoch 1725/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9918\n",
      "Epoch 01725: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 987ms/step - loss: 0.0445 - accuracy: 0.9918\n",
      "Epoch 1726/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9916\n",
      "Epoch 01726: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 986ms/step - loss: 0.0430 - accuracy: 0.9916\n",
      "Epoch 1727/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9918\n",
      "Epoch 01727: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0437 - accuracy: 0.9918\n",
      "Epoch 1728/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9922\n",
      "Epoch 01728: loss did not improve from 0.04282\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0432 - accuracy: 0.9922\n",
      "Epoch 1729/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9920\n",
      "Epoch 01729: loss improved from 0.04282 to 0.04245, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1729.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0424 - accuracy: 0.9920\n",
      "Epoch 1730/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9921\n",
      "Epoch 01730: loss did not improve from 0.04245\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0449 - accuracy: 0.9921\n",
      "Epoch 1731/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9920\n",
      "Epoch 01731: loss did not improve from 0.04245\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0444 - accuracy: 0.9920\n",
      "Epoch 1732/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9919\n",
      "Epoch 01732: loss did not improve from 0.04245\n",
      "2/2 [==============================] - 2s 987ms/step - loss: 0.0440 - accuracy: 0.9919\n",
      "Epoch 1733/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9922\n",
      "Epoch 01733: loss did not improve from 0.04245\n",
      "2/2 [==============================] - 2s 991ms/step - loss: 0.0432 - accuracy: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1734/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9923\n",
      "Epoch 01734: loss did not improve from 0.04245\n",
      "2/2 [==============================] - 2s 980ms/step - loss: 0.0430 - accuracy: 0.9923\n",
      "Epoch 1735/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9920\n",
      "Epoch 01735: loss did not improve from 0.04245\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0426 - accuracy: 0.9920\n",
      "Epoch 1736/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9921\n",
      "Epoch 01736: loss did not improve from 0.04245\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0431 - accuracy: 0.9921\n",
      "Epoch 1737/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9921\n",
      "Epoch 01737: loss did not improve from 0.04245\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0438 - accuracy: 0.9921\n",
      "Epoch 1738/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9919\n",
      "Epoch 01738: loss did not improve from 0.04245\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0430 - accuracy: 0.9919\n",
      "Epoch 1739/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9917\n",
      "Epoch 01739: loss did not improve from 0.04245\n",
      "2/2 [==============================] - 2s 981ms/step - loss: 0.0439 - accuracy: 0.9917\n",
      "Epoch 1740/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9919\n",
      "Epoch 01740: loss improved from 0.04245 to 0.04208, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1740.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0421 - accuracy: 0.9919\n",
      "Epoch 1741/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9918\n",
      "Epoch 01741: loss did not improve from 0.04208\n",
      "2/2 [==============================] - 7s 5s/step - loss: 0.0428 - accuracy: 0.9918\n",
      "Epoch 1742/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9915\n",
      "Epoch 01742: loss did not improve from 0.04208\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0452 - accuracy: 0.9915\n",
      "Epoch 1743/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9922\n",
      "Epoch 01743: loss improved from 0.04208 to 0.04134, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1743.ckpt\n",
      "2/2 [==============================] - 4s 3s/step - loss: 0.0413 - accuracy: 0.9922\n",
      "Epoch 1744/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9919\n",
      "Epoch 01744: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 6s 971ms/step - loss: 0.0435 - accuracy: 0.9919\n",
      "Epoch 1745/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9921\n",
      "Epoch 01745: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0438 - accuracy: 0.9921\n",
      "Epoch 1746/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9919\n",
      "Epoch 01746: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0450 - accuracy: 0.9919\n",
      "Epoch 1747/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9922\n",
      "Epoch 01747: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0434 - accuracy: 0.9922\n",
      "Epoch 1748/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9918\n",
      "Epoch 01748: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 6s 1s/step - loss: 0.0433 - accuracy: 0.9918\n",
      "Epoch 1749/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9917\n",
      "Epoch 01749: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0446 - accuracy: 0.9917\n",
      "Epoch 1750/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9921\n",
      "Epoch 01750: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.0419 - accuracy: 0.9921\n",
      "Epoch 1751/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9917\n",
      "Epoch 01751: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 2s 994ms/step - loss: 0.0437 - accuracy: 0.9917\n",
      "Epoch 1752/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9922\n",
      "Epoch 01752: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 7s 6s/step - loss: 0.0422 - accuracy: 0.9922\n",
      "Epoch 1753/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9920\n",
      "Epoch 01753: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0442 - accuracy: 0.9920\n",
      "Epoch 1754/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9918\n",
      "Epoch 01754: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 2s 956ms/step - loss: 0.0442 - accuracy: 0.9918\n",
      "Epoch 1755/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9918\n",
      "Epoch 01755: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0440 - accuracy: 0.9918\n",
      "Epoch 1756/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9918\n",
      "Epoch 01756: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0452 - accuracy: 0.9918\n",
      "Epoch 1757/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9917\n",
      "Epoch 01757: loss did not improve from 0.04134\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0453 - accuracy: 0.9917\n",
      "Epoch 1758/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9922\n",
      "Epoch 01758: loss improved from 0.04134 to 0.04069, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1758.ckpt\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.0407 - accuracy: 0.9922\n",
      "Epoch 1759/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9922\n",
      "Epoch 01759: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0417 - accuracy: 0.9922\n",
      "Epoch 1760/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9921\n",
      "Epoch 01760: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 961ms/step - loss: 0.0428 - accuracy: 0.9921\n",
      "Epoch 1761/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9920\n",
      "Epoch 01761: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 953ms/step - loss: 0.0434 - accuracy: 0.9920\n",
      "Epoch 1762/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9922\n",
      "Epoch 01762: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0422 - accuracy: 0.9922\n",
      "Epoch 1763/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9920\n",
      "Epoch 01763: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0433 - accuracy: 0.9920\n",
      "Epoch 1764/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9919\n",
      "Epoch 01764: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0437 - accuracy: 0.9919\n",
      "Epoch 1765/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9921\n",
      "Epoch 01765: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0430 - accuracy: 0.9921\n",
      "Epoch 1766/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9917\n",
      "Epoch 01766: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0446 - accuracy: 0.9917\n",
      "Epoch 1767/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9923\n",
      "Epoch 01767: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0414 - accuracy: 0.9923\n",
      "Epoch 1768/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9919\n",
      "Epoch 01768: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0427 - accuracy: 0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1769/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9920\n",
      "Epoch 01769: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0434 - accuracy: 0.9920\n",
      "Epoch 1770/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9919\n",
      "Epoch 01770: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0423 - accuracy: 0.9919\n",
      "Epoch 1771/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9921\n",
      "Epoch 01771: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0415 - accuracy: 0.9921\n",
      "Epoch 1772/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9920\n",
      "Epoch 01772: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0426 - accuracy: 0.9920\n",
      "Epoch 1773/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9918\n",
      "Epoch 01773: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0440 - accuracy: 0.9918\n",
      "Epoch 1774/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9919\n",
      "Epoch 01774: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0426 - accuracy: 0.9919\n",
      "Epoch 1775/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9920\n",
      "Epoch 01775: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0419 - accuracy: 0.9920\n",
      "Epoch 1776/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9920\n",
      "Epoch 01776: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0422 - accuracy: 0.9920\n",
      "Epoch 1777/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9919\n",
      "Epoch 01777: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 6s 1s/step - loss: 0.0426 - accuracy: 0.9919\n",
      "Epoch 1778/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9920\n",
      "Epoch 01778: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 989ms/step - loss: 0.0423 - accuracy: 0.9920\n",
      "Epoch 1779/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9917\n",
      "Epoch 01779: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 6s 5s/step - loss: 0.0438 - accuracy: 0.9917\n",
      "Epoch 1780/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9921\n",
      "Epoch 01780: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 6s 971ms/step - loss: 0.0420 - accuracy: 0.9921\n",
      "Epoch 1781/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9919\n",
      "Epoch 01781: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 986ms/step - loss: 0.0438 - accuracy: 0.9919\n",
      "Epoch 1782/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9916\n",
      "Epoch 01782: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 6s 5s/step - loss: 0.0433 - accuracy: 0.9916\n",
      "Epoch 1783/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9918\n",
      "Epoch 01783: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0432 - accuracy: 0.9918\n",
      "Epoch 1784/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9917\n",
      "Epoch 01784: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 960ms/step - loss: 0.0443 - accuracy: 0.9917\n",
      "Epoch 1785/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9916\n",
      "Epoch 01785: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0443 - accuracy: 0.9916\n",
      "Epoch 1786/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9920\n",
      "Epoch 01786: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0426 - accuracy: 0.9920\n",
      "Epoch 1787/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9922\n",
      "Epoch 01787: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0428 - accuracy: 0.9922\n",
      "Epoch 1788/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9918\n",
      "Epoch 01788: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0441 - accuracy: 0.9918\n",
      "Epoch 1789/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9920\n",
      "Epoch 01789: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0437 - accuracy: 0.9920\n",
      "Epoch 1790/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9917\n",
      "Epoch 01790: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0437 - accuracy: 0.9917\n",
      "Epoch 1791/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9917\n",
      "Epoch 01791: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0437 - accuracy: 0.9917\n",
      "Epoch 1792/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9918\n",
      "Epoch 01792: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0437 - accuracy: 0.9918\n",
      "Epoch 1793/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9920\n",
      "Epoch 01793: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 986ms/step - loss: 0.0426 - accuracy: 0.9920\n",
      "Epoch 1794/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9919\n",
      "Epoch 01794: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0430 - accuracy: 0.9919\n",
      "Epoch 1795/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9921\n",
      "Epoch 01795: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0424 - accuracy: 0.9921\n",
      "Epoch 1796/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9921\n",
      "Epoch 01796: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0438 - accuracy: 0.9921\n",
      "Epoch 1797/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9922\n",
      "Epoch 01797: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0428 - accuracy: 0.9922\n",
      "Epoch 1798/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9922\n",
      "Epoch 01798: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0418 - accuracy: 0.9922\n",
      "Epoch 1799/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9920\n",
      "Epoch 01799: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 984ms/step - loss: 0.0432 - accuracy: 0.9920\n",
      "Epoch 1800/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9921\n",
      "Epoch 01800: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0425 - accuracy: 0.9921\n",
      "Epoch 1801/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9920\n",
      "Epoch 01801: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0434 - accuracy: 0.9920\n",
      "Epoch 1802/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9919\n",
      "Epoch 01802: loss did not improve from 0.04069\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0434 - accuracy: 0.9919\n",
      "Epoch 1803/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9920\n",
      "Epoch 01803: loss improved from 0.04069 to 0.04012, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1803.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0401 - accuracy: 0.9920\n",
      "Epoch 1804/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9919\n",
      "Epoch 01804: loss did not improve from 0.04012\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0432 - accuracy: 0.9919\n",
      "Epoch 1805/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9919\n",
      "Epoch 01805: loss did not improve from 0.04012\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0416 - accuracy: 0.9919\n",
      "Epoch 1806/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9921\n",
      "Epoch 01806: loss did not improve from 0.04012\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0420 - accuracy: 0.9921\n",
      "Epoch 1807/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9919\n",
      "Epoch 01807: loss did not improve from 0.04012\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0421 - accuracy: 0.9919\n",
      "Epoch 1808/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9920\n",
      "Epoch 01808: loss did not improve from 0.04012\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0420 - accuracy: 0.9920\n",
      "Epoch 1809/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9921\n",
      "Epoch 01809: loss did not improve from 0.04012\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0422 - accuracy: 0.9921\n",
      "Epoch 1810/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9921\n",
      "Epoch 01810: loss did not improve from 0.04012\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0422 - accuracy: 0.9921\n",
      "Epoch 1811/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9920\n",
      "Epoch 01811: loss did not improve from 0.04012\n",
      "2/2 [==============================] - 2s 984ms/step - loss: 0.0437 - accuracy: 0.9920\n",
      "Epoch 1812/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9920\n",
      "Epoch 01812: loss did not improve from 0.04012\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0412 - accuracy: 0.9920\n",
      "Epoch 1813/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9924\n",
      "Epoch 01813: loss improved from 0.04012 to 0.03987, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1813.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0399 - accuracy: 0.9924\n",
      "Epoch 1814/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9922\n",
      "Epoch 01814: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0413 - accuracy: 0.9922\n",
      "Epoch 1815/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9924\n",
      "Epoch 01815: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0403 - accuracy: 0.9924\n",
      "Epoch 1816/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9918\n",
      "Epoch 01816: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0428 - accuracy: 0.9918\n",
      "Epoch 1817/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9921\n",
      "Epoch 01817: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0426 - accuracy: 0.9921\n",
      "Epoch 1818/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9919\n",
      "Epoch 01818: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0418 - accuracy: 0.9919\n",
      "Epoch 1819/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9922\n",
      "Epoch 01819: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0418 - accuracy: 0.9922\n",
      "Epoch 1820/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9921\n",
      "Epoch 01820: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0405 - accuracy: 0.9921\n",
      "Epoch 1821/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9925\n",
      "Epoch 01821: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0401 - accuracy: 0.9925\n",
      "Epoch 1822/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9919\n",
      "Epoch 01822: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0410 - accuracy: 0.9919\n",
      "Epoch 1823/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9922\n",
      "Epoch 01823: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 958ms/step - loss: 0.0423 - accuracy: 0.9922\n",
      "Epoch 1824/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9922\n",
      "Epoch 01824: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0424 - accuracy: 0.9922\n",
      "Epoch 1825/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9923\n",
      "Epoch 01825: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0428 - accuracy: 0.9923\n",
      "Epoch 1826/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9923\n",
      "Epoch 01826: loss did not improve from 0.03987\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0425 - accuracy: 0.9923\n",
      "Epoch 1827/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9924\n",
      "Epoch 01827: loss improved from 0.03987 to 0.03954, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1827.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0395 - accuracy: 0.9924\n",
      "Epoch 1828/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9924\n",
      "Epoch 01828: loss did not improve from 0.03954\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0409 - accuracy: 0.9924\n",
      "Epoch 1829/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9921\n",
      "Epoch 01829: loss did not improve from 0.03954\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0417 - accuracy: 0.9921\n",
      "Epoch 1830/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9923\n",
      "Epoch 01830: loss did not improve from 0.03954\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0415 - accuracy: 0.9923\n",
      "Epoch 1831/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9921\n",
      "Epoch 01831: loss did not improve from 0.03954\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0409 - accuracy: 0.9921\n",
      "Epoch 1832/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9924\n",
      "Epoch 01832: loss did not improve from 0.03954\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0417 - accuracy: 0.9924\n",
      "Epoch 1833/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9921\n",
      "Epoch 01833: loss did not improve from 0.03954\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0418 - accuracy: 0.9921\n",
      "Epoch 1834/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9920\n",
      "Epoch 01834: loss did not improve from 0.03954\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0416 - accuracy: 0.9920\n",
      "Epoch 1835/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9925\n",
      "Epoch 01835: loss improved from 0.03954 to 0.03926, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1835.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0393 - accuracy: 0.9925\n",
      "Epoch 1836/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9920\n",
      "Epoch 01836: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0399 - accuracy: 0.9920\n",
      "Epoch 1837/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9922\n",
      "Epoch 01837: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0409 - accuracy: 0.9922\n",
      "Epoch 1838/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9919\n",
      "Epoch 01838: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0414 - accuracy: 0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1839/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9922\n",
      "Epoch 01839: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0400 - accuracy: 0.9922\n",
      "Epoch 1840/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9921\n",
      "Epoch 01840: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0407 - accuracy: 0.9921\n",
      "Epoch 1841/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9924\n",
      "Epoch 01841: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0399 - accuracy: 0.9924\n",
      "Epoch 1842/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9922\n",
      "Epoch 01842: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0406 - accuracy: 0.9922\n",
      "Epoch 1843/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9921\n",
      "Epoch 01843: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0407 - accuracy: 0.9921\n",
      "Epoch 1844/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9921\n",
      "Epoch 01844: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0410 - accuracy: 0.9921\n",
      "Epoch 1845/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9923\n",
      "Epoch 01845: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0403 - accuracy: 0.9923\n",
      "Epoch 1846/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9924\n",
      "Epoch 01846: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0406 - accuracy: 0.9924\n",
      "Epoch 1847/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9924\n",
      "Epoch 01847: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0406 - accuracy: 0.9924\n",
      "Epoch 1848/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9923\n",
      "Epoch 01848: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0405 - accuracy: 0.9923\n",
      "Epoch 1849/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9924\n",
      "Epoch 01849: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0401 - accuracy: 0.9924\n",
      "Epoch 1850/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9925\n",
      "Epoch 01850: loss did not improve from 0.03926\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0408 - accuracy: 0.9925\n",
      "Epoch 1851/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9927\n",
      "Epoch 01851: loss improved from 0.03926 to 0.03797, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1851.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0380 - accuracy: 0.9927\n",
      "Epoch 1852/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9925\n",
      "Epoch 01852: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0391 - accuracy: 0.9925\n",
      "Epoch 1853/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9919\n",
      "Epoch 01853: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0426 - accuracy: 0.9919\n",
      "Epoch 1854/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9922\n",
      "Epoch 01854: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0403 - accuracy: 0.9922\n",
      "Epoch 1855/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9927\n",
      "Epoch 01855: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0401 - accuracy: 0.9927\n",
      "Epoch 1856/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9922\n",
      "Epoch 01856: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0418 - accuracy: 0.9922\n",
      "Epoch 1857/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9923\n",
      "Epoch 01857: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0400 - accuracy: 0.9923\n",
      "Epoch 1858/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9923\n",
      "Epoch 01858: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0396 - accuracy: 0.9923\n",
      "Epoch 1859/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9923\n",
      "Epoch 01859: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0412 - accuracy: 0.9923\n",
      "Epoch 1860/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9925\n",
      "Epoch 01860: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0399 - accuracy: 0.9925\n",
      "Epoch 1861/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9925\n",
      "Epoch 01861: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0408 - accuracy: 0.9925\n",
      "Epoch 1862/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9922\n",
      "Epoch 01862: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0391 - accuracy: 0.9922\n",
      "Epoch 1863/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9924\n",
      "Epoch 01863: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0388 - accuracy: 0.9924\n",
      "Epoch 1864/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9925\n",
      "Epoch 01864: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0390 - accuracy: 0.9925\n",
      "Epoch 1865/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9923\n",
      "Epoch 01865: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0404 - accuracy: 0.9923\n",
      "Epoch 1866/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9922\n",
      "Epoch 01866: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0411 - accuracy: 0.9922\n",
      "Epoch 1867/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9925\n",
      "Epoch 01867: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0394 - accuracy: 0.9925\n",
      "Epoch 1868/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9925\n",
      "Epoch 01868: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0404 - accuracy: 0.9925\n",
      "Epoch 1869/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9925\n",
      "Epoch 01869: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0391 - accuracy: 0.9925\n",
      "Epoch 1870/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9923\n",
      "Epoch 01870: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0408 - accuracy: 0.9923\n",
      "Epoch 1871/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9923\n",
      "Epoch 01871: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0405 - accuracy: 0.9923\n",
      "Epoch 1872/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9923\n",
      "Epoch 01872: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0399 - accuracy: 0.9923\n",
      "Epoch 1873/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9926\n",
      "Epoch 01873: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0409 - accuracy: 0.9926\n",
      "Epoch 1874/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9925\n",
      "Epoch 01874: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0399 - accuracy: 0.9925\n",
      "Epoch 1875/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9923\n",
      "Epoch 01875: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0415 - accuracy: 0.9923\n",
      "Epoch 1876/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9922\n",
      "Epoch 01876: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0409 - accuracy: 0.9922\n",
      "Epoch 1877/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9926\n",
      "Epoch 01877: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0398 - accuracy: 0.9926\n",
      "Epoch 1878/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9922\n",
      "Epoch 01878: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0408 - accuracy: 0.9922\n",
      "Epoch 1879/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9926\n",
      "Epoch 01879: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0407 - accuracy: 0.9926\n",
      "Epoch 1880/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9923\n",
      "Epoch 01880: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0395 - accuracy: 0.9923\n",
      "Epoch 1881/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9923\n",
      "Epoch 01881: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0408 - accuracy: 0.9923\n",
      "Epoch 1882/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9923\n",
      "Epoch 01882: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0408 - accuracy: 0.9923\n",
      "Epoch 1883/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9923\n",
      "Epoch 01883: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0392 - accuracy: 0.9923\n",
      "Epoch 1884/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9923\n",
      "Epoch 01884: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0394 - accuracy: 0.9923\n",
      "Epoch 1885/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9925\n",
      "Epoch 01885: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0409 - accuracy: 0.9925\n",
      "Epoch 1886/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9921\n",
      "Epoch 01886: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0416 - accuracy: 0.9921\n",
      "Epoch 1887/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9925\n",
      "Epoch 01887: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0394 - accuracy: 0.9925\n",
      "Epoch 1888/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9924\n",
      "Epoch 01888: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0399 - accuracy: 0.9924\n",
      "Epoch 1889/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9927\n",
      "Epoch 01889: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0404 - accuracy: 0.9927\n",
      "Epoch 1890/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9923\n",
      "Epoch 01890: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0395 - accuracy: 0.9923\n",
      "Epoch 1891/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9924\n",
      "Epoch 01891: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0394 - accuracy: 0.9924\n",
      "Epoch 1892/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9925\n",
      "Epoch 01892: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0383 - accuracy: 0.9925\n",
      "Epoch 1893/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9925\n",
      "Epoch 01893: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 992ms/step - loss: 0.0389 - accuracy: 0.9925\n",
      "Epoch 1894/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9924\n",
      "Epoch 01894: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0393 - accuracy: 0.9924\n",
      "Epoch 1895/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9923\n",
      "Epoch 01895: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0423 - accuracy: 0.9923\n",
      "Epoch 1896/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9924\n",
      "Epoch 01896: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0389 - accuracy: 0.9924\n",
      "Epoch 1897/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9925\n",
      "Epoch 01897: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 990ms/step - loss: 0.0400 - accuracy: 0.9925\n",
      "Epoch 1898/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9926\n",
      "Epoch 01898: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 961ms/step - loss: 0.0382 - accuracy: 0.9926\n",
      "Epoch 1899/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9923\n",
      "Epoch 01899: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 987ms/step - loss: 0.0400 - accuracy: 0.9923\n",
      "Epoch 1900/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9928\n",
      "Epoch 01900: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0402 - accuracy: 0.9928\n",
      "Epoch 1901/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9924\n",
      "Epoch 01901: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0380 - accuracy: 0.9924\n",
      "Epoch 1902/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9922\n",
      "Epoch 01902: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0406 - accuracy: 0.9922\n",
      "Epoch 1903/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9925\n",
      "Epoch 01903: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0385 - accuracy: 0.9925\n",
      "Epoch 1904/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9925\n",
      "Epoch 01904: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0391 - accuracy: 0.9925\n",
      "Epoch 1905/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9924\n",
      "Epoch 01905: loss did not improve from 0.03797\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0399 - accuracy: 0.9924\n",
      "Epoch 1906/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9927\n",
      "Epoch 01906: loss improved from 0.03797 to 0.03748, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1906.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0375 - accuracy: 0.9927\n",
      "Epoch 1907/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9924\n",
      "Epoch 01907: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 961ms/step - loss: 0.0395 - accuracy: 0.9924\n",
      "Epoch 1908/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9927\n",
      "Epoch 01908: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0397 - accuracy: 0.9927\n",
      "Epoch 1909/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9923\n",
      "Epoch 01909: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0411 - accuracy: 0.9923\n",
      "Epoch 1910/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9925\n",
      "Epoch 01910: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0390 - accuracy: 0.9925\n",
      "Epoch 1911/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9925\n",
      "Epoch 01911: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0391 - accuracy: 0.9925\n",
      "Epoch 1912/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9926\n",
      "Epoch 01912: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0381 - accuracy: 0.9926\n",
      "Epoch 1913/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9925\n",
      "Epoch 01913: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0390 - accuracy: 0.9925\n",
      "Epoch 1914/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9922\n",
      "Epoch 01914: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0395 - accuracy: 0.9922\n",
      "Epoch 1915/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9927\n",
      "Epoch 01915: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0387 - accuracy: 0.9927\n",
      "Epoch 1916/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9926\n",
      "Epoch 01916: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0382 - accuracy: 0.9926\n",
      "Epoch 1917/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9924\n",
      "Epoch 01917: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0400 - accuracy: 0.9924\n",
      "Epoch 1918/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9925\n",
      "Epoch 01918: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0383 - accuracy: 0.9925\n",
      "Epoch 1919/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9923\n",
      "Epoch 01919: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0391 - accuracy: 0.9923\n",
      "Epoch 1920/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9924\n",
      "Epoch 01920: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0388 - accuracy: 0.9924\n",
      "Epoch 1921/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9926\n",
      "Epoch 01921: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0378 - accuracy: 0.9926\n",
      "Epoch 1922/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9926\n",
      "Epoch 01922: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0379 - accuracy: 0.9926\n",
      "Epoch 1923/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9924\n",
      "Epoch 01923: loss did not improve from 0.03748\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0409 - accuracy: 0.9924\n",
      "Epoch 1924/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9923\n",
      "Epoch 01924: loss improved from 0.03748 to 0.03740, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1924.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0374 - accuracy: 0.9923\n",
      "Epoch 1925/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9926\n",
      "Epoch 01925: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0398 - accuracy: 0.9926\n",
      "Epoch 1926/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9927\n",
      "Epoch 01926: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0389 - accuracy: 0.9927\n",
      "Epoch 1927/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9927\n",
      "Epoch 01927: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0388 - accuracy: 0.9927\n",
      "Epoch 1928/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9926\n",
      "Epoch 01928: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0387 - accuracy: 0.9926\n",
      "Epoch 1929/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9925\n",
      "Epoch 01929: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0392 - accuracy: 0.9925\n",
      "Epoch 1930/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9927\n",
      "Epoch 01930: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0379 - accuracy: 0.9927\n",
      "Epoch 1931/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9923\n",
      "Epoch 01931: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0406 - accuracy: 0.9923\n",
      "Epoch 1932/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9923\n",
      "Epoch 01932: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0383 - accuracy: 0.9923\n",
      "Epoch 1933/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9922\n",
      "Epoch 01933: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 961ms/step - loss: 0.0391 - accuracy: 0.9922\n",
      "Epoch 1934/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9923\n",
      "Epoch 01934: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0376 - accuracy: 0.9923\n",
      "Epoch 1935/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9924\n",
      "Epoch 01935: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0390 - accuracy: 0.9924\n",
      "Epoch 1936/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9925\n",
      "Epoch 01936: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0384 - accuracy: 0.9925\n",
      "Epoch 1937/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9925\n",
      "Epoch 01937: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0380 - accuracy: 0.9925\n",
      "Epoch 1938/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9927\n",
      "Epoch 01938: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0384 - accuracy: 0.9927\n",
      "Epoch 1939/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9924\n",
      "Epoch 01939: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0391 - accuracy: 0.9924\n",
      "Epoch 1940/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9928\n",
      "Epoch 01940: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0374 - accuracy: 0.9928\n",
      "Epoch 1941/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9927\n",
      "Epoch 01941: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0384 - accuracy: 0.9927\n",
      "Epoch 1942/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9925\n",
      "Epoch 01942: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0387 - accuracy: 0.9925\n",
      "Epoch 1943/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9926\n",
      "Epoch 01943: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0383 - accuracy: 0.9926\n",
      "Epoch 1944/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9924\n",
      "Epoch 01944: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0385 - accuracy: 0.9924\n",
      "Epoch 1945/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9924\n",
      "Epoch 01945: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0381 - accuracy: 0.9924\n",
      "Epoch 1946/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9921\n",
      "Epoch 01946: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0387 - accuracy: 0.9921\n",
      "Epoch 1947/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9926\n",
      "Epoch 01947: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0392 - accuracy: 0.9926\n",
      "Epoch 1948/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9925\n",
      "Epoch 01948: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0402 - accuracy: 0.9925\n",
      "Epoch 1949/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9925\n",
      "Epoch 01949: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0382 - accuracy: 0.9925\n",
      "Epoch 1950/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9924\n",
      "Epoch 01950: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0416 - accuracy: 0.9924\n",
      "Epoch 1951/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9925\n",
      "Epoch 01951: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0386 - accuracy: 0.9925\n",
      "Epoch 1952/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9924\n",
      "Epoch 01952: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0397 - accuracy: 0.9924\n",
      "Epoch 1953/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9926\n",
      "Epoch 01953: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0378 - accuracy: 0.9926\n",
      "Epoch 1954/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9924\n",
      "Epoch 01954: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0398 - accuracy: 0.9924\n",
      "Epoch 1955/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9926\n",
      "Epoch 01955: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0393 - accuracy: 0.9926\n",
      "Epoch 1956/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9923\n",
      "Epoch 01956: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0392 - accuracy: 0.9923\n",
      "Epoch 1957/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9927\n",
      "Epoch 01957: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0384 - accuracy: 0.9927\n",
      "Epoch 1958/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9924\n",
      "Epoch 01958: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0390 - accuracy: 0.9924\n",
      "Epoch 1959/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9925\n",
      "Epoch 01959: loss did not improve from 0.03740\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0401 - accuracy: 0.9925\n",
      "Epoch 1960/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9928\n",
      "Epoch 01960: loss improved from 0.03740 to 0.03707, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1960.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0371 - accuracy: 0.9928\n",
      "Epoch 1961/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9927\n",
      "Epoch 01961: loss did not improve from 0.03707\n",
      "2/2 [==============================] - 2s 962ms/step - loss: 0.0374 - accuracy: 0.9927\n",
      "Epoch 1962/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9925\n",
      "Epoch 01962: loss did not improve from 0.03707\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0389 - accuracy: 0.9925\n",
      "Epoch 1963/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9925\n",
      "Epoch 01963: loss did not improve from 0.03707\n",
      "2/2 [==============================] - 2s 962ms/step - loss: 0.0391 - accuracy: 0.9925\n",
      "Epoch 1964/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9926\n",
      "Epoch 01964: loss did not improve from 0.03707\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0379 - accuracy: 0.9926\n",
      "Epoch 1965/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9926\n",
      "Epoch 01965: loss did not improve from 0.03707\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0385 - accuracy: 0.9926\n",
      "Epoch 1966/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9925\n",
      "Epoch 01966: loss did not improve from 0.03707\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0381 - accuracy: 0.9925\n",
      "Epoch 1967/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9926\n",
      "Epoch 01967: loss did not improve from 0.03707\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0391 - accuracy: 0.9926\n",
      "Epoch 1968/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9926\n",
      "Epoch 01968: loss did not improve from 0.03707\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0386 - accuracy: 0.9926\n",
      "Epoch 1969/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9924\n",
      "Epoch 01969: loss did not improve from 0.03707\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0384 - accuracy: 0.9924\n",
      "Epoch 1970/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9928\n",
      "Epoch 01970: loss improved from 0.03707 to 0.03686, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1970.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0369 - accuracy: 0.9928\n",
      "Epoch 1971/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9927\n",
      "Epoch 01971: loss did not improve from 0.03686\n",
      "2/2 [==============================] - 2s 959ms/step - loss: 0.0386 - accuracy: 0.9927\n",
      "Epoch 1972/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9926\n",
      "Epoch 01972: loss did not improve from 0.03686\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0384 - accuracy: 0.9926\n",
      "Epoch 1973/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9927\n",
      "Epoch 01973: loss did not improve from 0.03686\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0384 - accuracy: 0.9927\n",
      "Epoch 1974/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9928\n",
      "Epoch 01974: loss improved from 0.03686 to 0.03661, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1974.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0366 - accuracy: 0.9928\n",
      "Epoch 1975/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9929\n",
      "Epoch 01975: loss improved from 0.03661 to 0.03593, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1975.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0359 - accuracy: 0.9929\n",
      "Epoch 1976/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9928\n",
      "Epoch 01976: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0365 - accuracy: 0.9928\n",
      "Epoch 1977/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9929\n",
      "Epoch 01977: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0380 - accuracy: 0.9929\n",
      "Epoch 1978/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9926\n",
      "Epoch 01978: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0371 - accuracy: 0.9926\n",
      "Epoch 1979/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9927\n",
      "Epoch 01979: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0375 - accuracy: 0.9927\n",
      "Epoch 1980/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9929\n",
      "Epoch 01980: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0378 - accuracy: 0.9929\n",
      "Epoch 1981/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9927\n",
      "Epoch 01981: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0364 - accuracy: 0.9927\n",
      "Epoch 1982/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9927\n",
      "Epoch 01982: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0376 - accuracy: 0.9927\n",
      "Epoch 1983/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9929\n",
      "Epoch 01983: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0364 - accuracy: 0.9929\n",
      "Epoch 1984/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9928\n",
      "Epoch 01984: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0373 - accuracy: 0.9928\n",
      "Epoch 1985/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9928\n",
      "Epoch 01985: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 960ms/step - loss: 0.0380 - accuracy: 0.9928\n",
      "Epoch 1986/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9926\n",
      "Epoch 01986: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0370 - accuracy: 0.9926\n",
      "Epoch 1987/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9926\n",
      "Epoch 01987: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0372 - accuracy: 0.9926\n",
      "Epoch 1988/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9924\n",
      "Epoch 01988: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0387 - accuracy: 0.9924\n",
      "Epoch 1989/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9925\n",
      "Epoch 01989: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0387 - accuracy: 0.9925\n",
      "Epoch 1990/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9930\n",
      "Epoch 01990: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0360 - accuracy: 0.9930\n",
      "Epoch 1991/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9928\n",
      "Epoch 01991: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0386 - accuracy: 0.9928\n",
      "Epoch 1992/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9928\n",
      "Epoch 01992: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0372 - accuracy: 0.9928\n",
      "Epoch 1993/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9928\n",
      "Epoch 01993: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0385 - accuracy: 0.9928\n",
      "Epoch 1994/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9928\n",
      "Epoch 01994: loss did not improve from 0.03593\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0375 - accuracy: 0.9928\n",
      "Epoch 1995/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9928\n",
      "Epoch 01995: loss improved from 0.03593 to 0.03589, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1995.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0359 - accuracy: 0.9928\n",
      "Epoch 1996/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9925\n",
      "Epoch 01996: loss did not improve from 0.03589\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0364 - accuracy: 0.9925\n",
      "Epoch 1997/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9929\n",
      "Epoch 01997: loss improved from 0.03589 to 0.03562, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_1997.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0356 - accuracy: 0.9929\n",
      "Epoch 1998/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9924\n",
      "Epoch 01998: loss did not improve from 0.03562\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0390 - accuracy: 0.9924\n",
      "Epoch 1999/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9929\n",
      "Epoch 01999: loss did not improve from 0.03562\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0379 - accuracy: 0.9929\n",
      "Epoch 2000/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9926\n",
      "Epoch 02000: loss did not improve from 0.03562\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0365 - accuracy: 0.9926\n",
      "Epoch 2001/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9930\n",
      "Epoch 02001: loss did not improve from 0.03562\n",
      "2/2 [==============================] - 2s 961ms/step - loss: 0.0369 - accuracy: 0.9930\n",
      "Epoch 2002/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9925\n",
      "Epoch 02002: loss did not improve from 0.03562\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0386 - accuracy: 0.9925\n",
      "Epoch 2003/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9927\n",
      "Epoch 02003: loss did not improve from 0.03562\n",
      "2/2 [==============================] - 2s 991ms/step - loss: 0.0376 - accuracy: 0.9927\n",
      "Epoch 2004/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9928\n",
      "Epoch 02004: loss did not improve from 0.03562\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0377 - accuracy: 0.9928\n",
      "Epoch 2005/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9930\n",
      "Epoch 02005: loss did not improve from 0.03562\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0366 - accuracy: 0.9930\n",
      "Epoch 2006/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9928\n",
      "Epoch 02006: loss did not improve from 0.03562\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0370 - accuracy: 0.9928\n",
      "Epoch 2007/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9929\n",
      "Epoch 02007: loss improved from 0.03562 to 0.03558, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2007.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0356 - accuracy: 0.9929\n",
      "Epoch 2008/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9927\n",
      "Epoch 02008: loss did not improve from 0.03558\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0373 - accuracy: 0.9927\n",
      "Epoch 2009/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9928\n",
      "Epoch 02009: loss did not improve from 0.03558\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0363 - accuracy: 0.9928\n",
      "Epoch 2010/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9928\n",
      "Epoch 02010: loss did not improve from 0.03558\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0361 - accuracy: 0.9928\n",
      "Epoch 2011/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9927\n",
      "Epoch 02011: loss did not improve from 0.03558\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0359 - accuracy: 0.9927\n",
      "Epoch 2012/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9931\n",
      "Epoch 02012: loss improved from 0.03558 to 0.03536, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2012.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 2s/step - loss: 0.0354 - accuracy: 0.9931\n",
      "Epoch 2013/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9931\n",
      "Epoch 02013: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0360 - accuracy: 0.9931\n",
      "Epoch 2014/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9929\n",
      "Epoch 02014: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0364 - accuracy: 0.9929\n",
      "Epoch 2015/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9929\n",
      "Epoch 02015: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0362 - accuracy: 0.9929\n",
      "Epoch 2016/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9930\n",
      "Epoch 02016: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0370 - accuracy: 0.9930\n",
      "Epoch 2017/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9926\n",
      "Epoch 02017: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0364 - accuracy: 0.9926\n",
      "Epoch 2018/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9927\n",
      "Epoch 02018: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 957ms/step - loss: 0.0364 - accuracy: 0.9927\n",
      "Epoch 2019/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9929\n",
      "Epoch 02019: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0363 - accuracy: 0.9929\n",
      "Epoch 2020/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9928\n",
      "Epoch 02020: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0363 - accuracy: 0.9928\n",
      "Epoch 2021/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9927\n",
      "Epoch 02021: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0368 - accuracy: 0.9927\n",
      "Epoch 2022/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9930\n",
      "Epoch 02022: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0364 - accuracy: 0.9930\n",
      "Epoch 2023/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9927\n",
      "Epoch 02023: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0371 - accuracy: 0.9927\n",
      "Epoch 2024/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9927\n",
      "Epoch 02024: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0372 - accuracy: 0.9927\n",
      "Epoch 2025/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9928\n",
      "Epoch 02025: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0362 - accuracy: 0.9928\n",
      "Epoch 2026/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9929\n",
      "Epoch 02026: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0371 - accuracy: 0.9929\n",
      "Epoch 2027/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9927\n",
      "Epoch 02027: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0367 - accuracy: 0.9927\n",
      "Epoch 2028/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9926\n",
      "Epoch 02028: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0368 - accuracy: 0.9926\n",
      "Epoch 2029/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9929\n",
      "Epoch 02029: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0370 - accuracy: 0.9929\n",
      "Epoch 2030/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9929\n",
      "Epoch 02030: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0362 - accuracy: 0.9929\n",
      "Epoch 2031/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9927\n",
      "Epoch 02031: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0368 - accuracy: 0.9927\n",
      "Epoch 2032/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9929\n",
      "Epoch 02032: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0373 - accuracy: 0.9929\n",
      "Epoch 2033/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9930\n",
      "Epoch 02033: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0364 - accuracy: 0.9930\n",
      "Epoch 2034/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9930\n",
      "Epoch 02034: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0364 - accuracy: 0.9930\n",
      "Epoch 2035/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9927\n",
      "Epoch 02035: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0376 - accuracy: 0.9927\n",
      "Epoch 2036/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9929\n",
      "Epoch 02036: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0363 - accuracy: 0.9929\n",
      "Epoch 2037/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9931\n",
      "Epoch 02037: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0354 - accuracy: 0.9931\n",
      "Epoch 2038/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9928\n",
      "Epoch 02038: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 981ms/step - loss: 0.0370 - accuracy: 0.9928\n",
      "Epoch 2039/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9928\n",
      "Epoch 02039: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0362 - accuracy: 0.9928\n",
      "Epoch 2040/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9929\n",
      "Epoch 02040: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0365 - accuracy: 0.9929\n",
      "Epoch 2041/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9929\n",
      "Epoch 02041: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0372 - accuracy: 0.9929\n",
      "Epoch 2042/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9929\n",
      "Epoch 02042: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0384 - accuracy: 0.9929\n",
      "Epoch 2043/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9928\n",
      "Epoch 02043: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0364 - accuracy: 0.9928\n",
      "Epoch 2044/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9928\n",
      "Epoch 02044: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0377 - accuracy: 0.9928\n",
      "Epoch 2045/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9929\n",
      "Epoch 02045: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0362 - accuracy: 0.9929\n",
      "Epoch 2046/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9925\n",
      "Epoch 02046: loss did not improve from 0.03536\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0382 - accuracy: 0.9925\n",
      "Epoch 2047/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9931\n",
      "Epoch 02047: loss improved from 0.03536 to 0.03514, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2047.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0351 - accuracy: 0.9931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2048/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9927\n",
      "Epoch 02048: loss did not improve from 0.03514\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0365 - accuracy: 0.9927\n",
      "Epoch 2049/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9932\n",
      "Epoch 02049: loss did not improve from 0.03514\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0367 - accuracy: 0.9932\n",
      "Epoch 2050/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9927\n",
      "Epoch 02050: loss improved from 0.03514 to 0.03509, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2050.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0351 - accuracy: 0.9927\n",
      "Epoch 2051/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9929\n",
      "Epoch 02051: loss did not improve from 0.03509\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0368 - accuracy: 0.9929\n",
      "Epoch 2052/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9927\n",
      "Epoch 02052: loss did not improve from 0.03509\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0361 - accuracy: 0.9927\n",
      "Epoch 2053/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9928\n",
      "Epoch 02053: loss did not improve from 0.03509\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0367 - accuracy: 0.9928\n",
      "Epoch 2054/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9930\n",
      "Epoch 02054: loss did not improve from 0.03509\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0371 - accuracy: 0.9930\n",
      "Epoch 2055/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9931\n",
      "Epoch 02055: loss did not improve from 0.03509\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0352 - accuracy: 0.9931\n",
      "Epoch 2056/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9928\n",
      "Epoch 02056: loss did not improve from 0.03509\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0367 - accuracy: 0.9928\n",
      "Epoch 2057/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9930\n",
      "Epoch 02057: loss did not improve from 0.03509\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0351 - accuracy: 0.9930\n",
      "Epoch 2058/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9931\n",
      "Epoch 02058: loss did not improve from 0.03509\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0359 - accuracy: 0.9931\n",
      "Epoch 2059/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9928\n",
      "Epoch 02059: loss did not improve from 0.03509\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0361 - accuracy: 0.9928\n",
      "Epoch 2060/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9932\n",
      "Epoch 02060: loss improved from 0.03509 to 0.03437, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2060.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0344 - accuracy: 0.9932\n",
      "Epoch 2061/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9928\n",
      "Epoch 02061: loss did not improve from 0.03437\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0377 - accuracy: 0.9928\n",
      "Epoch 2062/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9929\n",
      "Epoch 02062: loss did not improve from 0.03437\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0368 - accuracy: 0.9929\n",
      "Epoch 2063/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9932\n",
      "Epoch 02063: loss did not improve from 0.03437\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0345 - accuracy: 0.9932\n",
      "Epoch 2064/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9931\n",
      "Epoch 02064: loss did not improve from 0.03437\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0352 - accuracy: 0.9931\n",
      "Epoch 2065/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9931\n",
      "Epoch 02065: loss did not improve from 0.03437\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0348 - accuracy: 0.9931\n",
      "Epoch 2066/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9925\n",
      "Epoch 02066: loss did not improve from 0.03437\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0370 - accuracy: 0.9925\n",
      "Epoch 2067/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9930\n",
      "Epoch 02067: loss did not improve from 0.03437\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0354 - accuracy: 0.9930\n",
      "Epoch 2068/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9930\n",
      "Epoch 02068: loss improved from 0.03437 to 0.03434, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2068.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0343 - accuracy: 0.9930\n",
      "Epoch 2069/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9929\n",
      "Epoch 02069: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0357 - accuracy: 0.9929\n",
      "Epoch 2070/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9933\n",
      "Epoch 02070: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0364 - accuracy: 0.9933\n",
      "Epoch 2071/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9932\n",
      "Epoch 02071: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0366 - accuracy: 0.9932\n",
      "Epoch 2072/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9930\n",
      "Epoch 02072: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0349 - accuracy: 0.9930\n",
      "Epoch 2073/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9931\n",
      "Epoch 02073: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0351 - accuracy: 0.9931\n",
      "Epoch 2074/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9928\n",
      "Epoch 02074: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0360 - accuracy: 0.9928\n",
      "Epoch 2075/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9928\n",
      "Epoch 02075: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0370 - accuracy: 0.9928\n",
      "Epoch 2076/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9928\n",
      "Epoch 02076: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0352 - accuracy: 0.9928\n",
      "Epoch 2077/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9927\n",
      "Epoch 02077: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0369 - accuracy: 0.9927\n",
      "Epoch 2078/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9929\n",
      "Epoch 02078: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0354 - accuracy: 0.9929\n",
      "Epoch 2079/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9930\n",
      "Epoch 02079: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0360 - accuracy: 0.9930\n",
      "Epoch 2080/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9928\n",
      "Epoch 02080: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0361 - accuracy: 0.9928\n",
      "Epoch 2081/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9932\n",
      "Epoch 02081: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 962ms/step - loss: 0.0359 - accuracy: 0.9932\n",
      "Epoch 2082/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9925\n",
      "Epoch 02082: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0376 - accuracy: 0.9925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2083/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9930\n",
      "Epoch 02083: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0368 - accuracy: 0.9930\n",
      "Epoch 2084/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9930\n",
      "Epoch 02084: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0352 - accuracy: 0.9930\n",
      "Epoch 2085/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9928\n",
      "Epoch 02085: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 961ms/step - loss: 0.0373 - accuracy: 0.9928\n",
      "Epoch 2086/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9928\n",
      "Epoch 02086: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0350 - accuracy: 0.9928\n",
      "Epoch 2087/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9931\n",
      "Epoch 02087: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0348 - accuracy: 0.9931\n",
      "Epoch 2088/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9927\n",
      "Epoch 02088: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 959ms/step - loss: 0.0360 - accuracy: 0.9927\n",
      "Epoch 2089/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9929\n",
      "Epoch 02089: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0349 - accuracy: 0.9929\n",
      "Epoch 2090/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9930\n",
      "Epoch 02090: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0361 - accuracy: 0.9930\n",
      "Epoch 2091/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9930\n",
      "Epoch 02091: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0356 - accuracy: 0.9930\n",
      "Epoch 2092/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9926\n",
      "Epoch 02092: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0370 - accuracy: 0.9926\n",
      "Epoch 2093/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9931\n",
      "Epoch 02093: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0351 - accuracy: 0.9931\n",
      "Epoch 2094/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9927\n",
      "Epoch 02094: loss did not improve from 0.03434\n",
      "2/2 [==============================] - 2s 980ms/step - loss: 0.0355 - accuracy: 0.9927\n",
      "Epoch 2095/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9932\n",
      "Epoch 02095: loss improved from 0.03434 to 0.03411, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2095.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0341 - accuracy: 0.9932\n",
      "Epoch 2096/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9928\n",
      "Epoch 02096: loss did not improve from 0.03411\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0351 - accuracy: 0.9928\n",
      "Epoch 2097/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9931\n",
      "Epoch 02097: loss did not improve from 0.03411\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0353 - accuracy: 0.9931\n",
      "Epoch 2098/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9933\n",
      "Epoch 02098: loss improved from 0.03411 to 0.03284, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2098.ckpt\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.0328 - accuracy: 0.9933\n",
      "Epoch 2099/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9931\n",
      "Epoch 02099: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0347 - accuracy: 0.9931\n",
      "Epoch 2100/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9933\n",
      "Epoch 02100: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0349 - accuracy: 0.9933\n",
      "Epoch 2101/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9930\n",
      "Epoch 02101: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0358 - accuracy: 0.9930\n",
      "Epoch 2102/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9930\n",
      "Epoch 02102: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0345 - accuracy: 0.9930\n",
      "Epoch 2103/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9930\n",
      "Epoch 02103: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0346 - accuracy: 0.9930\n",
      "Epoch 2104/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9932\n",
      "Epoch 02104: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0345 - accuracy: 0.9932\n",
      "Epoch 2105/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9932\n",
      "Epoch 02105: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0340 - accuracy: 0.9932\n",
      "Epoch 2106/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9930\n",
      "Epoch 02106: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0361 - accuracy: 0.9930\n",
      "Epoch 2107/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9932\n",
      "Epoch 02107: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0348 - accuracy: 0.9932\n",
      "Epoch 2108/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9933\n",
      "Epoch 02108: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0336 - accuracy: 0.9933\n",
      "Epoch 2109/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9930\n",
      "Epoch 02109: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 989ms/step - loss: 0.0347 - accuracy: 0.9930\n",
      "Epoch 2110/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9933\n",
      "Epoch 02110: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0348 - accuracy: 0.9933\n",
      "Epoch 2111/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9933\n",
      "Epoch 02111: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0347 - accuracy: 0.9933\n",
      "Epoch 2112/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9929\n",
      "Epoch 02112: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0362 - accuracy: 0.9929\n",
      "Epoch 2113/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9929\n",
      "Epoch 02113: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0343 - accuracy: 0.9929\n",
      "Epoch 2114/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9929\n",
      "Epoch 02114: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0345 - accuracy: 0.9929\n",
      "Epoch 2115/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9929\n",
      "Epoch 02115: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0367 - accuracy: 0.9929\n",
      "Epoch 2116/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9929\n",
      "Epoch 02116: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0351 - accuracy: 0.9929\n",
      "Epoch 2117/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9935\n",
      "Epoch 02117: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0335 - accuracy: 0.9935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2118/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9930\n",
      "Epoch 02118: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0363 - accuracy: 0.9930\n",
      "Epoch 2119/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9926\n",
      "Epoch 02119: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0379 - accuracy: 0.9926\n",
      "Epoch 2120/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9930\n",
      "Epoch 02120: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 984ms/step - loss: 0.0358 - accuracy: 0.9930\n",
      "Epoch 2121/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9930\n",
      "Epoch 02121: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 981ms/step - loss: 0.0356 - accuracy: 0.9930\n",
      "Epoch 2122/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9931\n",
      "Epoch 02122: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0360 - accuracy: 0.9931\n",
      "Epoch 2123/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9930\n",
      "Epoch 02123: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0351 - accuracy: 0.9930\n",
      "Epoch 2124/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9928\n",
      "Epoch 02124: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0360 - accuracy: 0.9928\n",
      "Epoch 2125/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9929\n",
      "Epoch 02125: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0359 - accuracy: 0.9929\n",
      "Epoch 2126/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9930\n",
      "Epoch 02126: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0345 - accuracy: 0.9930\n",
      "Epoch 2127/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9931\n",
      "Epoch 02127: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0358 - accuracy: 0.9931\n",
      "Epoch 2128/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9925\n",
      "Epoch 02128: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 981ms/step - loss: 0.0373 - accuracy: 0.9925\n",
      "Epoch 2129/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9933\n",
      "Epoch 02129: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0353 - accuracy: 0.9933\n",
      "Epoch 2130/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9930\n",
      "Epoch 02130: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0363 - accuracy: 0.9930\n",
      "Epoch 2131/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9926\n",
      "Epoch 02131: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0368 - accuracy: 0.9926\n",
      "Epoch 2132/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9928\n",
      "Epoch 02132: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0357 - accuracy: 0.9928\n",
      "Epoch 2133/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9933\n",
      "Epoch 02133: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0348 - accuracy: 0.9933\n",
      "Epoch 2134/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9933\n",
      "Epoch 02134: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0337 - accuracy: 0.9933\n",
      "Epoch 2135/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9930\n",
      "Epoch 02135: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0353 - accuracy: 0.9930\n",
      "Epoch 2136/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9930\n",
      "Epoch 02136: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0352 - accuracy: 0.9930\n",
      "Epoch 2137/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9934\n",
      "Epoch 02137: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0345 - accuracy: 0.9934\n",
      "Epoch 2138/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9932\n",
      "Epoch 02138: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0351 - accuracy: 0.9932\n",
      "Epoch 2139/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9929\n",
      "Epoch 02139: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0360 - accuracy: 0.9929\n",
      "Epoch 2140/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9931\n",
      "Epoch 02140: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0349 - accuracy: 0.9931\n",
      "Epoch 2141/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9930\n",
      "Epoch 02141: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0351 - accuracy: 0.9930\n",
      "Epoch 2142/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9931\n",
      "Epoch 02142: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0335 - accuracy: 0.9931\n",
      "Epoch 2143/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9929\n",
      "Epoch 02143: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0364 - accuracy: 0.9929\n",
      "Epoch 2144/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9932\n",
      "Epoch 02144: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 981ms/step - loss: 0.0340 - accuracy: 0.9932\n",
      "Epoch 2145/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9932\n",
      "Epoch 02145: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0340 - accuracy: 0.9932\n",
      "Epoch 2146/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9927\n",
      "Epoch 02146: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0342 - accuracy: 0.9927\n",
      "Epoch 2147/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9931\n",
      "Epoch 02147: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0332 - accuracy: 0.9931\n",
      "Epoch 2148/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9931\n",
      "Epoch 02148: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0349 - accuracy: 0.9931\n",
      "Epoch 2149/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9928\n",
      "Epoch 02149: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0359 - accuracy: 0.9928\n",
      "Epoch 2150/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9930\n",
      "Epoch 02150: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 980ms/step - loss: 0.0345 - accuracy: 0.9930\n",
      "Epoch 2151/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9931\n",
      "Epoch 02151: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0346 - accuracy: 0.9931\n",
      "Epoch 2152/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9930\n",
      "Epoch 02152: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0345 - accuracy: 0.9930\n",
      "Epoch 2153/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9926\n",
      "Epoch 02153: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0352 - accuracy: 0.9926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2154/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9930\n",
      "Epoch 02154: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0350 - accuracy: 0.9930\n",
      "Epoch 2155/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9932\n",
      "Epoch 02155: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0333 - accuracy: 0.9932\n",
      "Epoch 2156/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9930\n",
      "Epoch 02156: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0351 - accuracy: 0.9930\n",
      "Epoch 2157/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9934\n",
      "Epoch 02157: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0333 - accuracy: 0.9934\n",
      "Epoch 2158/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9930\n",
      "Epoch 02158: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0349 - accuracy: 0.9930\n",
      "Epoch 2159/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9932\n",
      "Epoch 02159: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0333 - accuracy: 0.9932\n",
      "Epoch 2160/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9933\n",
      "Epoch 02160: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0338 - accuracy: 0.9933\n",
      "Epoch 2161/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9932\n",
      "Epoch 02161: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0339 - accuracy: 0.9932\n",
      "Epoch 2162/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9930\n",
      "Epoch 02162: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0355 - accuracy: 0.9930\n",
      "Epoch 2163/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9931\n",
      "Epoch 02163: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0338 - accuracy: 0.9931\n",
      "Epoch 2164/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9933\n",
      "Epoch 02164: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0338 - accuracy: 0.9933\n",
      "Epoch 2165/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9934\n",
      "Epoch 02165: loss did not improve from 0.03284\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0331 - accuracy: 0.9934\n",
      "Epoch 2166/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9933\n",
      "Epoch 02166: loss improved from 0.03284 to 0.03252, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2166.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0325 - accuracy: 0.9933\n",
      "Epoch 2167/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9932\n",
      "Epoch 02167: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0337 - accuracy: 0.9932\n",
      "Epoch 2168/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9934\n",
      "Epoch 02168: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0328 - accuracy: 0.9934\n",
      "Epoch 2169/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9930\n",
      "Epoch 02169: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0335 - accuracy: 0.9930\n",
      "Epoch 2170/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9935\n",
      "Epoch 02170: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0329 - accuracy: 0.9935\n",
      "Epoch 2171/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9931\n",
      "Epoch 02171: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0337 - accuracy: 0.9931\n",
      "Epoch 2172/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9931\n",
      "Epoch 02172: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0327 - accuracy: 0.9931\n",
      "Epoch 2173/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9933\n",
      "Epoch 02173: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0327 - accuracy: 0.9933\n",
      "Epoch 2174/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9933\n",
      "Epoch 02174: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0328 - accuracy: 0.9933\n",
      "Epoch 2175/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9930\n",
      "Epoch 02175: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0330 - accuracy: 0.9930\n",
      "Epoch 2176/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9931\n",
      "Epoch 02176: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0348 - accuracy: 0.9931\n",
      "Epoch 2177/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9931\n",
      "Epoch 02177: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0335 - accuracy: 0.9931\n",
      "Epoch 2178/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9936\n",
      "Epoch 02178: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0342 - accuracy: 0.9936\n",
      "Epoch 2179/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9930\n",
      "Epoch 02179: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0339 - accuracy: 0.9930\n",
      "Epoch 2180/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9931\n",
      "Epoch 02180: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0325 - accuracy: 0.9931\n",
      "Epoch 2181/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9931\n",
      "Epoch 02181: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0336 - accuracy: 0.9931\n",
      "Epoch 2182/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9932\n",
      "Epoch 02182: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 980ms/step - loss: 0.0343 - accuracy: 0.9932\n",
      "Epoch 2183/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9933\n",
      "Epoch 02183: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0338 - accuracy: 0.9933\n",
      "Epoch 2184/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9934\n",
      "Epoch 02184: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0335 - accuracy: 0.9934\n",
      "Epoch 2185/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9934\n",
      "Epoch 02185: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0329 - accuracy: 0.9934\n",
      "Epoch 2186/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9934\n",
      "Epoch 02186: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0328 - accuracy: 0.9934\n",
      "Epoch 2187/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9932\n",
      "Epoch 02187: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0340 - accuracy: 0.9932\n",
      "Epoch 2188/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9934\n",
      "Epoch 02188: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0330 - accuracy: 0.9934\n",
      "Epoch 2189/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9933\n",
      "Epoch 02189: loss did not improve from 0.03252\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0340 - accuracy: 0.9933\n",
      "Epoch 2190/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9933\n",
      "Epoch 02190: loss improved from 0.03252 to 0.03189, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2190.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0319 - accuracy: 0.9933\n",
      "Epoch 2191/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9930\n",
      "Epoch 02191: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0342 - accuracy: 0.9930\n",
      "Epoch 2192/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9932\n",
      "Epoch 02192: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0329 - accuracy: 0.9932\n",
      "Epoch 2193/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9933\n",
      "Epoch 02193: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 984ms/step - loss: 0.0343 - accuracy: 0.9933\n",
      "Epoch 2194/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9931\n",
      "Epoch 02194: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0333 - accuracy: 0.9931\n",
      "Epoch 2195/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9932\n",
      "Epoch 02195: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0343 - accuracy: 0.9932\n",
      "Epoch 2196/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9930\n",
      "Epoch 02196: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 981ms/step - loss: 0.0340 - accuracy: 0.9930\n",
      "Epoch 2197/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9935\n",
      "Epoch 02197: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0324 - accuracy: 0.9935\n",
      "Epoch 2198/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9933\n",
      "Epoch 02198: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0329 - accuracy: 0.9933\n",
      "Epoch 2199/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9934\n",
      "Epoch 02199: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0333 - accuracy: 0.9934\n",
      "Epoch 2200/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9932\n",
      "Epoch 02200: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0339 - accuracy: 0.9932\n",
      "Epoch 2201/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9933\n",
      "Epoch 02201: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0320 - accuracy: 0.9933\n",
      "Epoch 2202/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9934\n",
      "Epoch 02202: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0339 - accuracy: 0.9934\n",
      "Epoch 2203/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9932\n",
      "Epoch 02203: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0330 - accuracy: 0.9932\n",
      "Epoch 2204/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9933\n",
      "Epoch 02204: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0335 - accuracy: 0.9933\n",
      "Epoch 2205/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9930\n",
      "Epoch 02205: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0351 - accuracy: 0.9930\n",
      "Epoch 2206/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9932\n",
      "Epoch 02206: loss did not improve from 0.03189\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0337 - accuracy: 0.9932\n",
      "Epoch 2207/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9931\n",
      "Epoch 02207: loss improved from 0.03189 to 0.03164, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2207.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0316 - accuracy: 0.9931\n",
      "Epoch 2208/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9934\n",
      "Epoch 02208: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0335 - accuracy: 0.9934\n",
      "Epoch 2209/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9932\n",
      "Epoch 02209: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0332 - accuracy: 0.9932\n",
      "Epoch 2210/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9931\n",
      "Epoch 02210: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0337 - accuracy: 0.9931\n",
      "Epoch 2211/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9935\n",
      "Epoch 02211: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0321 - accuracy: 0.9935\n",
      "Epoch 2212/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9934\n",
      "Epoch 02212: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0334 - accuracy: 0.9934\n",
      "Epoch 2213/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9934\n",
      "Epoch 02213: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0317 - accuracy: 0.9934\n",
      "Epoch 2214/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9935\n",
      "Epoch 02214: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0332 - accuracy: 0.9935\n",
      "Epoch 2215/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9932\n",
      "Epoch 02215: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0333 - accuracy: 0.9932\n",
      "Epoch 2216/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9933\n",
      "Epoch 02216: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0325 - accuracy: 0.9933\n",
      "Epoch 2217/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9934\n",
      "Epoch 02217: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0332 - accuracy: 0.9934\n",
      "Epoch 2218/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9938\n",
      "Epoch 02218: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0317 - accuracy: 0.9938\n",
      "Epoch 2219/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9936\n",
      "Epoch 02219: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0326 - accuracy: 0.9936\n",
      "Epoch 2220/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9933\n",
      "Epoch 02220: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0332 - accuracy: 0.9933\n",
      "Epoch 2221/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9933\n",
      "Epoch 02221: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0330 - accuracy: 0.9933\n",
      "Epoch 2222/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9933\n",
      "Epoch 02222: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0320 - accuracy: 0.9933\n",
      "Epoch 2223/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9933\n",
      "Epoch 02223: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0342 - accuracy: 0.9933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2224/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9930\n",
      "Epoch 02224: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 996ms/step - loss: 0.0325 - accuracy: 0.9930\n",
      "Epoch 2225/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9932\n",
      "Epoch 02225: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0342 - accuracy: 0.9932\n",
      "Epoch 2226/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9936\n",
      "Epoch 02226: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0327 - accuracy: 0.9936\n",
      "Epoch 2227/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9932\n",
      "Epoch 02227: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0331 - accuracy: 0.9932\n",
      "Epoch 2228/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9932\n",
      "Epoch 02228: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0334 - accuracy: 0.9932\n",
      "Epoch 2229/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9932\n",
      "Epoch 02229: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0331 - accuracy: 0.9932\n",
      "Epoch 2230/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9933\n",
      "Epoch 02230: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0332 - accuracy: 0.9933\n",
      "Epoch 2231/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9935\n",
      "Epoch 02231: loss did not improve from 0.03164\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0335 - accuracy: 0.9935\n",
      "Epoch 2232/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9936\n",
      "Epoch 02232: loss improved from 0.03164 to 0.03118, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2232.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0312 - accuracy: 0.9936\n",
      "Epoch 2233/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9934\n",
      "Epoch 02233: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0339 - accuracy: 0.9934\n",
      "Epoch 2234/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9934\n",
      "Epoch 02234: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0334 - accuracy: 0.9934\n",
      "Epoch 2235/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9935\n",
      "Epoch 02235: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0330 - accuracy: 0.9935\n",
      "Epoch 2236/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9933\n",
      "Epoch 02236: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0330 - accuracy: 0.9933\n",
      "Epoch 2237/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9933\n",
      "Epoch 02237: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0332 - accuracy: 0.9933\n",
      "Epoch 2238/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9931\n",
      "Epoch 02238: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0337 - accuracy: 0.9931\n",
      "Epoch 2239/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9932\n",
      "Epoch 02239: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0326 - accuracy: 0.9932\n",
      "Epoch 2240/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9934\n",
      "Epoch 02240: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0325 - accuracy: 0.9934\n",
      "Epoch 2241/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9934\n",
      "Epoch 02241: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0333 - accuracy: 0.9934\n",
      "Epoch 2242/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9933\n",
      "Epoch 02242: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 961ms/step - loss: 0.0334 - accuracy: 0.9933\n",
      "Epoch 2243/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9934\n",
      "Epoch 02243: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 962ms/step - loss: 0.0330 - accuracy: 0.9934\n",
      "Epoch 2244/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9933\n",
      "Epoch 02244: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0318 - accuracy: 0.9933\n",
      "Epoch 2245/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9932\n",
      "Epoch 02245: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 960ms/step - loss: 0.0327 - accuracy: 0.9932\n",
      "Epoch 2246/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9936\n",
      "Epoch 02246: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 961ms/step - loss: 0.0321 - accuracy: 0.9936\n",
      "Epoch 2247/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9934\n",
      "Epoch 02247: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0329 - accuracy: 0.9934\n",
      "Epoch 2248/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9935\n",
      "Epoch 02248: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0317 - accuracy: 0.9935\n",
      "Epoch 2249/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9936\n",
      "Epoch 02249: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0320 - accuracy: 0.9936\n",
      "Epoch 2250/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9934\n",
      "Epoch 02250: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0328 - accuracy: 0.9934\n",
      "Epoch 2251/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9932\n",
      "Epoch 02251: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0341 - accuracy: 0.9932\n",
      "Epoch 2252/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9935\n",
      "Epoch 02252: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0316 - accuracy: 0.9935\n",
      "Epoch 2253/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9931\n",
      "Epoch 02253: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0339 - accuracy: 0.9931\n",
      "Epoch 2254/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9934\n",
      "Epoch 02254: loss did not improve from 0.03118\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0330 - accuracy: 0.9934\n",
      "Epoch 2255/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9935\n",
      "Epoch 02255: loss improved from 0.03118 to 0.02996, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2255.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0300 - accuracy: 0.9935\n",
      "Epoch 2256/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9933\n",
      "Epoch 02256: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0332 - accuracy: 0.9933\n",
      "Epoch 2257/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9935\n",
      "Epoch 02257: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0318 - accuracy: 0.9935\n",
      "Epoch 2258/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9932\n",
      "Epoch 02258: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0354 - accuracy: 0.9932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2259/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9934\n",
      "Epoch 02259: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0313 - accuracy: 0.9934\n",
      "Epoch 2260/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9932\n",
      "Epoch 02260: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0333 - accuracy: 0.9932\n",
      "Epoch 2261/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9933\n",
      "Epoch 02261: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0331 - accuracy: 0.9933\n",
      "Epoch 2262/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9931\n",
      "Epoch 02262: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0336 - accuracy: 0.9931\n",
      "Epoch 2263/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9937\n",
      "Epoch 02263: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0321 - accuracy: 0.9937\n",
      "Epoch 2264/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9933\n",
      "Epoch 02264: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0337 - accuracy: 0.9933\n",
      "Epoch 2265/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9934\n",
      "Epoch 02265: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 960ms/step - loss: 0.0324 - accuracy: 0.9934\n",
      "Epoch 2266/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9934\n",
      "Epoch 02266: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0323 - accuracy: 0.9934\n",
      "Epoch 2267/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9937\n",
      "Epoch 02267: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0312 - accuracy: 0.9937\n",
      "Epoch 2268/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9934\n",
      "Epoch 02268: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0320 - accuracy: 0.9934\n",
      "Epoch 2269/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9934\n",
      "Epoch 02269: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0322 - accuracy: 0.9934\n",
      "Epoch 2270/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9937\n",
      "Epoch 02270: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0308 - accuracy: 0.9937\n",
      "Epoch 2271/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9935\n",
      "Epoch 02271: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0323 - accuracy: 0.9935\n",
      "Epoch 2272/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9935\n",
      "Epoch 02272: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0326 - accuracy: 0.9935\n",
      "Epoch 2273/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9933\n",
      "Epoch 02273: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0320 - accuracy: 0.9933\n",
      "Epoch 2274/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9937\n",
      "Epoch 02274: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0313 - accuracy: 0.9937\n",
      "Epoch 2275/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9936\n",
      "Epoch 02275: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0318 - accuracy: 0.9936\n",
      "Epoch 2276/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9936\n",
      "Epoch 02276: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0315 - accuracy: 0.9936\n",
      "Epoch 2277/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9934\n",
      "Epoch 02277: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0322 - accuracy: 0.9934\n",
      "Epoch 2278/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9937\n",
      "Epoch 02278: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0310 - accuracy: 0.9937\n",
      "Epoch 2279/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9935\n",
      "Epoch 02279: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0319 - accuracy: 0.9935\n",
      "Epoch 2280/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9936\n",
      "Epoch 02280: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0321 - accuracy: 0.9936\n",
      "Epoch 2281/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9936\n",
      "Epoch 02281: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 964ms/step - loss: 0.0310 - accuracy: 0.9936\n",
      "Epoch 2282/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9934\n",
      "Epoch 02282: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0319 - accuracy: 0.9934\n",
      "Epoch 2283/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9935\n",
      "Epoch 02283: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0323 - accuracy: 0.9935\n",
      "Epoch 2284/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9935\n",
      "Epoch 02284: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0310 - accuracy: 0.9935\n",
      "Epoch 2285/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9933\n",
      "Epoch 02285: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 960ms/step - loss: 0.0331 - accuracy: 0.9933\n",
      "Epoch 2286/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9935\n",
      "Epoch 02286: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0310 - accuracy: 0.9935\n",
      "Epoch 2287/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9933\n",
      "Epoch 02287: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 984ms/step - loss: 0.0323 - accuracy: 0.9933\n",
      "Epoch 2288/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9934\n",
      "Epoch 02288: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0321 - accuracy: 0.9934\n",
      "Epoch 2289/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9933\n",
      "Epoch 02289: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0325 - accuracy: 0.9933\n",
      "Epoch 2290/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9934\n",
      "Epoch 02290: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0308 - accuracy: 0.9934\n",
      "Epoch 2291/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9936\n",
      "Epoch 02291: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0318 - accuracy: 0.9936\n",
      "Epoch 2292/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9935\n",
      "Epoch 02292: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0314 - accuracy: 0.9935\n",
      "Epoch 2293/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9936\n",
      "Epoch 02293: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0307 - accuracy: 0.9936\n",
      "Epoch 2294/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9937\n",
      "Epoch 02294: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0321 - accuracy: 0.9937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2295/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9934\n",
      "Epoch 02295: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 957ms/step - loss: 0.0325 - accuracy: 0.9934\n",
      "Epoch 2296/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9936\n",
      "Epoch 02296: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0312 - accuracy: 0.9936\n",
      "Epoch 2297/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9933\n",
      "Epoch 02297: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0309 - accuracy: 0.9933\n",
      "Epoch 2298/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9936\n",
      "Epoch 02298: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0307 - accuracy: 0.9936\n",
      "Epoch 2299/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9935\n",
      "Epoch 02299: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0303 - accuracy: 0.9935\n",
      "Epoch 2300/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9937\n",
      "Epoch 02300: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0318 - accuracy: 0.9937\n",
      "Epoch 2301/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9937\n",
      "Epoch 02301: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0308 - accuracy: 0.9937\n",
      "Epoch 2302/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9935\n",
      "Epoch 02302: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0318 - accuracy: 0.9935\n",
      "Epoch 2303/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9936\n",
      "Epoch 02303: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0312 - accuracy: 0.9936\n",
      "Epoch 2304/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9936\n",
      "Epoch 02304: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 979ms/step - loss: 0.0310 - accuracy: 0.9936\n",
      "Epoch 2305/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9935\n",
      "Epoch 02305: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0316 - accuracy: 0.9935\n",
      "Epoch 2306/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9936\n",
      "Epoch 02306: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0305 - accuracy: 0.9936\n",
      "Epoch 2307/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9937\n",
      "Epoch 02307: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0309 - accuracy: 0.9937\n",
      "Epoch 2308/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9935\n",
      "Epoch 02308: loss did not improve from 0.02996\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0309 - accuracy: 0.9935\n",
      "Epoch 2309/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9937\n",
      "Epoch 02309: loss improved from 0.02996 to 0.02926, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2309.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0293 - accuracy: 0.9937\n",
      "Epoch 2310/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9937\n",
      "Epoch 02310: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 985ms/step - loss: 0.0311 - accuracy: 0.9937\n",
      "Epoch 2311/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9936\n",
      "Epoch 02311: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0298 - accuracy: 0.9936\n",
      "Epoch 2312/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9938\n",
      "Epoch 02312: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 962ms/step - loss: 0.0321 - accuracy: 0.9938\n",
      "Epoch 2313/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9932\n",
      "Epoch 02313: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 977ms/step - loss: 0.0326 - accuracy: 0.9932\n",
      "Epoch 2314/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9934\n",
      "Epoch 02314: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0320 - accuracy: 0.9934\n",
      "Epoch 2315/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9934\n",
      "Epoch 02315: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0318 - accuracy: 0.9934\n",
      "Epoch 2316/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9936\n",
      "Epoch 02316: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0304 - accuracy: 0.9936\n",
      "Epoch 2317/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9933\n",
      "Epoch 02317: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0318 - accuracy: 0.9933\n",
      "Epoch 2318/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9934\n",
      "Epoch 02318: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0320 - accuracy: 0.9934\n",
      "Epoch 2319/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9937\n",
      "Epoch 02319: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0296 - accuracy: 0.9937\n",
      "Epoch 2320/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9935\n",
      "Epoch 02320: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 962ms/step - loss: 0.0314 - accuracy: 0.9935\n",
      "Epoch 2321/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9933\n",
      "Epoch 02321: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0317 - accuracy: 0.9933\n",
      "Epoch 2322/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9935\n",
      "Epoch 02322: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0308 - accuracy: 0.9935\n",
      "Epoch 2323/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9934\n",
      "Epoch 02323: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0316 - accuracy: 0.9934\n",
      "Epoch 2324/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9935\n",
      "Epoch 02324: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0327 - accuracy: 0.9935\n",
      "Epoch 2325/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9935\n",
      "Epoch 02325: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0311 - accuracy: 0.9935\n",
      "Epoch 2326/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9933\n",
      "Epoch 02326: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0319 - accuracy: 0.9933\n",
      "Epoch 2327/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9938\n",
      "Epoch 02327: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0308 - accuracy: 0.9938\n",
      "Epoch 2328/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9935\n",
      "Epoch 02328: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0315 - accuracy: 0.9935\n",
      "Epoch 2329/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9937\n",
      "Epoch 02329: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0311 - accuracy: 0.9937\n",
      "Epoch 2330/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9936\n",
      "Epoch 02330: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0312 - accuracy: 0.9936\n",
      "Epoch 2331/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9935\n",
      "Epoch 02331: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 959ms/step - loss: 0.0309 - accuracy: 0.9935\n",
      "Epoch 2332/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9936\n",
      "Epoch 02332: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 963ms/step - loss: 0.0321 - accuracy: 0.9936\n",
      "Epoch 2333/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9934\n",
      "Epoch 02333: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0317 - accuracy: 0.9934\n",
      "Epoch 2334/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9936\n",
      "Epoch 02334: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0332 - accuracy: 0.9936\n",
      "Epoch 2335/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9936\n",
      "Epoch 02335: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0322 - accuracy: 0.9936\n",
      "Epoch 2336/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9934\n",
      "Epoch 02336: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0318 - accuracy: 0.9934\n",
      "Epoch 2337/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9935\n",
      "Epoch 02337: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0321 - accuracy: 0.9935\n",
      "Epoch 2338/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9936\n",
      "Epoch 02338: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0311 - accuracy: 0.9936\n",
      "Epoch 2339/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9934\n",
      "Epoch 02339: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0330 - accuracy: 0.9934\n",
      "Epoch 2340/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9934\n",
      "Epoch 02340: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0330 - accuracy: 0.9934\n",
      "Epoch 2341/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9935\n",
      "Epoch 02341: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0318 - accuracy: 0.9935\n",
      "Epoch 2342/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9932\n",
      "Epoch 02342: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0329 - accuracy: 0.9932\n",
      "Epoch 2343/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9933\n",
      "Epoch 02343: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0315 - accuracy: 0.9933\n",
      "Epoch 2344/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9935\n",
      "Epoch 02344: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 978ms/step - loss: 0.0330 - accuracy: 0.9935\n",
      "Epoch 2345/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9936\n",
      "Epoch 02345: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0315 - accuracy: 0.9936\n",
      "Epoch 2346/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9934\n",
      "Epoch 02346: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0329 - accuracy: 0.9934\n",
      "Epoch 2347/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9935\n",
      "Epoch 02347: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0299 - accuracy: 0.9935\n",
      "Epoch 2348/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9936\n",
      "Epoch 02348: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 976ms/step - loss: 0.0312 - accuracy: 0.9936\n",
      "Epoch 2349/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9938\n",
      "Epoch 02349: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0303 - accuracy: 0.9938\n",
      "Epoch 2350/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9935\n",
      "Epoch 02350: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0319 - accuracy: 0.9935\n",
      "Epoch 2351/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9936\n",
      "Epoch 02351: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0310 - accuracy: 0.9936\n",
      "Epoch 2352/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9934\n",
      "Epoch 02352: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0310 - accuracy: 0.9934\n",
      "Epoch 2353/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9937\n",
      "Epoch 02353: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0312 - accuracy: 0.9937\n",
      "Epoch 2354/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9937\n",
      "Epoch 02354: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0301 - accuracy: 0.9937\n",
      "Epoch 2355/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9936\n",
      "Epoch 02355: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 982ms/step - loss: 0.0316 - accuracy: 0.9936\n",
      "Epoch 2356/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9937\n",
      "Epoch 02356: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 969ms/step - loss: 0.0307 - accuracy: 0.9937\n",
      "Epoch 2357/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9936\n",
      "Epoch 02357: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 0.0310 - accuracy: 0.9936\n",
      "Epoch 2358/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9933\n",
      "Epoch 02358: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 0.0326 - accuracy: 0.9933\n",
      "Epoch 2359/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9938\n",
      "Epoch 02359: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0312 - accuracy: 0.9938\n",
      "Epoch 2360/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9938\n",
      "Epoch 02360: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 980ms/step - loss: 0.0301 - accuracy: 0.9938\n",
      "Epoch 2361/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9937\n",
      "Epoch 02361: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0310 - accuracy: 0.9937\n",
      "Epoch 2362/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9935\n",
      "Epoch 02362: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0317 - accuracy: 0.9935\n",
      "Epoch 2363/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9935\n",
      "Epoch 02363: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0304 - accuracy: 0.9935\n",
      "Epoch 2364/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9933\n",
      "Epoch 02364: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0324 - accuracy: 0.9933\n",
      "Epoch 2365/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9938\n",
      "Epoch 02365: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 968ms/step - loss: 0.0313 - accuracy: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2366/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9936\n",
      "Epoch 02366: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0313 - accuracy: 0.9936\n",
      "Epoch 2367/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9934\n",
      "Epoch 02367: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 972ms/step - loss: 0.0316 - accuracy: 0.9934\n",
      "Epoch 2368/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9934\n",
      "Epoch 02368: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0321 - accuracy: 0.9934\n",
      "Epoch 2369/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9936\n",
      "Epoch 02369: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 0.0301 - accuracy: 0.9936\n",
      "Epoch 2370/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9935\n",
      "Epoch 02370: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 975ms/step - loss: 0.0310 - accuracy: 0.9935\n",
      "Epoch 2371/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9937\n",
      "Epoch 02371: loss did not improve from 0.02926\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0299 - accuracy: 0.9937\n",
      "Epoch 2372/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9940\n",
      "Epoch 02372: loss improved from 0.02926 to 0.02904, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2372.ckpt\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.0290 - accuracy: 0.9940\n",
      "Epoch 2373/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9937\n",
      "Epoch 02373: loss did not improve from 0.02904\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0294 - accuracy: 0.9937\n",
      "Epoch 2374/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9937\n",
      "Epoch 02374: loss did not improve from 0.02904\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 0.0307 - accuracy: 0.9937\n",
      "Epoch 2375/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9935\n",
      "Epoch 02375: loss did not improve from 0.02904\n",
      "2/2 [==============================] - 2s 970ms/step - loss: 0.0313 - accuracy: 0.9935\n",
      "Epoch 2376/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9936\n",
      "Epoch 02376: loss did not improve from 0.02904\n",
      "2/2 [==============================] - 2s 973ms/step - loss: 0.0315 - accuracy: 0.9936\n",
      "Epoch 2377/2500\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9940\n",
      "Epoch 02377: loss improved from 0.02904 to 0.02901, saving model to C:/Users/derma/Documents/Checkpoints Deep\\cp_2377.ckpt\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to WriteFile: C:/Users/derma/Documents/Checkpoints Deep\\cp_2377.ckpt_temp/part-00000-of-00001.data-00000-of-00001.tempstate13512726061771246931 : There is not enough space on the disk.\r\n; operation in progress [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20116/346446738.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m history=model.fit(dataset, \n\u001b[0m\u001b[0;32m      7\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to WriteFile: C:/Users/derma/Documents/Checkpoints Deep\\cp_2377.ckpt_temp/part-00000-of-00001.data-00000-of-00001.tempstate13512726061771246931 : There is not enough space on the disk.\r\n; operation in progress [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "# ciclos de entrenamiento = 500\n",
    "# verbose 0 = no quiero ver por terminal la descripcion de cada ciclo de entrenamiento\n",
    "# vervose 0 = menor requerimiento de recursos en el entrenamiento, se utiliza netamiente la GPU para entrenar\n",
    "\n",
    "EPOCHS=2500\n",
    "history=model.fit(dataset, \n",
    "                  epochs=EPOCHS, \n",
    "                  verbose=1,\n",
    "                  callbacks=[cp_callback]) #6000 + 6000 + 1000 + 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2hHEKXavgr7"
   },
   "source": [
    "Tambien se puede entranar atravez de otro checkpoint.\n",
    "\n",
    "Desde la carpeta que optamos guardar los checkpoints\n",
    "\n",
    "1. el archivo .data es el archivo que contiene nuestras variables de entrenamiento y vamos a ir tras él.\n",
    "2. el archivo checkpoint, simplemente mantiene un registro de los últimos archivos de punto de control guardados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1227,
     "status": "ok",
     "timestamp": 1637435274264,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "AsHDkkFtvvdf",
    "outputId": "1a1ccbfe-b930-48ef-8901-816b459d8e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/derma/Documents/Checkpoints Deep/cp_2372.ckpt\n"
     ]
    }
   ],
   "source": [
    "#creamos un modelo con iguales caracteristicas al 1° modelo\n",
    "model=create_model(vocab_size   =vocab_size,\n",
    "                  embedding_dim =embedding_dim,\n",
    "                  rnn_units     =rnn_units,\n",
    "                  batch_size    =BATCH_SIZE)\n",
    "\n",
    "#buscamos el ultimo checkpoint de entrenamiento\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest) \n",
    "#C:/Users/derma/Documents/Checkpoints Deep/cp_0299.ckpt\n",
    "#C:/Users/derma/Documents/Checkpoints Deep/cp_0299.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.18517 6000 Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Pérdida vs. iteraciones')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.xlabel('Iteración')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Precisión vs. iteraciones')\n",
    "plt.ylabel('Precisión')\n",
    "plt.xlabel('Iteración')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okn-pEmfvy43"
   },
   "source": [
    "## Generando Texto usando RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "xoMZHRnYvz3W"
   },
   "outputs": [],
   "source": [
    "#creamos un modelo tomando como base el ultimo checkpoint\n",
    "model = create_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "_aOfWtbkwhge"
   },
   "outputs": [],
   "source": [
    "#funcion para generar texto\n",
    "def generate_text(model, start_string):\n",
    "  #definimos cuantos tensores/cantidad de texto generaremos\n",
    "  num_generate=500\n",
    "  #convertimos el texto en números\n",
    "  input_eval=[char2idx[s] for s in start_string]\n",
    "  input_eval= tf.expand_dims (input_eval,0)\n",
    "  text_generated = []\n",
    "\n",
    "  temperature = 0.1  #(0.0 a  1) entre más alta la temperatura más creatividad al modelo, pero tambien más errores ortograficos.\n",
    "  model.reset_states() #bucle para generar caracteres, mediante predicciones\n",
    "  for i in range(num_generate):\n",
    "    predictions = model(input_eval)\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "    input_eval= tf.expand_dims([predicted_id],0)\n",
    "    text_generated.append (idx2char[predicted_id])\n",
    "  \n",
    "  return (start_string+ ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yMIwur176J4"
   },
   "source": [
    "### Generando texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "ZD7lj7KOAkod",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soleado y me acuesto a dormir yo vivo en un pueblo podrido en donde todo esta podrido y voy de noche siempre a oscuras caminando entre la basura  no voy a llegar muy lejos en un omnibus lleno de viejos porque me asaltan con un caño delincuentes de doce años  asi quiero estar  los zapatos se me mojan pisando las baldosas flojas y la calle no me da tregua esta playback de mi vida cancion problemita todo lo que me gusta es pecado o hace mal todo lo que me gusta es muy caro o ilegal me mete en problemas qu\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"soleado\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLz82hddAx0V"
   },
   "source": [
    "## Exportando modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "error",
     "timestamp": 1637004642848,
     "user": {
      "displayName": "Luis Felipe Narvaez Gomez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjXcDURDH-B2fUyoGzkdL6AUWGQMU77b9WQtesg=s64",
      "userId": "09694380853557080637"
     },
     "user_tz": 300
    },
    "id": "Ce36Irbuwhge",
    "outputId": "3dc554d4-5dfe-4ef7-92cc-9762cc929319"
   },
   "source": [
    "Guardamos y Serializamos el Modelo (con esto ya podemos vender nuestro modelo de predicción de texto según lo aprendido por nuestra RNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7WBX262mwhgf"
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "40E0Lm0n2I9x"
   },
   "outputs": [],
   "source": [
    "dir_export= 'C:/Users/derma/Documents/Exports/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "5Jq0dzHe2NdX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/derma/Documents/Exports/\n"
     ]
    }
   ],
   "source": [
    "print(dir_export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "VcoS3joTwhgf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo salvado en Directorio Local\n"
     ]
    }
   ],
   "source": [
    "# Serializamos el modelo en forma JSON\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(dir_export,'RNN_rock_json.json'), 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(os.path.join(dir_export,'RNN_rock_pesos.hdf5'))\n",
    "model.save(os.path.join(dir_export,'RNN_rock_model.h5'))\n",
    "print(\"modelo salvado en Directorio Local\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "xGKdeALQKzcq",
    "cINT2voTtupb",
    "C6Qc6_M1uKNB",
    "-Rg-z0vxo6U8",
    "3cviBoQD3fkB",
    "5yMIwur176J4",
    "VcoS3joTwhgf",
    "40E0Lm0n2I9x",
    "QswnqvuD2wgB",
    "LVdIF9ek26OL"
   ],
   "name": "P1T17_DeepLearning_Redes Neuronales Recurrentes RNN _ Generación de Texto con KERAS (ElGatoNegro).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
